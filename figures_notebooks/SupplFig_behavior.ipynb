{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flammkuchen as fl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy import stats\n",
    "import os\n",
    "import math\n",
    "\n",
    "from luminance_analysis import PooledData\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from luminance_analysis.utilities import nanzscore\n",
    "\n",
    "plt.style.use(\"figures.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bouter.utilities import extract_segments_above_threshold\n",
    "import seaborn as sns\n",
    "from luminance_analysis.plotting import make_bar, get_yg_custom_cmap, add_offset_axes, shade_plot, stim_plot\n",
    "\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fold = Path(r\"C:\\Users\\otprat\\Documents\\figures\\luminance\\manuscript_figures\\fig1supp\")\n",
    "\n",
    "if not os.path.isdir(fig_fold):\n",
    "    os.mkdir(fig_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_vel(x_vel, y_vel):  \n",
    "    return(np.sqrt((x_vel**2)+(y_vel**2)))\n",
    "\n",
    "def crop_intervals_from_mat(data_mat, timepoints, dt, window):\n",
    "    cropped_mat = np.empty((data_mat.shape[0]*len(timepoints), int(window/dt), data_mat.shape[2]))\n",
    "    \n",
    "    for fish in range(data_mat.shape[2]):\n",
    "        for stim_rep in range(data_mat.shape[0]):\n",
    "            for timepoint in range(len(timepoints)):\n",
    "                if timepoints[timepoint][0] < 0:\n",
    "                    cropped_interval = data_mat[stim_rep, timepoints[timepoint][0]:, fish]\n",
    "                else:\n",
    "                    cropped_interval = data_mat[stim_rep, timepoints[timepoint][0]:timepoints[timepoint][0]+int(window/dt), fish]\n",
    "                cropped_mat[timepoint + len(timepoints)*stim_rep, :, fish] = cropped_interval   \n",
    "    return(cropped_mat)\n",
    "\n",
    "def smooth_df(df, window, omit_col=None):       \n",
    "    extended_df = pd.DataFrame(np.concatenate((df.values[-window//2:, :], df.values, df.values[:window//2, :])))\n",
    "    smoothed_extended_df = extended_df.rolling(window+1, center=True).mean()\n",
    "    smoothed_df = pd.DataFrame(smoothed_extended_df.values[window//2:-window//2, :], index=df.index, columns=df.columns)\n",
    "    \n",
    "    if omit_col is not None:\n",
    "        smoothed_df[omit_col] = df[omit_col]\n",
    "    \n",
    "    return(smoothed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary functions from old bouter\n",
    "\n",
    "def resample(df_in, resample_sec=0.005):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_in :\n",
    "\n",
    "    resample_sec :\n",
    "\n",
    "    fill_nan: int\n",
    "        If a number is passed, NaNs will be filled with it before interpolation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    t_index = pd.to_timedelta(\n",
    "        (df[\"t\"].to_numpy() * 10e5).astype(np.uint64), unit=\"us\"\n",
    "    )\n",
    "    df.set_index(t_index - t_index[0], inplace=True)\n",
    "    df = df.resample(\"{}ms\".format(int(resample_sec * 1000))).mean()\n",
    "    df.index = df.index.total_seconds()\n",
    "    return df.interpolate().drop(\"t\", axis=1)\n",
    "\n",
    "    \n",
    "def find_phase_col(exp):\n",
    "    \"\"\"\n",
    "    Find the name of the stimulus_param_log df where phase data is stored\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        Name of the DataFrame column\n",
    "    \"\"\"\n",
    "    phase_col = next(col for col in exp.stimulus_log.columns if col.endswith('_current_phase'))\n",
    "    return phase_col\n",
    "\n",
    "\n",
    "def get_n_reps(exp):\n",
    "    \"\"\"\n",
    "    Find number of shuffled repetitions per stimulation loop\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Number of shuffled repetitions per stimulation loop\n",
    "    \"\"\"\n",
    "    try:\n",
    "        n_reps = exp['stimulus']['protocol'][next(iter(exp['stimulus']['protocol'].keys()))]['shuffled_reps']\n",
    "    except KeyError:\n",
    "        n_reps = 1\n",
    "\n",
    "    return n_reps\n",
    "\n",
    "\n",
    "def get_rep_t_intervals(exp, phases_per_rep, use_resampled_df=True, use_phases=False):\n",
    "    \"\"\"\n",
    "    Get starting and ending timepoints for each shuffled stimulus repetition\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phases_per_rep : int\n",
    "        Number of phases of which the presented stimulus consists\n",
    "    use_resampled_df : bool\n",
    "        Indicates whether the DataFrame should be resampled\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples\n",
    "        Starting and ending timepoints for each stimulus repetition\n",
    "    \"\"\"\n",
    "    if use_resampled_df:\n",
    "        stimulus_log = resample(exp.stimulus_log)\n",
    "    else:\n",
    "        stimulus_log = exp.stimulus_log\n",
    "\n",
    "    phase_col = find_phase_col(exp)\n",
    "    if not use_phases:\n",
    "        n_shuffled_reps = get_n_reps(exp)\n",
    "    else:\n",
    "        n_shuffled_reps = int((np.unique(exp.stimulus_log[find_phase_col(exp)]).shape[0])/phases_per_rep)\n",
    "        \n",
    "    t_rep_intervals = []\n",
    "\n",
    "    for i_shuffled_rep in range(n_shuffled_reps):\n",
    "        rep_phases = [phase + phases_per_rep * i_shuffled_rep for phase in range(phases_per_rep)]\n",
    "\n",
    "        idx_start_t = stimulus_log[stimulus_log[phase_col] == rep_phases[0]].index.to_list()[0]\n",
    "        idx_end_t = stimulus_log[stimulus_log[phase_col] == rep_phases[-1]].index.to_list()[-1]\n",
    "\n",
    "        if use_resampled_df:\n",
    "            t_rep_intervals.append((idx_start_t, idx_end_t))\n",
    "        else:\n",
    "            t_rep_intervals.append((stimulus_log.iloc[idx_start_t]['t'], stimulus_log.iloc[idx_end_t]['t']))\n",
    "\n",
    "    return t_rep_intervals\n",
    "\n",
    "def get_stim_arr(exp, phases_per_rep, stim_name, resample_df=True):\n",
    "    \"\"\"\n",
    "    Get stimulus array with timestamps and stimulation variable\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phases_per_rep : int\n",
    "        Number of phases of which the presented stimulus consists\n",
    "    stim_name : str\n",
    "        Name of the DataFrame column containing the stimulation variable\n",
    "    resample_df : bool\n",
    "        Indicates whether the stimulus array should be resampled\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Stimulus array\n",
    "    \"\"\"\n",
    "    phase_col = find_phase_col(exp)\n",
    "    first_rep = exp.stimulus_log[exp.stimulus_log[phase_col] < phases_per_rep]\n",
    "\n",
    "    if resample_df:\n",
    "        first_rep = resample(first_rep)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    stim = first_rep.index.values\n",
    "    stim = np.vstack([stim, first_rep[stim_name].values])\n",
    "\n",
    "    return stim\n",
    "\n",
    "def crop_reps_from_df(df, cropping_idxs, data_cols, n_timepoints, use_resampled_df=True, out_format='dict'):\n",
    "    \"\"\"\n",
    "    Crop a Dataframe into the multiple repetitions of the stimulus\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame with the complete data\n",
    "    cropping_idxs : list of tuples\n",
    "        Starting and ending indexes for each stimulus repetition\n",
    "    data_cols : list of str\n",
    "        Names of the DataFrame columns from which we want to crop the data\n",
    "    n_timepoints : int\n",
    "        number of timepoints into which the data should be resampled\n",
    "    use_resampled_df : bool\n",
    "        Indicates whether the input DataFrame has been previously resampled (and timepoints correspond to indexes)\n",
    "    out_format : str\n",
    "        Indicates the type of output data. 'list' for list of dataframes, one for each repetition,\n",
    "        'dict' for dictionary of arrays, one for each parameter specified in data_cols.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict of arrays\n",
    "        Dictionary of arrays for each column in data_cols. Dimensions being (stimulation repetitions x timepoints)\n",
    "    list of dataframes\n",
    "        List of pandas dataframes for each repetition in cropping_idxs.\n",
    "    \"\"\"\n",
    "    if out_format == 'dict':\n",
    "        data_dict = {}\n",
    "\n",
    "        for col in data_cols:\n",
    "            data_arr = np.empty((len(cropping_idxs), n_timepoints))\n",
    "            for rep in range(len(cropping_idxs)):\n",
    "                if use_resampled_df:\n",
    "                    rep_raw_t = df[cropping_idxs[rep][0]:cropping_idxs[rep][1]].index.values\n",
    "                else:\n",
    "                    rep_raw_t = df[cropping_idxs[rep][0]:cropping_idxs[rep][1]]['t'].values\n",
    "                rep_raw_data = df[cropping_idxs[rep][0]:cropping_idxs[rep][1]][col].values\n",
    "                data_arr[rep, :] = np.interp(np.linspace(rep_raw_t[0], rep_raw_t[-1], n_timepoints), rep_raw_t,\n",
    "                                             rep_raw_data)\n",
    "            data_dict[col] = data_arr\n",
    "\n",
    "        output_data = data_dict\n",
    "\n",
    "    elif out_format == 'list':\n",
    "        data_list = []\n",
    "\n",
    "        for rep in range(len(cropping_idxs)):\n",
    "            data_list.append(df[data_cols][cropping_idxs[rep][0]:cropping_idxs[rep][1]])\n",
    "\n",
    "        output_data = data_list\n",
    "\n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bouter\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classic luminance\n",
    "phases_per_rep = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled fish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swimming velocity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = True\n",
    "method = 'LFF'#'LFF' #'rolling median'\n",
    "window_size = 20\n",
    "\n",
    "fill_nans = True\n",
    "fill_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select datasets to load\n",
    "datasets = ['pilot']\n",
    "master_path = Path(r'\\\\FUNES\\Shared\\experiments\\E0032_luminance\\neat_exps\\freely_swimming_beh')\n",
    "\n",
    "#Define bout extraction parameters\n",
    "threshold = .25\n",
    "min_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And load them\n",
    "dataset_dict = {'vel_mat':{}, 'prob_mat':{}}\n",
    "stimulus_arr = np.array([])\n",
    "mat_len = 0\n",
    "\n",
    "#Load dataset velocities\n",
    "all_fish_mat = np.array([])\n",
    "\n",
    "for experiment in list(master_path.glob(\"*_f[0-9]\")):\n",
    "\n",
    "    print('Working on ' + str(experiment))\n",
    "    print('Loading data')\n",
    "    exp = bouter.free.FreelySwimmingExperiment(experiment)\n",
    "    idx_rep_intervals = get_rep_t_intervals(exp, phases_per_rep, use_phases=True)\n",
    "    \n",
    "    stim_arr = get_stim_arr(exp, phases_per_rep, 'flash_luminance')\n",
    "    experiment_dict = {}\n",
    "    \n",
    "    #Get stimulus array\n",
    "    if stimulus_arr.shape[0] == 0:\n",
    "        stimulus_arr = stim_arr\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    n_fish = exp['general']['program_version']['arguments']['tracking']['tracking_params']['n_max_fish']\n",
    "    print('{} fish detected'.format(n_fish))\n",
    "\n",
    "    print('Computing velocities')\n",
    "    vel_data_cols = []\n",
    "    for fish in range(n_fish):\n",
    "        for dim in ['x', 'y']:\n",
    "            vel_data_cols.append('f{}_v{}'.format(fish, dim))  \n",
    "\n",
    "    #Smooth dataset if desired\n",
    "    if smoothing:\n",
    "        if method == 'rolling median':\n",
    "            behavior_df = exp.behavior_log.rolling(window=window_size, min_periods=1).median()\n",
    "        elif method == 'LFF':\n",
    "            behavior_df = smooth_df(exp.behavior_log, window_size, omit_col='t')       \n",
    "    else:\n",
    "        behavior_df = exp.behavior_log  \n",
    "\n",
    "    #Fill NaNs\n",
    "    if fill_nans:\n",
    "        behavior_df = behavior_df.fillna(value=fill_val)\n",
    "\n",
    "    #Get velocities\n",
    "    experiment_dict = crop_reps_from_df(resample(behavior_df), idx_rep_intervals, vel_data_cols, stim_arr.shape[1])\n",
    "\n",
    "    for fish in range(n_fish):\n",
    "        fish_vel = calculate_total_vel(experiment_dict['f{}_vx'.format(fish)], experiment_dict['f{}_vy'.format(fish)])\n",
    "\n",
    "        #Set n_timepoints for data across all datasets\n",
    "        if mat_len == 0:\n",
    "            mat_len = fish_vel.shape[1]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #Stack data if same length, pad if shorter, crop if longer.\n",
    "        if fish_vel.shape[1] == mat_len:\n",
    "            if all_fish_mat.shape[0] == 0:\n",
    "                all_fish_mat = fish_vel\n",
    "            else:\n",
    "                all_fish_mat = np.dstack((all_fish_mat, fish_vel))\n",
    "            print('Data size matches perfectly')\n",
    "        elif fish_vel.shape[1] > mat_len:\n",
    "            if all_fish_mat.shape[0] == 0:\n",
    "                all_fish_mat = fish_vel[:, :mat_len]\n",
    "            else:\n",
    "                all_fish_mat = np.dstack((all_fish_mat, fish_vel[:, :mat_len]))\n",
    "            print('Cropped velocity data from {} to {} datapoints'.format(fish_vel.shape[1], mat_len))\n",
    "        else:\n",
    "            n_pad = ((0,0), (0, mat_len-fish_vel.shape[1]))\n",
    "            if all_fish_mat.shape[0] == 0:\n",
    "                all_fish_mat = np.pad(fish_vel, pad_width=n_pad, mode='edge')\n",
    "            else:\n",
    "                all_fish_mat = np.dstack((all_fish_mat, np.pad(fish_vel, pad_width=n_pad, mode='edge')))\n",
    "            print('Extended velocity data from {} to {} datapoints'.format(fish_vel.shape[1], mat_len)) \n",
    "    print('Velocities computed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract bouts\n",
    "print('Extracting dataset bouts')\n",
    "all_fish_bouts = np.zeros_like(all_fish_mat)\n",
    "\n",
    "for fish in range(all_fish_mat.shape[2]):\n",
    "    for rep in range(all_fish_mat.shape[0]):\n",
    "        try:\n",
    "            bouts, cont = extract_segments_above_threshold(all_fish_mat[rep, :, fish], threshold=threshold, min_length=min_length)\n",
    "        except IndexError:\n",
    "                    print('No bouts found in fish {}, repetition {}'.format(fish, rep))\n",
    "\n",
    "        for i_bout in range(len(bouts)):\n",
    "            all_fish_bouts[rep, bouts[i_bout][0]:bouts[i_bout][1], fish] = 1    \n",
    "\n",
    "#Store dataset velocities and bouts\n",
    "dataset_dict['vel_mat'] = all_fish_mat\n",
    "dataset_dict['prob_mat'] = all_fish_bouts\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize bout probability datasets\n",
    "normalize = 'fishwise' #'trialwise' #'fishwise'\n",
    "method = None #'zscore' #'substract' #'divide' #'zscore'\n",
    "\n",
    "prob_mat = dataset_dict['prob_mat']\n",
    "norm_prob_mat = np.empty_like(prob_mat)\n",
    "\n",
    "if normalize == 'trialwise':\n",
    "    for fish in range(prob_mat.shape[2]):\n",
    "        for rep in range(prob_mat.shape[0]):\n",
    "            if method == 'substract': #Substract mean\n",
    "                norm_rep = prob_mat[rep, :, fish] - np.nanmean(prob_mat[rep, :, fish])\n",
    "            elif method == 'divide': #Divide mean\n",
    "                norm_rep = prob_mat[rep, :, fish] / np.nanmean(prob_mat[rep, :, fish])\n",
    "            elif method == 'zscore': #Zscore\n",
    "                norm_rep = nanzscore(prob_mat[rep, :, fish])\n",
    "\n",
    "            norm_prob_mat[rep, :, fish] = norm_rep\n",
    "\n",
    "elif normalize == 'fishwise':\n",
    "    for fish in range(prob_mat.shape[2]):\n",
    "        norm_fish = prob_mat[:, :, fish] - np.nanmean(prob_mat[:, :, fish])\n",
    "        norm_prob_mat[:, :, fish] = norm_fish\n",
    "\n",
    "dataset_dict['norm_prob_mat'] = norm_prob_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_arr = stimulus_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bout probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_normalized_bout_mat = True\n",
    "\n",
    "if use_normalized_bout_mat:\n",
    "    prob_mat = dataset_dict['norm_prob_mat']\n",
    "else:\n",
    "    prob_mat = dataset_dict['prob_mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get average bout probability for each fish\n",
    "fish_mean_bout_prob = np.empty((prob_mat.shape[2], prob_mat.shape[1]))\n",
    "\n",
    "for fish in range(prob_mat.shape[2]):     \n",
    "    fish_mean_bout_prob[fish, :] = np.nanmean(prob_mat[:, :, fish], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bout_prob(bout_prob_mat, stimulus_array, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(6, 6))\n",
    "        \n",
    "    ax1 = add_offset_axes(figure, (0.12, 0.8, .75, .05), frame=frame) \n",
    "    ax2 = add_offset_axes(figure, (0.12, 0.3, .75, .5), frame=frame)\n",
    "    ax3 = add_offset_axes(figure, (0.12, 0.1, .75, .19), frame=frame)\n",
    "    ax4 = add_offset_axes(figure, (0.87, .45, .05, .1), frame=frame)\n",
    "\n",
    "    ax1.plot(stim_arr[0, :], stim_arr[1, :], c='black')\n",
    "    ax1.set_xlim([np.min(stim_arr[0, :]), np.max(stim_arr[0, :])])\n",
    "    ax1.axis('off')\n",
    "\n",
    "    plot_mat = ax2.imshow(fish_mean_bout_prob, aspect='auto', cmap='RdBu_r', vmin=-.25, vmax=.25)\n",
    "    ax2.set_ylabel('Fish')\n",
    "    ax2.axes.get_xaxis().set_visible(False)\n",
    "    ax2.set_yticks([i for i in np.arange(0, 15, 2)])\n",
    "    ax2.set_yticklabels([i for i in np.arange(1, 17, 2)])\n",
    "\n",
    "    ax3.plot(stim_arr[0, :], np.nanmean(fish_mean_bout_prob, 0), c='royalblue')\n",
    "    ax3.set_xlim([np.min(stim_arr[0, :]), np.max(stim_arr[0, :])])\n",
    "    ax3.set_ylabel('Avrg. bout ΔProb')\n",
    "    ax3.set_xlabel('Time [s.]')\n",
    "\n",
    "    alpha = .99\n",
    "    mean, std = stats.norm.fit(np.nanmean(fish_mean_bout_prob, 0))\n",
    "    conf_int = stats.norm.interval(0.99, loc=mean, scale=std)\n",
    "    for lim in conf_int:\n",
    "        ax3.axhline(lim, color='red', ls='--', alpha=.35)\n",
    "    ax3.text(.95, .5, '99% c.i.',ha='center', va='center', transform=ax3.transAxes, fontsize=7, color='red', alpha=.65)\n",
    "\n",
    "    cbar = plt.colorbar(plot_mat, ticks=[.25, 0, -.25], ax=ax4, shrink=2)\n",
    "    cbar.ax.tick_params(length=3)\n",
    "    ax4.axis('off')\n",
    "    ax4.text(.75, 0.5, 'Bout ΔProbability', ha='center', va='center', transform=ax4.transAxes, fontsize=7, rotation=90)\n",
    "\n",
    "    sns.despine(left=True, bottom=True, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bout_prob(fish_mean_bout_prob, stim_arr, figure=None, frame=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P(bout) decrease time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get timepoints of luminance offsets\n",
    "offset_timepoints = [(0, 0)]\n",
    "\n",
    "stim_diff = np.diff(stim_arr[1, :])\n",
    "for t in range(stim_diff.shape[0]):\n",
    "    if stim_diff[t]<0 and stim_diff[t-1]==0:\n",
    "        offset_timepoints.append((t, stim_arr[0, t]))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crop bout probabilities after luminance offsets\n",
    "dt = stim_arr[0, :][1]\n",
    "pre_t_window = .5\n",
    "t_window = 3\n",
    "\n",
    "fish_offsets = np.empty((len(offset_timepoints), int((pre_t_window + t_window)/dt), fish_mean_bout_prob.shape[0]))\n",
    "\n",
    "for fish in range(fish_mean_bout_prob.shape[0]):\n",
    "    fish_offset_prob = np.empty((len(offset_timepoints), int((pre_t_window + t_window)/dt)))\n",
    "    \n",
    "    for offset in range(len(offset_timepoints)):\n",
    "        if offset_timepoints[offset][0] == 0:\n",
    "            fish_offset_prob[offset, :int(pre_t_window/dt)] = fish_mean_bout_prob[fish, -int(pre_t_window/dt):]\n",
    "            fish_offset_prob[offset, int(pre_t_window/dt):] = fish_mean_bout_prob[fish, :int(t_window/dt)]\n",
    "        else:\n",
    "            fish_offset_prob[offset, :] = fish_mean_bout_prob[fish, offset_timepoints[offset][0]-int(pre_t_window/dt):offset_timepoints[offset][0]+int(t_window/dt)]\n",
    "    \n",
    "    fish_offsets[:, :, fish] = fish_offset_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bout_window(offset_mat, t_window=3, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(4, 4))\n",
    "        \n",
    "    ax = add_offset_axes(figure, (0.15, 0.15, .8, .8), frame=frame) \n",
    "    \n",
    "    t_arr = np.arange(-pre_t_window, t_window, dt)\n",
    "    for fish in range(fish_offsets.shape[2]):\n",
    "        ax.plot(t_arr, np.nanmean(fish_offsets[:, :, fish], 0), c='gray', alpha=.5)\n",
    "    \n",
    "    ax.plot(t_arr, np.nanmean(np.nanmean(fish_offsets, 0), 1),  c='royalblue', linewidth=2)\n",
    "    ax.axvline(0, c='black', ls=':', lw=2)\n",
    "    ax.set_xlim([np.min(t_arr), np.max(t_arr)])\n",
    "    ax.set_ylabel('Mean bout Δprobability')\n",
    "    ax.set_xlabel('Time [s.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bout_window(fish_offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_window = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_triggers = [offset_timepoints[i][0] for i in range(len(offset_timepoints))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrapping for individual fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get REAL bout probabilities after luminance offset for each fish\n",
    "offset_bout_prob = np.empty((fish_mean_bout_prob.shape[0]))\n",
    "\n",
    "for fish in range(fish_mean_bout_prob.shape[0]):\n",
    "    fish_offset_prob = np.empty((len(offset_triggers), int(t_window/dt)))\n",
    "    \n",
    "    for offset in range(len(offset_timepoints)):\n",
    "        fish_offset_prob[offset, :] = fish_mean_bout_prob[fish, offset_triggers[offset]:offset_triggers[offset]+int(t_window/dt)]\n",
    "    \n",
    "    offset_bout_prob[fish] = np.nanmean(fish_offset_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of iterations and matrix to save data\n",
    "n_iterations = 1000\n",
    "fake_offset_bout_prob = np.empty((n_iterations, fish_mean_bout_prob.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create extended data matrix to avoid issues with datapoints picked from the end of the series\n",
    "fish_bout_prob_extended = np.empty((fish_mean_bout_prob.shape[0], fish_mean_bout_prob.shape[1]+int(t_window/dt)))\n",
    "\n",
    "for fish in range(fish_mean_bout_prob.shape[0]):\n",
    "    fish_bout_prob_extended[fish] = np.append(fish_mean_bout_prob[fish, :], fish_mean_bout_prob[fish, :int(t_window/dt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(n_iterations):\n",
    "    random_triggers = np.random.choice(range(fish_mean_bout_prob.shape[1]), len(offset_triggers), replace=False).tolist()\n",
    "    \n",
    "    for fish in range(fish_mean_bout_prob.shape[0]):\n",
    "        fake_fish_offset_prob = np.empty((len(random_triggers), int(t_window/dt)))\n",
    "        \n",
    "        for offset in range(len(random_triggers)):\n",
    "            fake_fish_offset_prob[offset, :] = fish_bout_prob_extended[fish, random_triggers[offset]:random_triggers[offset]+int(t_window/dt)]\n",
    "            \n",
    "        fake_offset_bout_prob[iteration, fish] = np.nanmean(fake_fish_offset_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_prob = 1 #in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot fish bootstrapped distributions\n",
    "bootstrapping_fig, axes = plt.subplots(math.ceil(all_fish_mat.shape[2]/5), 5, figsize=(10, 5))\n",
    "axes = np.ravel(axes)\n",
    "bootstrap_dict = {fish:{} for fish in range(fish_offsets.shape[2])}\n",
    "\n",
    "for fish in range(fish_offsets.shape[2]):\n",
    "    fish_fake_data = fake_offset_bout_prob[:, fish]\n",
    "    \n",
    "    #Plot histogram\n",
    "    axes[fish].set_title('fish {}'.format(fish+1))\n",
    "    axes[fish].hist(fish_fake_data, bins='auto', density=True)\n",
    "    \n",
    "    #Fit normal distribution\n",
    "    mu, std = stats.norm.fit(fish_fake_data)\n",
    "    xmin, xmax = axes[fish].get_xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = stats.norm.pdf(x, mu, std)\n",
    "    axes[fish].plot(x, p, 'k', linewidth=2)\n",
    "    axes[fish].text(.8, .8, '$\\mu$ = {:.4f} \\n$\\sigma$ = {:.4f}'.format(mu, std), fontsize=5, \n",
    "                    transform=axes[fish].transAxes)\n",
    "    \n",
    "    #Find variable value corresponding to the desired percentile\n",
    "    threshold_prob = 1 #in %\n",
    "    lower_bound = stats.norm.ppf(threshold_prob/100, mu, std)\n",
    "    axes[fish].axvline(lower_bound, c='red', ls='--')\n",
    "    axes[fish].text(.8, .7, '1%ile = {:.2f}'.format(lower_bound), fontsize=5, color='red', \n",
    "                    transform=axes[fish].transAxes, ha='left')\n",
    "\n",
    "    #Plot actual bout probability\n",
    "    axes[fish].axvline(offset_bout_prob[fish], c='green', linewidth=2)\n",
    "    axes[fish].text(.8, .6, 'P(bout) = {:.2f}'.format(offset_bout_prob[fish]), fontsize=5, color='green', \n",
    "                    transform=axes[fish].transAxes)\n",
    "    \n",
    "    #Save bootstrapping results\n",
    "    bootstrap_dict[fish]['mu'] = mu\n",
    "    bootstrap_dict[fish]['std'] = std\n",
    "    bootstrap_dict[fish]['1ile'] = lower_bound\n",
    "    bootstrap_dict[fish]['offset_prob'] = offset_bout_prob[fish]\n",
    "\n",
    "for i_ax, ax in enumerate(axes):\n",
    "    if i_ax >= fish_offsets.shape[2]:\n",
    "        ax.axis('off')\n",
    "        \n",
    "bootstrapping_fig.text(0.5, 0, 'Bout Δprobability', ha='center')\n",
    "bootstrapping_fig.text(0., 0.5, '# of occurences', va='center', rotation='vertical')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrapping for average P(bout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average bout probability during experiment\n",
    "mean_bout_prob = np.nanmean(fish_mean_bout_prob, 0)\n",
    "\n",
    "#Get REAL bout probabilities after luminance offset\n",
    "offset_bout_prob = np.empty((len(offset_triggers), int(t_window/dt)))\n",
    "    \n",
    "for offset in range(len(offset_timepoints)):\n",
    "    offset_bout_prob[offset, :] = mean_bout_prob[offset_triggers[offset]:offset_triggers[offset]+int(t_window/dt)]\n",
    "    \n",
    "mean_offset_bout_prob = np.nanmean(np.nanmean(offset_bout_prob, 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of iterations and matrix to save data\n",
    "n_iterations = 1000\n",
    "fake_offset_bout_prob = np.empty((n_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create extended data matrix to avoid issues with datapoints picked from the end of the series\n",
    "mean_bout_prob_extended = np.append(mean_bout_prob, mean_bout_prob[:int(t_window/dt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(n_iterations):\n",
    "    random_triggers = np.random.choice(range(mean_bout_prob.shape[0]), len(offset_triggers), replace=True).tolist()\n",
    "    \n",
    "    fake_mean_offset_bout_prob = np.empty((len(random_triggers), int(t_window/dt)))\n",
    "        \n",
    "    for offset in range(len(random_triggers)):\n",
    "        fake_mean_offset_bout_prob[offset, :] = mean_bout_prob_extended[random_triggers[offset]:random_triggers[offset]+int(t_window/dt)]\n",
    "\n",
    "    fake_offset_bout_prob[iteration] = np.nanmean(fake_mean_offset_bout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bootstrap(fake_bout_probs, real_bout_prob, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    ax = add_offset_axes(figure, (0.15, 0.15, .8, .8), frame=frame)\n",
    "    \n",
    "    #Plot histogram\n",
    "    ax.hist(fake_bout_probs, bins='auto', density=True, color='royalblue')\n",
    "    \n",
    "    #Fit normal distribution\n",
    "    mu, std = stats.norm.fit(fake_bout_probs)\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = stats.norm.pdf(x, mu, std)\n",
    "    ax.plot(x, p, 'k', linewidth=2)\n",
    "    ax.text(.8, .9, '$\\mu$ = {:.4f} \\n$\\sigma$ = {:.4f}'.format(mu, std), fontsize=7.5, \n",
    "                    transform=ax.transAxes)\n",
    "    \n",
    "    #Find variable value corresponding to the desired percentile\n",
    "    threshold_prob = 1 #in %\n",
    "    lower_bound = stats.norm.ppf(threshold_prob/100, mu, std)\n",
    "    ax.axvline(lower_bound, c='red', ls='--')\n",
    "    ax.text(lower_bound+0.002, ymax, 'P\\u2081 = {:.4f}'.format(lower_bound), fontsize=6, color='red', \n",
    "            ha='left', va='top')\n",
    "    \n",
    "    #Plot actual bout probability\n",
    "    ax.axvline(real_bout_prob, c='green', linewidth=2)\n",
    "    ax.text(mean_offset_bout_prob+0.002, ymax, 'P(bout|offset) \\n = {:.4f}'.format(real_bout_prob), fontsize=6, color='green', \n",
    "           ha='left', va='top')\n",
    "    \n",
    "    ax.set_xlabel('Bout ΔProbability')\n",
    "    ax.set_ylabel('# of occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bootstrap(fake_offset_bout_prob, mean_offset_bout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_fish_bootstrap(bootstrapping_dict, figure=None, frame=None):\n",
    "    \n",
    "#     if figure is None:\n",
    "#         figure = plt.figure(figsize=(6, 1.5))\n",
    "    \n",
    "#     ax = add_offset_axes(figure, (0.15, 0.25, 0.8, 0.7), frame=frame)\n",
    "\n",
    "#     fish_diff = []\n",
    "#     colors = []\n",
    "#     for fish in bootstrap_dict.keys():\n",
    "#         difference = bootstrapping_dict[fish]['offset_prob'] - bootstrapping_dict[fish]['1ile']\n",
    "#         fish_diff.append(difference)\n",
    "#         if difference < 0:\n",
    "#             colors.append('green')\n",
    "#         else:\n",
    "#             colors.append('red')\n",
    "        \n",
    "#     ax.scatter(np.arange(1, 16), fish_diff, color=colors)\n",
    "#     ax.axhline(0, ls='--', c='black', alpha=.5)\n",
    "    \n",
    "#     ax.set_xlabel('Fish')\n",
    "#     ax.set_ylabel('P(bout|offset) - P\\u2081')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fish_bootstrap(bootstrapping_dict, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(2, 3))\n",
    "    \n",
    "    c_pal_cols = ['red', 'grass green']\n",
    "    c_pal = sns.xkcd_palette(c_pal_cols)\n",
    "    \n",
    "    ax = add_offset_axes(figure, (0.5, 0.05, 0.5, 0.9), frame=frame)\n",
    "\n",
    "    fish_diff = []\n",
    "    colors = []\n",
    "    for fish in bootstrap_dict.keys():\n",
    "        difference = bootstrapping_dict[fish]['offset_prob'] - bootstrapping_dict[fish]['1ile']\n",
    "        fish_diff.append(difference)\n",
    "        if difference < 0:\n",
    "            colors.append('green')\n",
    "        else:\n",
    "            colors.append('red')\n",
    "    \n",
    "    x_pos = np.random.normal(1, .0025, len(fish_diff))\n",
    "    g = sns.swarmplot(x=np.full(len(fish_diff), 1), y=fish_diff, hue=colors, palette=c_pal)\n",
    "    ax.legend().remove()\n",
    "    ax.axhline(0, ls='--', c='black', alpha=.5)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylabel('P(bout|offset) - P\\u2081')\n",
    "    ax.spines['bottom'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fish_bootstrap(bootstrap_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figureS7 = plt.figure(figsize=(7, 9))\n",
    "\n",
    "#Bout prob plot:\n",
    "bout_prob_panel = plot_bout_prob(fish_mean_bout_prob, stim_arr, figure=figureS7, frame=(0.01, 0.4, 1, 0.65))\n",
    "figureS7.text(0.01, 0.95, 'A')\n",
    "\n",
    "#Bout prob window plot:\n",
    "bout_prob_win_panel = plot_bout_window(fish_offsets, figure=figureS7, frame=(0.025, 0.05, 0.4, 0.35))\n",
    "figureS7.text(0.005, 0.375, 'B')\n",
    "\n",
    "#Bootstrapping of average P(bout):\n",
    "avg_bootstrap_panel = plot_bootstrap(fake_offset_bout_prob, mean_offset_bout_prob, figure=figureS7, frame=(0.425, 0.05, 0.4, 0.35))\n",
    "figureS7.text(0.425, 0.375, 'C')\n",
    "\n",
    "#Individual fish bootstrapping:\n",
    "fish_bootstrap_panel = plot_fish_bootstrap(bootstrap_dict, figure=figureS7, frame=(0.885, 0.1, 0.125, 0.3))\n",
    "figureS7.text(0.85, 0.375, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    figureS7.savefig(str(fig_fold / \"behavior_supplementary.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flammkuchen as fl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from luminance_analysis import PooledData, traces_stim_from_path\n",
    "from ipywidgets import interact, fixed, interactive\n",
    "import ipywidgets as widgets\n",
    "\n",
    "plt.style.use(\"figures.mplstyle\")\n",
    "cols = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fold = Path(r\"C:\\Users\\otprat\\Documents\\figures\\luminance\\manuscript_figures\\fig7_v3\\all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path = Path(r\"\\\\FUNES\\Shared\\experiments\\E0032_luminance\\neat_exps\")\n",
    "# master_path = Path(r\"J:\\_Shared\\GC_IO_luminance\\data\\neat_exps\")\n",
    "# master_path = Path(r\"/Users/luigipetrucco/Desktop/data_dictionaries/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luminance_analysis.utilities import deconv_resamp_norm_trace, reliability, nanzscore, get_kernel\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree, to_tree, set_link_color_palette\n",
    "from luminance_analysis.plotting import plot_clusters_dendro, shade_plot, add_offset_axes, make_bar\n",
    "from luminance_analysis.clustering import cluster_id_search, find_trunc_dendro_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<luminance_analysis.FishData object at 0x0000013F1364FD48>, <luminance_analysis.FishData object at 0x0000013F1364FDC8>, <luminance_analysis.FishData object at 0x0000013F1365B948>, <luminance_analysis.FishData object at 0x0000013F13665148>, <luminance_analysis.FishData object at 0x0000013F13676908>]\n",
      "[<luminance_analysis.FishData object at 0x0000013F13653B88>, <luminance_analysis.FishData object at 0x0000013F13653B08>, <luminance_analysis.FishData object at 0x0000013F136612C8>, <luminance_analysis.FishData object at 0x0000013F13665C88>, <luminance_analysis.FishData object at 0x0000013F13676848>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\rplab\\lib\\site-packages\\numpy\\lib\\function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\tools\\miniconda3\\envs\\rplab\\lib\\site-packages\\numpy\\lib\\function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<luminance_analysis.FishData object at 0x0000013F14341088>, <luminance_analysis.FishData object at 0x0000013F14341108>, <luminance_analysis.FishData object at 0x0000013F1434D6C8>, <luminance_analysis.FishData object at 0x0000013F1435CC88>, <luminance_analysis.FishData object at 0x0000013F14345288>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89df07e7aa094ed8b3ba7a34476d36a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<luminance_analysis.FishData object at 0x0000013F144FB748>, <luminance_analysis.FishData object at 0x0000013F144FB7C8>, <luminance_analysis.FishData object at 0x0000013F144FCE48>, <luminance_analysis.FishData object at 0x0000013F145046C8>, <luminance_analysis.FishData object at 0x0000013F14515F08>]\n",
      "[<luminance_analysis.FishData object at 0x0000013F14501D88>, <luminance_analysis.FishData object at 0x0000013F14501D08>, <luminance_analysis.FishData object at 0x0000013F14504E88>, <luminance_analysis.FishData object at 0x0000013F14342808>, <luminance_analysis.FishData object at 0x0000013F1450F908>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8578512ea84b5cb26ffc13dafb2b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<luminance_analysis.FishData object at 0x0000013F13F24188>, <luminance_analysis.FishData object at 0x0000013F13F270C8>, <luminance_analysis.FishData object at 0x0000013F13F29248>, <luminance_analysis.FishData object at 0x0000013F13F2E3C8>, <luminance_analysis.FishData object at 0x0000013F13F32708>]\n",
      "[<luminance_analysis.FishData object at 0x0000013F13F27EC8>, <luminance_analysis.FishData object at 0x0000013F13F27D48>, <luminance_analysis.FishData object at 0x0000013F13F2E148>, <luminance_analysis.FishData object at 0x0000013F1451C1C8>, <luminance_analysis.FishData object at 0x0000013F13F42B08>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d840ccfe71423ca934e0fbc6b42a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tau_6f = 5\n",
    "tau_6s = 8\n",
    "ker_len = 20\n",
    "normalization = \"zscore\"\n",
    "protocol = 'steps'\n",
    "\n",
    "brain_regions_list = [\"GC\", \"IO\", \"PC\"]\n",
    "tau_list = [tau_6f, tau_6f, tau_6s]\n",
    "n_cluster_list = [8, 6, 8]\n",
    "nan_thr_list = [0, 1, 1]\n",
    "\n",
    "data_dict = {k:{} for k in brain_regions_list}\n",
    "\n",
    "#load stimulus of GCs and use it as a the reference for time array and stimulus array:\n",
    "stim_ref = PooledData(path = master_path / protocol / \"GC\").stimarray_rep\n",
    "\n",
    "for brain_region, tau, n_cluster, nan_thr in zip(brain_regions_list, tau_list, \n",
    "                                                 n_cluster_list, nan_thr_list):\n",
    "    #Load data :\n",
    "    path = master_path / protocol / brain_region\n",
    "    stim, traces, meanresps = traces_stim_from_path(path)\n",
    "\n",
    "    # Mean traces, calculate reliability index :\n",
    "    rel_idxs = reliability(traces)\n",
    "    \n",
    "    # Find threshold from reliability histogram...\n",
    "    rel_thr = threshold_otsu(rel_idxs[~np.isnan(rel_idxs)])\n",
    "\n",
    "    # ...and load again filtering with the threshold:\n",
    "    _, traces, meanresps = traces_stim_from_path(path, resp_threshold=rel_thr, nanfraction_thr=nan_thr)\n",
    "\n",
    "    # Hierarchical clustering:\n",
    "    linked = linkage(meanresps, 'ward')\n",
    "    \n",
    "    # Truncate dendrogram at n_cluster level:\n",
    "    plt.figure(figsize=(0.1, 0.1))  \n",
    "    dendro = dendrogram(linked, n_cluster, truncate_mode =\"lastp\")\n",
    "    plt.close()\n",
    "    cluster_ids = dendro[\"leaves\"]\n",
    "    labels = find_trunc_dendro_clusters(linked, dendro) \n",
    "    \n",
    "    # Deconvolution, resampling / normalization:\n",
    "    deconv_meanresps = np.empty((meanresps.shape[0], stim_ref.shape[0]))\n",
    "    resamp_meanresps = np.empty((meanresps.shape[0], stim_ref.shape[0]))\n",
    "    for roi_i in range(deconv_meanresps.shape[0]):\n",
    "        deconv_meanresps[roi_i, :] = deconv_resamp_norm_trace(meanresps[roi_i, :], stim[:, 0],\n",
    "                                                                stim_ref[:, 0], tau, ker_len,\n",
    "                                                                smooth_wnd=4,\n",
    "                                                                normalization=normalization)\n",
    "        resamp_meanresps[roi_i, :] = deconv_resamp_norm_trace(meanresps[roi_i, :], stim[:, 0],\n",
    "                                                                stim_ref[:, 0], None, ker_len,\n",
    "                                                                smooth_wnd=4,\n",
    "                                                                normalization=normalization)\n",
    "    \n",
    "    cluster_resps = np.empty((n_cluster, stim_ref.shape[0]))\n",
    "    for clust_i in range(n_cluster):\n",
    "        cluster_resp = np.nanmean(deconv_meanresps[labels==clust_i, :], 0)  # average cluster responses\n",
    "        cluster_resps[clust_i, :] = nanzscore(cluster_resp)  # normalize\n",
    "\n",
    "\n",
    "    # Add everything to dictionary:\n",
    "    data_dict[brain_region][\"linkage_mat\"] = linked\n",
    "    data_dict[brain_region][\"clust_labels\"] = labels\n",
    "    #data_dict[brain_region][\"raw_mn_resps\"] = meanresps\n",
    "    data_dict[brain_region][\"traces\"] = traces\n",
    "    #data_dict[brain_region][\"deconv_mn_resps\"] = deconv_meanresps\n",
    "    #data_dict[brain_region][\"resamp_mn_resps\"] = resamp_meanresps\n",
    "    data_dict[brain_region][\"rel_idxs\"] = rel_idxs[rel_idxs > rel_thr]\n",
    "    data_dict[brain_region][\"rel_thr\"] = rel_thr\n",
    "    data_dict[brain_region][\"clust_resps\"] = cluster_resps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the model\n",
    "\n",
    "\n",
    "The goal of the model is to reconstruct the activity of PCs based on the activity observed for GCs and IONs.\n",
    "The function that we will use to model a PC is the following:\n",
    "$$ trace_{PC}^i = o^i + clusters_{GC} * w^i_{GC} + clusters_{IO} * w^i_{IO}$$\n",
    "\n",
    "\n",
    " - $trace_{PC}^i$ is the $i^{th}$ PC cell trace;\n",
    " - $o^i$ is an offset term:\n",
    " - $clusters_{GC}$, $clusters_{IO}$ are matrices with the average activation of all GC&IO clusters;\n",
    " - $w^i_{GC}$, $w^i_{IO}$ are weights vectors for each of the GC and IO cluster. We will allow positive and negative $w^i_{GC}$, but only positive $w^i_{IO}$. This is a quite safe assumption considering the known PC physiology. \n",
    "\n",
    "\n",
    "### Approach\n",
    "\n",
    "Here is a summary of the modelling approach:\n",
    "- **Create a panel of regressors**:\n",
    "    - Calculate clusters of GC and IO responses; \n",
    "    - Deconvolve average response of each cluster with 6fe05 kernel;\n",
    "    - Reconvolve it with 6s kernel;\n",
    "    - Normalize it to be  > 0, and with integral = 1.\n",
    "\n",
    "\n",
    "- **Clean up PC traces**:\n",
    "    - For each cell, take raw fluorescence if valid trials, and zscore them on a trial-to-trial base (for changes in offset F across planes);\n",
    "    - concatenate repetitions;\n",
    "    - high-pass filter them with very low cutoff freq (1/80 Hz) to remove slow fluctuations;\n",
    "    - smooth them with a 3 pts mean boxcar rolling window;\n",
    "    \n",
    "    \n",
    "- **Split fit and test data**:\n",
    "    - Randomly pick from each cell:\n",
    "        - 2 repetitions that will be left out for the analysis (**test traces**);\n",
    "        - 4 repetitions (or more, if there are more planes) that will be used for finding the regularization term and for the actual fitting (**fit traces**);\n",
    "\n",
    "\n",
    "- **Define boundaries, cost function and regularization function**:\n",
    "    - Parameters to be optimized are:\n",
    "        - *offset*: a constant term, bound to be between -5 and 5;\n",
    "        - *coefs_GC*: coefficients for GC regressors, bound to be between -1000 and 1000 (the large difference comes from the different normalizations applied on regressors -norm- and on trace - Z scoring)\n",
    "        - *coefs_IO*: coefficients for GC regressors, bound to be between 0 and 1000, as we have good reasons to postulate that IO contributions are strictly positive\n",
    "        - cost function: L2 distance to target trace;\n",
    "        - regularization function: L1 (sum of absolute value of parameters)\n",
    "        \n",
    "        \n",
    "- **Find regularization parameter**:\n",
    "    - Find regularization parameter (leave one out cross-validation):\n",
    "    - For each lambda parameter, train the model on all the fit traces but one (**train traces**);\n",
    "    - Then, calculate the cost of the fit on the one trace that was left out (**validation trace**);\n",
    "    - Do this iterating over all possible combinations of n-1 and 1 traces;\n",
    "    - Calculate average cross over all combinations, over all cells;\n",
    "\n",
    "\n",
    "- **Fit the trace**:\n",
    "    - Use the resulting regularization term for fitting the fit repetitions, and use the obtained coefficients for plots / further analyses on the test repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a panel of regressors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create regressor panel, making traces non-0 and with integral equal to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gc_clust = data_dict[\"GC\"][\"clust_resps\"].shape[0]\n",
    "n_io_clust = data_dict[\"IO\"][\"clust_resps\"].shape[0]\n",
    "regressors_mat = np.concatenate([data_dict[\"GC\"][\"clust_resps\"], data_dict[\"IO\"][\"clust_resps\"]])\n",
    "\n",
    "# Reconvolve and normalize regressors:\n",
    "for i in range(regressors_mat.shape[0]):\n",
    "    reconvolved = np.convolve(regressors_mat[i, :], get_kernel(ker_len=100, tau=tau_6s))[:regressors_mat.shape[1]]\n",
    "    \n",
    "    # Make strictly positive and with integral == 1:\n",
    "    reconvolved -= np.min(reconvolved)  # offset at 0\n",
    "    regressors_mat[i, :] = reconvolved / np.sum(reconvolved)\n",
    "\n",
    "# Arbitrary cluster names (do we need them?):\n",
    "gc_cluster_names = ['ON 1', 'ON 2', 'ON abs', 'ON inter.1', 'ON inter.2', 'OFF 1', 'OFF 2', 'OFF inter.']\n",
    "io_cluster_names = ['Onset', 'ON max', 'Offset 1', 'Offset 2', 'On inter.', 'Offset 3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the regressors panel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regressor panel:\n",
    "def reg_panel_plot(regressors_mat, figure=None, ax=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3, 3))\n",
    "\n",
    "    offset = 0.01\n",
    "    if ax is None:\n",
    "        ax = add_offset_axes(figure, (0., 0., 1, 1), frameon=False, frame=frame)\n",
    "    cols = sns.color_palette()\n",
    "    for i, col in enumerate([cols[0], ]*n_gc_clust + [cols[1], ]*n_io_clust):\n",
    "        ax.fill_between(stim[:, 0], np.zeros(stim[:, 0].shape) - i*offset, \n",
    "                        regressors_mat[i, :] - i*offset, color=col)\n",
    "        \n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7c124b51d34d9184495177dd9ebe42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_panel_plot(regressors_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up PC traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luminance_analysis.utilities import smooth_traces, butter_highpass_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cell_rep_block(cellmat, cutoff=1/80, smooth_wnd=3):\n",
    "    \"\"\" Filter traces from the raw traces block.\n",
    "    Return a repetitions block containing only the valid repetitions.\n",
    "    \"\"\"\n",
    "    cutoff = 1 / 80\n",
    "    dt = stim[1, 0]\n",
    "    \n",
    "    # Select entries with valid numbers in the repetition matrix:\n",
    "    cellmat = cellmat[:, ~np.isnan(cellmat).all(0)].copy()\n",
    "    \n",
    "    # zscore repetition-wise, important for ROIs spanning more than one plane\n",
    "    cellmat = (cellmat - np.nanmean(cellmat, 0)) / np.nanstd(cellmat, 0)\n",
    "    \n",
    "    # concatenate, highpass filter with very low cutoff, and smooth:\n",
    "    trace = np.concatenate(cellmat.T, 0)\n",
    "    filtered = butter_highpass_filter(trace, cutoff, 1 / dt)  # filt trace\n",
    "    filtered = smooth_traces(filtered[np.newaxis, :], win=3, method=\"mean\")[0, :]  # smooth\n",
    "    filtered[np.isnan(filtered)] = 0\n",
    "    \n",
    "    # reshape in original form, and zscore again after filtering and smoothing:\n",
    "    reshaped = filtered.reshape(cellmat.T.shape).T  \n",
    "    reshaped = (reshaped - np.nanmean(reshaped, 0))/np.nanstd(reshaped, 0)\n",
    "    \n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup parameters:\n",
    "cutoff_hz = 1 / 80  # long cutoff for highpass filter - remove long fluctuations in PC signal\n",
    "smooth_wnd = 3  # smoothing window to reduce noise. Our data is sampled ar around 0.25 seconds\n",
    "\n",
    "raw_traces = data_dict[\"PC\"][\"traces\"]  # raw PC fluorescences\n",
    "rel_idxs = data_dict[\"PC\"][\"rel_idxs\"]  # reliability indexes for each PC cell\n",
    "\n",
    "n_rois = raw_traces.shape[0]  # number of ROIs\n",
    "n_rep_timepts = raw_traces.shape[1]  # timepoints per repetition\n",
    "n_reps_max = raw_traces.shape[2]  # maximum number of repetitions in a cell\n",
    "\n",
    "# Find number of valid repetitions for each cell:\n",
    "n_valid_reps = (~np.isnan(raw_traces).all(1)).sum(1)\n",
    "\n",
    "# Clean up:\n",
    "clean_traces = np.full(raw_traces.shape, np.nan)\n",
    "for i_roi in range(n_rois):\n",
    "    clean_block = filter_cell_rep_block(raw_traces[i_roi, :, :], cutoff=cutoff_hz, smooth_wnd=smooth_wnd)\n",
    "    clean_traces[i_roi, :, :n_valid_reps[i_roi]] = clean_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a trace panel:\n",
    "def little_trace_plot(clean_traces, i=0, figure=None, ax=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3, 1))\n",
    "\n",
    "    if ax is None:\n",
    "        ax = add_offset_axes(figure, (0., 0., 1, 1), frameon=False, frame=frame)\n",
    "    offset = 0.01\n",
    "    plt.plot(clean_traces[i, :, :1].T.flatten())\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89a88b850764da2aedd48721e43a583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "little_trace_plot(clean_traces, i=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate testing and training traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix randomness for reproducibility:\n",
    "np.random.seed(572704)\n",
    "seed(572704)\n",
    "\n",
    "# Generate list of 2 indexes for each cell which will be used to keep traces out for the testing part.\n",
    "# Generate randomly indexes for test and train set of traces:\n",
    "n_test_reps = 3\n",
    "\n",
    "test_idxs = []\n",
    "fit_idxs = []\n",
    "for n_resps in n_valid_reps:\n",
    "    idxs = np.arange(n_resps)  # possible repetitions indexes\n",
    "    shuffle(idxs)  # shuffle index list\n",
    "    test_idxs.append(idxs[:n_test_reps])  # test idxs will be the first 2\n",
    "    fit_idxs.append(idxs[n_test_reps:])  # the rest goes for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define boundaries, function & regularisation/cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for the regression.\n",
    "\n",
    "# This is the the main function that we actually use to describe PC activity:\n",
    "def offset_cluster_combine(coefs, regressors):\n",
    "    \"\"\" Compute trace from offset/coefficients and regressors.\n",
    "    It assumes coefs and regressors for GC and IO are all concatenated,\n",
    "    and first element of coefs array is the offset.\n",
    "    \"\"\"\n",
    "    return coefs[0] + np.sum(coefs[1:] * regressors, 1)  # first term is baseline\n",
    "\n",
    "def cost_func(fit_coefs, regressors, trace2fit, model):\n",
    "    \"\"\" Cost function: sum of squares.\n",
    "    \"\"\"\n",
    "    diff = trace2fit - model(fit_coefs, regressors)\n",
    "    return np.sum(diff**2) / trace2fit.shape[0]\n",
    "\n",
    "def reg_func(fit_coefs, reg_coef=0):\n",
    "    \"\"\" Regularization function: sum of absolute coefs values.\n",
    "    Does not regularize the offset, so first term is excluded:\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(fit_coefs[1:]))\n",
    "\n",
    "def minimization_func(fit_coefs, regressors, trace2fit, model, cost_func, reg_func, reg_lamda=0):\n",
    "    \"\"\"Full function to minimize, including cost and regularization terms.\n",
    "    \"\"\"\n",
    "    return cost_func(fit_coefs, regressors, trace2fit, model) + reg_func(fit_coefs) * reg_lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set starting values and bounds for the offset (the +1 below) and the coefficients.\n",
    "\n",
    "# Initial guesses:\n",
    "# coefs_init_guess = np.zeros(regressors_mat.shape[0] + 1) \n",
    "\n",
    "# We know that IO input can only positively contribute to PC activity, \n",
    "# so we set IO coefficients to be positive:\n",
    "# w_bound = 1000  # bound for regressors weights (high b/c of normalization differences) \n",
    "# off_bound = 5  # bound for the offset\n",
    "# coefs_bounds =[(-off_bound, off_bound)] + \\\n",
    "#               [(0, w_bound) for _ in range(n_gc_clust)] + \\\n",
    "#               [(0, w_bound) for _ in range(n_io_clust)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test for the optimal regularization lambda. As this parameter search can take quite long, you can just skip the section and execute from the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = ['GC', 'IO']\n",
    "\n",
    "regressors_mat_dict = {'GC': regressors_mat[:n_cluster_list[0], :],\n",
    "                       'IO': regressors_mat[-n_cluster_list[1]:, :]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the cost of a fit with all 0 coefficients is 1 - the std of the trace (which is zscored),\n",
    "# this will be our estimation of the cost that we use to decide the regularization lambda range \n",
    "# (2 orders of mag below and above the expected cost):\n",
    "reg_lambda_arr = np.insert(10**np.arange(-7., -2, 0.35), 0, 0)\n",
    "\n",
    "# Initialise empty matrices for storing the costs and the lambda parameters for all left-one-out fits:\n",
    "n_lambdas = reg_lambda_arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n"
     ]
    }
   ],
   "source": [
    "costs = {cell_type:np.full((n_rois, n_lambdas, n_reps_max - n_test_reps), np.nan) for cell_type in cell_types}\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    \n",
    "    coefs_init_guess = np.zeros(regressors_mat_dict[cell_type].shape[0] + 1) \n",
    "    \n",
    "    # Prepare a concatenation of regressors long enough to fit the longest possible trace:\n",
    "    regressors_concat = np.concatenate([regressors_mat_dict[cell_type],]*(n_reps_max - n_test_reps), 1).T\n",
    "    \n",
    "    # Use scikit learn leave-one-out iterator:\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    n_downsample = 1  # skip cells if we are testing. Otherwise, set to 1\n",
    "\n",
    "    for i_roi in range(0, n_rois, n_downsample):\n",
    "        if np.mod(i_roi, 50) == 0:\n",
    "            print(i_roi)\n",
    "        roi_fit_idxs = fit_idxs[i_roi]\n",
    "\n",
    "        # Hyperparameter grid search:\n",
    "        for i_lambda, reg_lambda in enumerate(reg_lambda_arr):\n",
    "\n",
    "            # Leave-one-out validation:\n",
    "            for i_loo, (idxs_train, idxs_valid) in enumerate(loo.split(roi_fit_idxs)):\n",
    "                roi_train_trace = clean_traces[i_roi, :, roi_fit_idxs[idxs_train]].flatten()\n",
    "                roi_valid_trace = clean_traces[i_roi, :, roi_fit_idxs[idxs_valid[0]]]\n",
    "                res = optimize.minimize(minimization_func, method='SLSQP', \n",
    "                                        args=(regressors_concat[:roi_train_trace.shape[0], :], \n",
    "                                              roi_train_trace, offset_cluster_combine, \n",
    "                                              cost_func, reg_func, reg_lambda),\n",
    "                                        x0=coefs_init_guess, bounds=None)\n",
    "\n",
    "                costs[cell_type][i_roi, i_lambda, i_loo] = cost_func(res.x, regressors_concat[:roi_valid_trace.shape[0], :], \n",
    "                                                          roi_valid_trace, offset_cluster_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061cf49c0d91438690aa81ce5e95155f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "\n",
    "for ax, cell_type, col in zip(axes, cell_types, cols[:2]):\n",
    "    cost_arr_mean = np.nanmean(costs[cell_type], 2)\n",
    "    \n",
    "    ax.plot(range(n_lambdas), np.nanmean(cost_arr_mean, 0), c=col)\n",
    "    ax.fill_between(range(n_lambdas), \n",
    "                    np.nanmean(cost_arr_mean, 0)-np.nanstd(cost_arr_mean, 0),\n",
    "                    np.nanmean(cost_arr_mean, 0)+np.nanstd(cost_arr_mean, 0), color=col, alpha=.2, edgecolor=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'reg_opti_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_within_std_err(cell_costs):\n",
    "    mean_cost = np.nanmean(cell_costs, 1)\n",
    "    std_err_cost = np.nanstd(cell_costs, 1) / np.sqrt(np.sum(~np.isnan(cell_costs[0, :])) - 1)\n",
    "\n",
    "    min_idx = np.argmin(mean_cost)\n",
    "    std_err_min = std_err_cost[min_idx]\n",
    "\n",
    "    i = min_idx\n",
    "    while i < len(mean_cost) - 1 and mean_cost[i + 1] < mean_cost[min_idx] + std_err_min:\n",
    "        i += 1\n",
    "    \n",
    "    if i != len(mean_cost) and mean_cost[i] < 1:\n",
    "        return i\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "costs_final = {cell_type: np.full(n_rois, np.nan) for cell_type in cell_types}  # Costs of our final fit\n",
    "coefs_final = {cell_type: np.full((n_rois, regressors_mat_dict[cell_type].shape[0] + 1), np.nan) for cell_type in cell_types}  # Coefs from our final fit\n",
    "valid_roi_idxs = {cell_type:[] for cell_type in cell_types}\n",
    "\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    \n",
    "    #Set initial guesses\n",
    "    coefs_init_guess = np.zeros(regressors_mat_dict[cell_type].shape[0] + 1) \n",
    "    \n",
    "    #Prepare a concatenation of regressors long enough to fit the longest possible trace:\n",
    "    regressors_concat = np.concatenate([regressors_mat_dict[cell_type],]*(n_reps_max - n_test_reps), 1).T\n",
    "\n",
    "    \n",
    "    for i_roi in range(n_rois):\n",
    "        if np.mod(i_roi, 100) == 0:\n",
    "            print(i_roi)\n",
    "        cost_idx = max_within_std_err(costs[cell_type][i_roi, :, :])\n",
    "\n",
    "        if not np.isnan(cost_idx):\n",
    "            final_lambda_reg = reg_lambda_arr[cost_idx]\n",
    "\n",
    "            # Get test and fit indexes and traces:\n",
    "            roi_test_idxs = test_idxs[i_roi]\n",
    "            roi_test_trace = clean_traces[i_roi, :, roi_test_idxs].flatten()\n",
    "\n",
    "            roi_fit_idxs = fit_idxs[i_roi]\n",
    "            roi_fit_trace = clean_traces[i_roi, :, roi_fit_idxs].flatten()  \n",
    "\n",
    "            # Fit the train set:\n",
    "            res = optimize.minimize(minimization_func, method='SLSQP', \n",
    "                                    args=(regressors_concat[:roi_fit_trace.shape[0], :], \n",
    "                                          roi_fit_trace, offset_cluster_combine, \n",
    "                                          cost_func, reg_func, final_lambda_reg),\n",
    "                                    x0=coefs_init_guess, bounds=None)\n",
    "\n",
    "            # Calculate cost on the test set:\n",
    "            costs_final[cell_type][i_roi] = cost_func(res.x, regressors_concat[:roi_test_trace.shape[0], :], \n",
    "                                                      roi_test_trace, offset_cluster_combine)\n",
    "            # Save the coefficients:\n",
    "            coefs_final[cell_type][i_roi, :] = res.x\n",
    "\n",
    "            valid_roi_idxs[cell_type].append(i_roi)\n",
    "            \n",
    "valid_roi_idxs_dict = {cell_type: np.array(valid_roi_idxs[cell_type]) for cell_type in cell_types}\n",
    "n_valid_rois = {cell_type: len(valid_roi_idxs[cell_type]) for cell_type in cell_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep data only from properly fit ROIs\n",
    "coefs_final_sel = {} \n",
    "costs_final_sel = {} \n",
    "clean_traces_sel = {} \n",
    "test_idxs_sel = {}\n",
    "fit_idxs_sel = {}\n",
    "rel_idx_sel = {}\n",
    "clust_lab_sel = {}\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    coefs_final_sel[cell_type] = coefs_final[cell_type][valid_roi_idxs[cell_type], :]\n",
    "    costs_final_sel[cell_type] = costs_final[cell_type][valid_roi_idxs[cell_type]]\n",
    "    clean_traces_sel[cell_type] = clean_traces[valid_roi_idxs[cell_type], :, :]\n",
    "    test_idxs_sel[cell_type] = [test_idxs[i] for i in valid_roi_idxs[cell_type]]\n",
    "    fit_idxs_sel[cell_type] = [fit_idxs[i] for i in valid_roi_idxs[cell_type]]\n",
    "    rel_idx_sel[cell_type] = data_dict[\"PC\"][\"rel_idxs\"][valid_roi_idxs[cell_type]]\n",
    "    clust_lab_sel[cell_type] = data_dict[\"PC\"][\"clust_labels\"][valid_roi_idxs[cell_type]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting with shuffled coefficients to set a random fit baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_shuf = {cell_type: np.full_like(coefs_final_sel[cell_type], np.nan) for cell_type in cell_types}\n",
    "costs_shuf = {cell_type: np.full(n_valid_rois[cell_type], np.nan) for cell_type in cell_types}  # Costs from shuffled weights\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    \n",
    "    #Prepare a concatenation of regressors long enough to fit the longest possible trace:\n",
    "    regressors_concat = np.concatenate([regressors_mat_dict[cell_type],]*(n_reps_max - n_test_reps), 1).T\n",
    "    \n",
    "    for i in range(coefs_final_sel[cell_type].shape[1]):\n",
    "        shuf_idx = np.random.permutation(coefs_final_sel[cell_type].shape[0])\n",
    "        coefs_shuf[cell_type][:, i] = coefs_final_sel[cell_type][shuf_idx, i]\n",
    "    \n",
    "    for i_roi in range(n_valid_rois[cell_type]):\n",
    "    \n",
    "        # Get test and fit indexes and traces:\n",
    "        roi_test_idxs = test_idxs_sel[cell_type][i_roi]\n",
    "        roi_test_trace = clean_traces_sel[cell_type][i_roi, :,roi_test_idxs].flatten()\n",
    "        \n",
    "        # Calculate cost on the test set with shuffled weights:\n",
    "        costs_shuf[cell_type][i_roi] = cost_func(coefs_shuf[cell_type][i_roi, :], regressors_concat[:roi_test_trace.shape[0], :], \n",
    "                                                 roi_test_trace, offset_cluster_combine)\n",
    "\n",
    "cost_threshold = {cell_type: np.percentile(costs_shuf[cell_type], 5) for cell_type in cell_types}\n",
    "sel_fit = {cell_type: np.argwhere(costs_final_sel[cell_type] < cost_threshold[cell_type])[:, 0] for cell_type in cell_types}\n",
    "n_valid_rois = {cell_type: len(sel_fit[cell_type]) for cell_type in cell_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieve original indexes of ROIs with a good fitting\n",
    "inclusion_mask = {cell_type: costs_final_sel[cell_type] < cost_threshold[cell_type] for cell_type in cell_types}\n",
    "final_sel_idxs = {cell_type:{} for cell_type in cell_types}\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    final_sel_idxs[cell_type] = np.array(valid_roi_idxs[cell_type])[inclusion_mask[cell_type]]\n",
    "    \n",
    "#And find ROIs with a good fitting with both GC and IO regressors\n",
    "total_fit_idxs = np.intersect1d(final_sel_idxs['GC'], final_sel_idxs['IO'])\n",
    "total_fit_idxs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_figure(costs_final, costs_shuf, cost_threshold, ax_coefs=None, frame=None):\n",
    "    \n",
    "    bin_array = np.arange(0.01, 1.6, 0.05)\n",
    "    costs_shuf_hist, b = np.histogram(costs_shuf, bin_array)\n",
    "    costs_final_hist, b = np.histogram(costs_final, bin_array)\n",
    "    costs_final_sel_hist, b = np.histogram(costs_final[costs_final < cost_threshold], bin_array)\n",
    "    \n",
    "    sel_fract = np.nansum(costs_final < cost_threshold) / np.sum(~np.isnan(costs_final))\n",
    "    \n",
    "    if ax_coefs is None:\n",
    "        figure = plt.figure(figsize=(3.,2))\n",
    "        ax_coefs = add_offset_axes(figure, (0.2, 0.2, 0.7, 0.7), frame=frame)\n",
    "            \n",
    "    a = 0.7\n",
    "    x = (bin_array[1:] + bin_array[:-1]) / 2\n",
    "    ax_coefs.fill_between(x, costs_shuf_hist, step=\"mid\", alpha=a, edgecolor=None, facecolor=sns.color_palette()[4])\n",
    "    ax_coefs.fill_between(x, costs_final_sel_hist, step=\"mid\", alpha=a, edgecolor=None, facecolor=sns.color_palette()[3])\n",
    "    ax_coefs.step(x, costs_final_hist, where=\"mid\", alpha=a, color=sns.color_palette()[3])\n",
    "    \n",
    "    ax_coefs.axvline(cost_threshold, c=(0.4,)*3)\n",
    "    ax_coefs.text(0.05, .95, '{:.2f}% PCs'.format(sel_fract*100), transform=ax_coefs.transAxes, c=sns.color_palette()[3], ha='left', fontsize=8.5)\n",
    "    ax_coefs.set_xlabel(\"Cost (on test)\")\n",
    "    ax_coefs.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6e70fd285c4405823e59d1d253fe70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(1, 0.45, 'Shuffled fits')"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "\n",
    "for ax, cell_type in zip(axes, cell_types):\n",
    "    cost_figure(costs_final[cell_type], costs_shuf[cell_type], cost_threshold[cell_type], ax_coefs=ax)\n",
    "    ax.set_title('Fitting cost with {} regressors'.format(cell_type), c=(0.4,)*3)\n",
    "    \n",
    "axes[1].text(1, .5, 'Regressor fits', transform=axes[1].transAxes, c=sns.color_palette()[3], ha='left', va='top', fontsize=8.5)\n",
    "axes[1].text(1, .45, 'Shuffled fits', transform=axes[1].transAxes, c=sns.color_palette()[4], ha='left', va='top', fontsize=8.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'fitting_costs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI fit explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roi_fits(roi_idx):\n",
    "    gc_fit_rank = ((np.argwhere(np.argsort(costs_final['GC']) == roi_idx)[0][0])/n_rois)*100\n",
    "    io_fit_rank = ((np.argwhere(np.argsort(costs_final['IO']) == roi_idx)[0][0])/n_rois)*100\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
    "\n",
    "    #Find train-test trials\n",
    "    roi_test_idxs = test_idxs[roi_idx]\n",
    "    test_traces = clean_traces[roi_idx, :, roi_test_idxs]\n",
    "\n",
    "    #Recover traces\n",
    "    roi_fit_idxs = fit_idxs[roi_idx]\n",
    "    fit_traces = clean_traces[roi_idx, :, roi_fit_idxs]\n",
    "\n",
    "    #Recover fit coefficients\n",
    "    gc_coefs = coefs_final['GC'][roi_idx, :]\n",
    "    io_coefs = coefs_final['IO'][roi_idx, :]\n",
    "\n",
    "    #Reconstruct fits\n",
    "    gc_fit = offset_cluster_combine(gc_coefs, regressors_mat_dict['GC'].T)\n",
    "    io_fit = offset_cluster_combine(io_coefs, regressors_mat_dict['IO'].T)\n",
    "\n",
    "    for row, traces in zip(range(2), [fit_traces, test_traces]):\n",
    "        for col, fit in zip(range(2), [gc_fit, io_fit]):\n",
    "            for rep in range(traces.shape[0]):\n",
    "                axes[row, col].plot(traces[rep, :], 'gray', alpha=.2)\n",
    "            axes[row, col].plot(np.nanmean(traces, 0), c=cols[2])\n",
    "            axes[row, col].plot(fit, c=cols[col])\n",
    "\n",
    "\n",
    "        for row, label in zip(range(2), ['Training set', 'Test set']):\n",
    "            axes[row, 0].set_ylabel(label, c='gray')\n",
    "\n",
    "        for col, title, rank in zip(range(2), ['GC regressors', 'IO regressors'], [gc_fit_rank, io_fit_rank]):\n",
    "            axes[0, col].set_title('{} (best {:.2f}%)'.format(title, rank), c='gray')\n",
    "\n",
    "    plt.suptitle('ROI {} fits'.format(roi_idx), c='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaa3db0ce284bb5ad1e9a2cae238b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='roi_idx', max=672), Output()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_roi_fits(roi_idx)>"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_roi_fits,\n",
    "         roi_idx=widgets.IntSlider(min=0, max=n_rois, step=1, continuous_update=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298eecaaf0374ad581fa108e674376f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roi_fits(np.argsort(costs_final['GC'])[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'best_GC_fit.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefs_plot(clust_lab, coefs_final, cell_type, col, ax_coefs=None, frame=None):\n",
    "    \n",
    "    if ax_coefs is None:\n",
    "        figure = plt.figure(figsize=(4, 3))\n",
    "        ax_coefs = add_offset_axes(figure, (0.05, 0.2, 0.75, 0.8), frame=frame)\n",
    "    \n",
    "    idxs_sort = np.argsort(clust_lab)\n",
    "\n",
    "    c_lim = 125\n",
    "    im = ax_coefs.imshow(coefs_final[idxs_sort, 1:].T, vmin=-c_lim, vmax=c_lim, aspect=\"auto\", cmap=\"RdBu\")\n",
    "    ax_coefs.set_xlabel(\"Roi n.\")\n",
    "\n",
    "    ax_coefs.set_yticks([])\n",
    "    ax_coefs.set_ylabel('{}'.format(cell_type), rotation=90, c=col)\n",
    "    [ax_coefs.axes.spines[s].set_visible(False) for s in\n",
    "         [\"left\", \"right\", \"top\", \"bottom\"]]\n",
    "    for ytick, color in zip(ax_coefs.get_yticklabels(), sns.color_palette()[:2]):\n",
    "        ytick.set_color(color)\n",
    "\n",
    "    k = np.sum(clust_lab == 0)\n",
    "    for n in range(1, clust_lab.max() + 1): \n",
    "        ax_coefs.axvline(k, c='black')\n",
    "        k += np.sum(clust_lab == n)\n",
    "        \n",
    "#     axcolor = add_offset_axes(figure, [0.86, 0.2, 0.02, 0.12], frame=frame)\n",
    "#     cbar = plt.colorbar(im, orientation=\"vertical\")\n",
    "#     cbar.set_ticks([-c_lim, c_lim])\n",
    "#     cbar.ax.tick_params(length=3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b88c0c4491f42e7bc93e59d8c512953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, axes = plt.subplots(1, 2, figsize=(7, 3))\n",
    "\n",
    "for ax, cell_type, c in zip(axes, cell_types, range(2)):\n",
    "    im = coefs_plot(clust_lab_sel[cell_type], coefs_final_sel[cell_type], cell_type, col=cols[c], ax_coefs=ax)\n",
    "    \n",
    "cbar = figure.colorbar(im, ax=ax, orientation='vertical', shrink=.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure.savefig(fig_fold/'fitting_coefs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check error histogram and relationship with cell reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check error of the fit as a function of the cell reliability index. We expect a negative relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5cfebfc434472d82c906a83bcdb2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7, 3), sharey=True)\n",
    "\n",
    "for ax, cell_type, c in zip(axes, cell_types, range(2)):\n",
    "    ax.scatter(rel_idxs, costs_final[cell_type], c='none', edgecolors=cols[c], linewidths=.25, s=7)\n",
    "    ax.scatter(rel_idxs[final_sel_idxs[cell_type]], costs_final[cell_type][final_sel_idxs[cell_type]], c=cols[c], s=7)\n",
    "    \n",
    "#     error_vs_reliabil(rel_idx_sel[cell_type], costs_final_sel[cell_type], ax, c=cols[c])\n",
    "    \n",
    "for ax, cell_type in zip(axes, cell_types):\n",
    "    ax.set_title('Fits with {} regressors'.format(cell_type), c='gray', fontsize=10)\n",
    "    ax.set_xlabel(\"Reliability idx\", fontsize=8.5)\n",
    "    ax.set_ylabel(\"Fit error\", fontsize=8.5)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2, figsize=(7, 3), sharey=True)\n",
    "\n",
    "# for ax, cell_type, c in zip(axes, cell_types, range(2)):\n",
    "#     ax.scatter(rel_idx_sel[cell_type], costs_final_sel[cell_type], c=cols[c], s=5)\n",
    "    \n",
    "# #     error_vs_reliabil(rel_idx_sel[cell_type], costs_final_sel[cell_type], ax, c=cols[c])\n",
    "    \n",
    "# for ax, cell_type in zip(axes, cell_types):\n",
    "#     ax.set_title('Fits with {} regressors'.format(cell_type), c='gray', fontsize=10)\n",
    "#     ax.set_xlabel(\"Reliability idx\", fontsize=8.5)\n",
    "#     ax.set_ylabel(\"Fit error\", fontsize=8.5)\n",
    "    \n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'fitting_coefs_rel.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GC-IO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_io_idx = (1/(costs_final['GC']) - 1/(cost\n",
    "                                        nal['IO']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a IO-GC colormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors = [sns.color_palette()[1], (.72,)*3, sns.color_palette()[0]]\n",
    "n_bins = 200\n",
    "cmap_name = 'contributions_cmap'\n",
    "custom_cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e04061f74ed440c821a866c74d30072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.05, 0.95, '$\\\\rho$=0.29 \\np=5.5e-06')"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].scatter(costs_final['GC'], costs_final['IO'], c='none', edgecolor=cols[2], linewidth=.25, s=7)\n",
    "axes[0].scatter(costs_final['GC'][total_fit_idxs], costs_final['IO'][total_fit_idxs], c=cols[2], s=7)\n",
    "axes[0].plot([0, 1], [0, 1], transform=axes[0].transAxes, c='gray', ls='--')\n",
    "\n",
    "axes[0].set_ylabel('IO fitting costs', fontsize=8)\n",
    "axes[0].set_xlabel('GC fitting costs', fontsize=8)\n",
    "\n",
    "\n",
    "r = stats.spearmanr(gc_io_idx[total_fit_idxs], rel_idxs[total_fit_idxs])\n",
    "axes[1].axvline(0, c = (0.6, )*3, zorder=-100)\n",
    "\n",
    "edge_cols = custom_cmap(gc_io_idx)\n",
    "axes[1].scatter(gc_io_idx, rel_idxs, facecolor='none', edgecolor='white', s=7, linewidths=.075)\n",
    "axes[1].scatter(gc_io_idx[total_fit_idxs], rel_idxs[total_fit_idxs], c=gc_io_idx[total_fit_idxs], cmap=custom_cmap, s=6, vmin=-0.1, vmax=0.1, \n",
    "           edgecolor=(0.3,)*3, linewidths=0.1)\n",
    "\n",
    "#     ax.set_xlim(-1.1, 1.1)\n",
    "axes[1].set_ylabel(\"Reliability index\")\n",
    "axes[1].set_xlabel(\"GC-IO idx\")\n",
    "#     numbers = \n",
    "axes[1].text(.05, .95, \"$\\\\rho$\" + \"={:1.2f} \\np={:1.2}\".format(r.correlation, r.pvalue), fontsize=7, color=(0.3,)*3, transform=axes[1].transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'gc_io_idx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_diffs = {cell_type: np.full((n_rois, clean_traces.shape[1]), np.nan) for cell_type in cell_types}\n",
    "\n",
    "for roi_idx in range(n_rois):\n",
    "    \n",
    "    #Find train-test trials\n",
    "    roi_test_idxs = test_idxs[roi_idx]\n",
    "    test_traces = clean_traces[roi_idx, :, roi_test_idxs]\n",
    "\n",
    "    #Recover traces\n",
    "    roi_fit_idxs = fit_idxs[roi_idx]\n",
    "    fit_traces = clean_traces[roi_idx, :, roi_fit_idxs]\n",
    "\n",
    "    #Recover fit coefficients\n",
    "    gc_coefs = coefs_final['GC'][roi_idx, :]\n",
    "    io_coefs = coefs_final['IO'][roi_idx, :]\n",
    "\n",
    "    #Reconstruct fits\n",
    "    gc_fit = offset_cluster_combine(gc_coefs, regressors_mat_dict['GC'].T)\n",
    "    io_fit = offset_cluster_combine(io_coefs, regressors_mat_dict['IO'].T)\n",
    "\n",
    "    #Calculate error between fit and average test trace   \n",
    "    fit_diffs['GC'][roi_idx, :] = (np.nanmean(test_traces, 0) - gc_fit)**2\n",
    "    fit_diffs['IO'][roi_idx, :] = (np.nanmean(test_traces, 0) - io_fit)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contributions_mat = np.full((n_rois, clean_traces.shape[1]), np.nan)\n",
    "\n",
    "for roi in range(n_rois):\n",
    "    time_contributions_mat[roi, :] = fit_diffs['GC'][roi, :] - fit_diffs['IO'][roi, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 426)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_contributions_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.argsort(costs_final['IO'])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50c028218124d6da87a2d74de3c6d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.025, 0.03, 'Fits w/ IO')"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(14,4))\n",
    "\n",
    "ax = add_offset_axes(figure, (0.1, 0.1, 0.9, 0.9))\n",
    "\n",
    "# Find quartiles:\n",
    "median_contr = np.nanmedian(time_contributions_mat[total_fit_idxs], 0)\n",
    "low_quart_contr = np.nanquantile(time_contributions_mat[total_fit_idxs], 0.25, axis=0)\n",
    "high_quart_contr = np.nanquantile(time_contributions_mat[total_fit_idxs], 0.75, axis=0)\n",
    "\n",
    "# Plot trace and filling:\n",
    "i_col=5\n",
    "ax.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "ax.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col], \n",
    "                     alpha=.3, zorder=100, edgecolor=None)\n",
    "shade_plot(stim, ax, shade_range=(0.75, 0.98))\n",
    "ax.axhline(0, c = (0.3,)*3, zorder=1)\n",
    "ax.set_xlim(0, stim[-1, 0])\n",
    "#     for y_line in [-1, 1]:\n",
    "#         ax.axhline(y_line, color=(0.3,)*3, linewidth=0.5)\n",
    "\n",
    "make_bar(ax, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "ax.set_ylabel('Fitting error')\n",
    "ax.text(0.025, .97, 'Fits w/ GC', fontsize=7, color=sns.color_palette()[0], transform=ax.transAxes, va='center')\n",
    "ax.text(0.025, .03, 'Fits w/ IO', fontsize=7, color=sns.color_palette()[1], transform=ax.transAxes, va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure.savefig(fig_fold/'time_contr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 1.5))\n",
    "    \n",
    "# Find quartiles:\n",
    "median_contr = np.nanmedian(time_contributions_mat, 0)\n",
    "low_quart_contr = np.nanquantile(time_contributions_mat, 0.25, axis=0)\n",
    "high_quart_contr = np.nanquantile(time_contributions_mat, 0.75, axis=0)\n",
    "\n",
    "plt.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "plt.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contributions_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trace and filling:\n",
    "i_col=5\n",
    "ax.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "ax.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col], \n",
    "                     alpha=.3, zorder=100, edgecolor=None)\n",
    "shade_plot(stim, ax, shade_range=(0.75, 0.98))\n",
    "ax.axhline(0, c = (0.3,)*3, zorder=1)\n",
    "ax.set_xlim(0, stim[-1, 0])\n",
    "#     for y_line in [-1, 1]:\n",
    "#         ax.axhline(y_line, color=(0.3,)*3, linewidth=0.5)\n",
    "\n",
    "make_bar(ax, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "ax.set_ylabel('Contribution ratio')\n",
    "ax.text(0.5, 1.05, 'GC contributions dominates', fontsize=7, color=sns.color_palette()[0])\n",
    "ax.text(0.5, -1.15, 'IO contributions dominates', fontsize=7, color=sns.color_palette()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.fill_between(stim[:,0], low_quart_contr, high_quart_contr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_quart_contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_idx = np.argsort(costs_final['GC'])[2]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
    "\n",
    "#Find train-test trials\n",
    "roi_test_idxs = test_idxs[roi_idx]\n",
    "test_traces = clean_traces[roi_idx, :, roi_test_idxs]\n",
    "\n",
    "#Recover traces\n",
    "roi_fit_idxs = fit_idxs[roi_idx]\n",
    "fit_traces = clean_traces[roi_idx, :, roi_fit_idxs]\n",
    "\n",
    "#Recover fit coefficients\n",
    "gc_coefs = coefs_final['GC'][roi_idx, :]\n",
    "io_coefs = coefs_final['IO'][roi_idx, :]\n",
    "\n",
    "#Reconstruct fits\n",
    "gc_fit = offset_cluster_combine(gc_coefs, regressors_mat_dict['GC'].T)\n",
    "io_fit = offset_cluster_combine(io_coefs, regressors_mat_dict['IO'].T)\n",
    "\n",
    "\n",
    "\n",
    "for row, traces in zip(range(2), [fit_traces, test_traces]):\n",
    "    for col, fit in zip(range(2), [gc_fit, io_fit]):\n",
    "        for rep in range(traces.shape[0]):\n",
    "            axes[row, col].plot(traces[rep, :], 'gray', alpha=.2)\n",
    "        axes[row, col].plot(np.nanmean(traces, 0), c=cols[2])\n",
    "        axes[row, col].plot(fit, c=cols[col])\n",
    "        \n",
    "\n",
    "    for row, label in zip(range(2), ['Training set', 'Test set']):\n",
    "        axes[row, 0].set_ylabel(label, c='gray')\n",
    "        \n",
    "    for col, title in zip(range(2), ['GC regressors', 'IO regressors']):\n",
    "        axes[0, col].set_title(title, c='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at distribution of IO and GC coefficients weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_coefs = coefs_final_sel.copy()\n",
    "cleaned_coefs = cleaned_coefs[~(cleaned_coefs == 0).all(1), :]\n",
    "coefs_sum = np.nansum(np.abs(cleaned_coefs), 1)\n",
    "norm_coefs = (cleaned_coefs.T / coefs_sum).T\n",
    "non_zero_coefs = np.abs(norm_coefs) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_io_weights_hist(cleaned_coefs, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3,2))\n",
    "        \n",
    "    ax = add_offset_axes(figure, (0.2, 0.2, 0.7, 0.7), frame=frame)\n",
    "    l=400\n",
    "    ax.hist(cleaned_coefs[:, 1:9].sum(1), np.arange(-l, l, 20), alpha=0.6, label=\"GC\")\n",
    "    ax.hist(cleaned_coefs[:, 9:].sum(1), np.arange(-l, l, 20), alpha=0.6, label=\"IO\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Weight of coefs\")\n",
    "    ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_io_weights_hist(cleaned_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at distribution of number of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_io_nonzero_hist(non_zero_coefs, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3,2))\n",
    "        \n",
    "    ax = add_offset_axes(figure, (0.2, 0.2, 0.7, 0.7), frame=frame)\n",
    "    ax.hist(non_zero_coefs[:, 1:9].sum(1), np.arange(0, 15), \n",
    "            label=\"GC (mn={:2.1f})\".format(np.nanmean(non_zero_coefs[:, 1:9].sum(1))), alpha=0.6)\n",
    "    ax.hist(non_zero_coefs[:, 9:].sum(1), np.arange(0, 15), \n",
    "            label=\"IO (mn={:2.1f})\".format(np.nanmean(non_zero_coefs[:, 9:].sum(1))), alpha=0.6)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"N. of coefs\")\n",
    "    ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_io_nonzero_hist(non_zero_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GC-IO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"GC vs IO-ness index\", looking at the ratio of coefficients of GC clusters and IO clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gc = np.abs(coefs_final_sel[:, 1:n_gc_clust+1]).mean(1)\n",
    "w_io = np.abs(coefs_final_sel[:, n_gc_clust+1:]).mean(1)\n",
    "gc_io_idx = (w_gc - w_io) / (w_gc + w_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a IO-GC colormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors = [sns.color_palette()[1], (.72,)*3, sns.color_palette()[0]]\n",
    "n_bins = 200\n",
    "cmap_name = 'contributions_cmap'\n",
    "custom_cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_plot(gc_io_idx, rel_idxs, figure=None, frame=None):\n",
    "    r = stats.spearmanr(gc_io_idx[~np.isnan(gc_io_idx)], rel_idxs[~np.isnan(gc_io_idx)])\n",
    "    \n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3., 2.))\n",
    "    \n",
    "    ax = add_offset_axes(figure, (0.2, 0.2, 0.7, 0.7), frame=frame)\n",
    "    ax.axvline(0, c = (0.6, )*3, zorder=-100)\n",
    "    ax.scatter(gc_io_idx, rel_idxs, c=gc_io_idx, cmap=custom_cmap, s=6, vmin=-1, vmax=1, \n",
    "               edgecolor=(0.3,)*3, linewidths=0.1)\n",
    "    ax.set_xlim(-1.1, 1.1)\n",
    "    ax.set_ylabel(\"Reliability index\")\n",
    "    ax.set_xlabel(\"GC/IO idx\")\n",
    "#     numbers = \n",
    "    ax.text(-1, 0.7, \"$\\\\rho$\" + \"={:1.2f} \\np={:1.2}\".format(r.correlation, r.pvalue), fontsize=7, color=(0.3,)*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_plot(gc_io_idx, rel_idx_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single cell example fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11, 17, 32, 33, (44), 71\n",
    "\n",
    "37, 60, 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_cell_plot(traces, all_coefs, roi_test_idxs, idx, \n",
    "                          legend=True, bar=True, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(7, 2))\n",
    "    coefs = all_coefs[idx, :]\n",
    "    roi_test_idxs = test_idxs[idx]\n",
    "    reshaped = traces[idx, :, roi_test_idxs]\n",
    "    \n",
    "    ylim = 3.7\n",
    "    axtrace = add_offset_axes(figure, (0.0, 0.1, 0.58, 0.92), frame=frame)\n",
    "    axtrace.plot(stim[:, 0], reshaped.T, color=sns.color_palette()[2], linewidth=0.5)\n",
    "    axtrace.plot(stim[:, 0], np.nanmean(reshaped, 0), color=sns.color_palette()[2], linewidth=2, label=\"PC trace\")\n",
    "    axtrace.plot(stim[:, 0], nanzscore(offset_cluster_combine(coefs, regressors_mat.T)), color=\"k\", label=\"Fit\")\n",
    "    shade_plot(stim, axtrace, shade_range=(0.75, 0.98))\n",
    "    \n",
    "    axtrace.set_ylim(-ylim, ylim)\n",
    "    axtrace.set_xlim(0, stim[-1, 0])\n",
    "    axtrace.spines[\"left\"].set_visible(False)\n",
    "    axtrace.set_yticks([])\n",
    "    if bar:\n",
    "        make_bar(axtrace, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "    else:\n",
    "        axtrace.spines[\"bottom\"].set_visible(False)\n",
    "        axtrace.set_xticks([])\n",
    "    \n",
    "    # Legend\n",
    "    handles, labels = axtrace.get_legend_handles_labels()\n",
    "    unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]\n",
    "    if legend:\n",
    "        plt.legend(*zip(*unique), loc=\"lower left\", fontsize=7)\n",
    "    \n",
    "    # Inserts\n",
    "    ylim = 1.5\n",
    "    y_off = -0.5\n",
    "    coefs_gc = np.zeros(coefs.shape)\n",
    "    coefs_io = np.zeros(coefs.shape)\n",
    "    coefs_gc[1:9] = coefs[1:9]\n",
    "    coefs_io[9:] = coefs[9:]\n",
    "    for n, (ax_pos, lab, c_coefs) in enumerate(zip([(0.6, 0.6, 0.4, 0.4), (0.6, 0.1, 0.4, 0.4)], \n",
    "                                                   [\"GC\", \"IO\"],\n",
    "                                                   [coefs_gc, coefs_io])):\n",
    "        col = sns.color_palette()[n]\n",
    "        ax_little = add_offset_axes(figure, ax_pos, frame=frame)\n",
    "        ax_little.plot(stim[:, 0], offset_cluster_combine(c_coefs, regressors_mat.T), color=col)\n",
    "        shade_plot(stim, ax_little, shade_range=(0.75, 0.98))\n",
    "        ax_little.set_ylim(-ylim-y_off, ylim-y_off)\n",
    "        ax_little.axis(\"off\")\n",
    "        \n",
    "        if legend:\n",
    "            ax_little.text(2, -ylim-y_off + 0.2, lab + \" contribution\", color=col, fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cells  # (gc_io idx sort): \n",
    "- 97, 254 example IO\n",
    "- 197, example comb\n",
    "- 89, 115, 60 example comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "97, 197, 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = costs_final_sel < 0.9\n",
    "idx = np.argsort(gc_io_idx[sel])[-11]\n",
    "make_single_cell_plot(clean_traces_sel, coefs_final_sel, fit_idxs_sel, idx, figure=None, frame=None)\n",
    "# for idx in [98]:\n",
    "#     make_single_cell_plot(clean_traces_sel, coefs_final_sel, fit_idxs_sel, idx, figure=None, frame=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time contribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contributions_mat = np.zeros((n_rep_timepts, n_valid_rois))\n",
    "coefs_gc = np.zeros(coefs_final_sel.shape)\n",
    "coefs_io = np.zeros(coefs_final_sel.shape)\n",
    "coefs_gc[:, 1:9] = coefs_final_sel[:, 1:9]\n",
    "coefs_io[:, 9:] = coefs_final_sel[:, 9:]\n",
    "\n",
    "for i_roi in range(n_valid_rois):\n",
    "       \n",
    "    gc_contribution = offset_cluster_combine(coefs_gc[i_roi, :], regressors_mat.T)\n",
    "    io_contribution = offset_cluster_combine(coefs_io[i_roi, :], regressors_mat.T)\n",
    "    \n",
    "    contribution_ratio = (np.abs(gc_contribution) - np.abs(io_contribution)) / \\\n",
    "                (np.abs(gc_contribution) + np.abs(io_contribution))\n",
    "    \n",
    "    time_contributions_mat[:, i_roi] = contribution_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_contr_plot(time_contributions_mat, stim, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(7, 1.5))\n",
    "    \n",
    "    ax = add_offset_axes(figure, (0.1, 0.1, 0.9, 0.9), frame=frame)\n",
    "\n",
    "    # Find quartiles:\n",
    "    median_contr = np.nanmedian(time_contributions_mat, 1)\n",
    "    low_quart_contr = np.nanquantile(time_contributions_mat, 0.25, axis=1)\n",
    "    high_quart_contr = np.nanquantile(time_contributions_mat, 0.75, axis=1)\n",
    "    \n",
    "    # Plot trace and filling:\n",
    "    i_col=5\n",
    "    ax.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "    ax.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col], \n",
    "                         alpha=.3, zorder=100, edgecolor=None)\n",
    "    shade_plot(stim, ax, shade_range=(0.75, 0.98))\n",
    "    ax.axhline(0, c = (0.3,)*3, zorder=1)\n",
    "    ax.set_ylim(-1., 1.)\n",
    "    ax.set_xlim(0, stim[-1, 0])\n",
    "#     for y_line in [-1, 1]:\n",
    "#         ax.axhline(y_line, color=(0.3,)*3, linewidth=0.5)\n",
    "    \n",
    "    make_bar(ax, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "    ax.set_ylabel('Contribution ratio')\n",
    "    ax.text(0.5, 1.05, 'GC contributions dominates', fontsize=7, color=sns.color_palette()[0])\n",
    "    ax.text(0.5, -1.15, 'IO contributions dominates', fontsize=7, color=sns.color_palette()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contr_plot(time_contributions_mat, stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble final panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_names = [\"IO{}\".format(i+1) for i in range(n_io_clust)] + [\"GC{}\".format(i+1) for i in range(n_gc_clust)]\n",
    "cols = [sns.color_palette()[1]]*n_io_clust + [sns.color_palette()[0]]*n_gc_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regressor panel:\n",
    "def reg_panel_plot(regressors_mat, figure=None, ax=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3, 3))\n",
    "\n",
    "    offset = 0.01\n",
    "    if ax is None:\n",
    "        ax = add_offset_axes(figure, (0., 0., 1, 1), frameon=False, frame=frame)\n",
    "    cols = sns.color_palette()\n",
    "    for i, col in enumerate([cols[0], ]*n_gc_clust + [cols[1], ]*n_io_clust):\n",
    "        ax.fill_between(stim[:, 0], np.zeros(stim[:, 0].shape) - i*offset, \n",
    "                        regressors_mat[i, :] - i*offset, color=col)\n",
    "        \n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "# Plot a trace panel:\n",
    "def little_trace_plot(clean_traces, i=0, figure=None, ax=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3, 1))\n",
    "\n",
    "    if ax is None:\n",
    "        ax = add_offset_axes(figure, (0., 0., 1, 1), frameon=False, frame=frame)\n",
    "    offset = 0.01\n",
    "    ax.plot(clean_traces[i, :, :1].T.flatten(), c=sns.color_palette()[2])\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema_panel(clean_traces, regressors_mat, i=9, figure=None, frame=None):\n",
    "    if figure is None:        \n",
    "        figure = plt.figure(figsize=(7, 3))\n",
    "\n",
    "    schema_y = 0.3\n",
    "\n",
    "    h_cent = 0.5\n",
    "    trace_h = 0.2\n",
    "    reg_h = 0.9\n",
    "    schema_h = 0.9\n",
    "    ax_trace = add_offset_axes(figure, [0.7, h_cent - trace_h/2, 0.3, trace_h], frameon=False, frame=frame)\n",
    "    ax_regressors = add_offset_axes(figure, [0.02, h_cent - reg_h/2 - 0.01, 0.3, reg_h], frameon=False, frame=frame)\n",
    "    ax_schema = add_offset_axes(figure, [0.31, h_cent - schema_h/2, 0.4, schema_h], frameon=False, aspect=1., frame=frame)\n",
    "    little_trace_plot(clean_traces, i=18, figure=figure, ax=ax_trace)\n",
    "\n",
    "    reg_panel_plot(regressors_mat, figure=figure, ax=ax_regressors)\n",
    "\n",
    "    ax_schema.xaxis.set_visible(False)\n",
    "    ax_schema.yaxis.set_visible(False)\n",
    "\n",
    "    n_clust = 14\n",
    "    n_gc_clust\n",
    "    n_io_clust\n",
    "    c_cent = (0.6, 0.5)  # x, y\n",
    "    p = mpatches.Circle(c_cent, 0.1, edgecolor=\"k\", facecolor=\"w\")\n",
    "\n",
    "    w_pos_x = 0.0\n",
    "    line_displ_x = 0.2\n",
    "    for i_clust, (label, col) in enumerate(zip(clust_names, cols)):\n",
    "        c = 1/(2*(n_clust + 1)) + i_clust/(n_clust + 1)\n",
    "        l = lines.Line2D([w_pos_x + line_displ_x, c_cent[0]], [c, c_cent[1]], c=\"k\", zorder=-100)\n",
    "        ax_schema.add_line(l)\n",
    "        ax_schema.text(w_pos_x, c, \"$\\cdot w_i^{\" + label + \"}$\", ha=\"left\", va=\"center\", fontsize=7, color=col)\n",
    "\n",
    "    c = 1/(2*n_clust) + (i_clust + 1)/(n_clust + 1)\n",
    "    l = lines.Line2D([w_pos_x + line_displ_x, c_cent[0]], [c, c_cent[1]], c=\"k\", zorder=-100)\n",
    "    ax_schema.add_line(l)\n",
    "    ax_schema.text(w_pos_x, c, \"$offset_i$\", ha=\"left\", va=\"center\", fontsize=7, color=\"k\")\n",
    "\n",
    "    ax_schema.add_patch(p)\n",
    "\n",
    "    l = lines.Line2D([c_cent[0], 1], [c_cent[1], c_cent[1]], c=\"k\", zorder=-100)\n",
    "    ax_schema.add_line(l)\n",
    "\n",
    "    # Text\n",
    "    ax_schema.text(*c_cent, \"$\\sum$\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "    ax_schema.text(0.55, 0.9, \"$PC_i = regr^{GC} \\cdot w_i^{GC} + regr^{IO} \\cdot w_i^{IO} + offset_i$\", \n",
    "                   ha=\"left\", va=\"center\", fontsize=7.5)\n",
    "    ax_trace.text(0, -3, \"$PC_i$\", ha=\"left\", va=\"center\", fontsize=9, color=sns.color_palette()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 9))\n",
    "schema_panel(clean_traces, regressors_mat, i=9, figure=fig, frame=[0.25, 0.77, 0.6, 0.2])\n",
    "\n",
    "offset_y = 0.13\n",
    "start_y = 0.36\n",
    "for i, idx in enumerate([97, 197, 89]):\n",
    "    y = start_y + i*offset_y\n",
    "    \n",
    "    make_single_cell_plot(clean_traces_sel, coefs_final_sel, fit_idxs_sel, idx, figure=fig, frame=[0., y, 0.53, 0.12], legend=(i==2), bar=(i==0))\n",
    "\n",
    "coefs_plot(clust_lab_sel, coefs_final_sel, figure=fig, frame=[0.58, 0.56, 0.4, 0.18])\n",
    "indexes_plot(gc_io_idx, rel_idx_sel, figure=fig, frame=[0.58, 0.35, 0.35, 0.2])\n",
    "time_contr_plot(time_contributions_mat, stim, figure= fig, frame=[0.1, 0.17, 0.65, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    fig.savefig(fig_fold / \"fig7_panel.pdf\", forma=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsupp = plt.figure(figsize=(6, 4))\n",
    "s = 0.45\n",
    "cost_figure(costs_final, costs_shuf, cost_threshold, figure=figsupp, frame=[0., 0.5, s, s])\n",
    "error_vs_reliabil(rel_idx_sel, costs_final_sel, figure=figsupp, frame=[0.5, 0.5, s, s])\n",
    "# gc_io_weights_hist(cleaned_coefs, figure=figsupp, frame=[0., 0., s, s])\n",
    "gc_io_nonzero_hist(non_zero_coefs, figure=figsupp, frame=[0.25, 0., s, s])\n",
    "# sorted_examples_plot(coefs_final, gc_io_idx, clean_traces, test_idxs, figure=figure6supp, frame=[0.5, 0.1, 0.5, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    figsupp.savefig(fig_fold.parent.parent / (fig_fold.parent.name + \"supp/src\") / \"supp_panel.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

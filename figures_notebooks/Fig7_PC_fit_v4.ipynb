{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flammkuchen as fl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from luminance_analysis import PooledData, traces_stim_from_path\n",
    "from ipywidgets import interact, fixed, interactive\n",
    "import ipywidgets as widgets\n",
    "\n",
    "plt.style.use(\"figures.mplstyle\")\n",
    "cols = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fold = Path(r\"C:\\Users\\otprat\\Documents\\figures\\luminance\\manuscript_figures\\fig7_v4\\all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path = Path(r\"\\\\FUNES\\Shared\\experiments\\E0032_luminance\\neat_exps\")\n",
    "# master_path = Path(r\"D:\\neat_exps\")\n",
    "# master_path = Path(r\"/Users/luigipetrucco/Desktop/data_dictionaries/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_rerun = False\n",
    "save_path = master_path/'fitting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luminance_analysis.utilities import deconv_resamp_norm_trace, reliability, nanzscore, get_kernel\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree, to_tree, set_link_color_palette\n",
    "from luminance_analysis.plotting import plot_clusters_dendro, shade_plot, add_offset_axes, make_bar\n",
    "from luminance_analysis.clustering import cluster_id_search, find_trunc_dendro_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<luminance_analysis.FishData object at 0x000001FC5EDA5648>, <luminance_analysis.FishData object at 0x000001FC5EDA56C8>, <luminance_analysis.FishData object at 0x000001FC5EDB51C8>, <luminance_analysis.FishData object at 0x000001FC5EDD0988>, <luminance_analysis.FishData object at 0x000001FC5EDBF188>]\n",
      "[<luminance_analysis.FishData object at 0x000001FC5EDB53C8>, <luminance_analysis.FishData object at 0x000001FC5EDB5948>, <luminance_analysis.FishData object at 0x000001FC5EDBD4C8>, <luminance_analysis.FishData object at 0x000001FC5EDBFF48>, <luminance_analysis.FishData object at 0x000001FC5EDCA308>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\rplab\\lib\\site-packages\\numpy\\lib\\function_base.py:2642: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\tools\\miniconda3\\envs\\rplab\\lib\\site-packages\\numpy\\lib\\function_base.py:2643: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<luminance_analysis.FishData object at 0x000001FC00CA0888>, <luminance_analysis.FishData object at 0x000001FC00CA0908>, <luminance_analysis.FishData object at 0x000001FC00CA4E88>, <luminance_analysis.FishData object at 0x000001FC00CA5488>, <luminance_analysis.FishData object at 0x000001FC00CB8A48>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410a2a68cc534a69bf3c651ff363b42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<luminance_analysis.FishData object at 0x000001FC00D5B288>, <luminance_analysis.FishData object at 0x000001FC00D5B308>, <luminance_analysis.FishData object at 0x000001FC00D528C8>, <luminance_analysis.FishData object at 0x000001FC00D54148>, <luminance_analysis.FishData object at 0x000001FC00D7D988>]\n",
      "[<luminance_analysis.FishData object at 0x000001FC00D52608>, <luminance_analysis.FishData object at 0x000001FC00D52588>, <luminance_analysis.FishData object at 0x000001FC00D54A08>, <luminance_analysis.FishData object at 0x000001FC00D756C8>, <luminance_analysis.FishData object at 0x000001FC00D76708>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b7c5f7560b4406a31681f97b817eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<luminance_analysis.FishData object at 0x000001FC0088B188>, <luminance_analysis.FishData object at 0x000001FC0088BB08>, <luminance_analysis.FishData object at 0x000001FC0089EC08>, <luminance_analysis.FishData object at 0x000001FC00891D88>, <luminance_analysis.FishData object at 0x000001FC0089C108>]\n",
      "[<luminance_analysis.FishData object at 0x000001FC0088CCC8>, <luminance_analysis.FishData object at 0x000001FC0088CB48>, <luminance_analysis.FishData object at 0x000001FC00895648>, <luminance_analysis.FishData object at 0x000001FC00CAF788>, <luminance_analysis.FishData object at 0x000001FC008A9288>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400df1b6a66642feb9934c24666f78f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tau_6f = 5\n",
    "tau_6s = 8\n",
    "ker_len = 20\n",
    "normalization = \"zscore\"\n",
    "protocol = 'steps'\n",
    "\n",
    "brain_regions_list = [\"GC\", \"IO\", \"PC\"]\n",
    "tau_list = [tau_6f, tau_6f, tau_6s]\n",
    "n_cluster_list = [8, 6, 8]\n",
    "nan_thr_list = [0, 1, 1]\n",
    "\n",
    "data_dict = {k:{} for k in brain_regions_list}\n",
    "\n",
    "#load stimulus of GCs and use it as a the reference for time array and stimulus array:\n",
    "stim_ref = PooledData(path = master_path / protocol / \"GC\").stimarray_rep\n",
    "\n",
    "for brain_region, tau, n_cluster, nan_thr in zip(brain_regions_list, tau_list, \n",
    "                                                 n_cluster_list, nan_thr_list):\n",
    "    #Load data :\n",
    "    path = master_path / protocol / brain_region\n",
    "    stim, traces, meanresps = traces_stim_from_path(path)\n",
    "\n",
    "    # Mean traces, calculate reliability index :\n",
    "    rel_idxs = reliability(traces)\n",
    "    \n",
    "    # Find threshold from reliability histogram...\n",
    "    rel_thr = threshold_otsu(rel_idxs[~np.isnan(rel_idxs)])\n",
    "\n",
    "    # ...and load again filtering with the threshold:\n",
    "    _, traces, meanresps = traces_stim_from_path(path, resp_threshold=rel_thr, nanfraction_thr=nan_thr)\n",
    "\n",
    "    # Hierarchical clustering:\n",
    "    linked = linkage(meanresps, 'ward')\n",
    "    \n",
    "    # Truncate dendrogram at n_cluster level:\n",
    "    plt.figure(figsize=(0.1, 0.1))  \n",
    "    dendro = dendrogram(linked, n_cluster, truncate_mode =\"lastp\")\n",
    "    plt.close()\n",
    "    cluster_ids = dendro[\"leaves\"]\n",
    "    labels = find_trunc_dendro_clusters(linked, dendro) \n",
    "    \n",
    "    # Deconvolution, resampling / normalization:\n",
    "    deconv_meanresps = np.empty((meanresps.shape[0], stim_ref.shape[0]))\n",
    "    resamp_meanresps = np.empty((meanresps.shape[0], stim_ref.shape[0]))\n",
    "    for roi_i in range(deconv_meanresps.shape[0]):\n",
    "        deconv_meanresps[roi_i, :] = deconv_resamp_norm_trace(meanresps[roi_i, :], stim[:, 0],\n",
    "                                                                stim_ref[:, 0], tau, ker_len,\n",
    "                                                                smooth_wnd=4,\n",
    "                                                                normalization=normalization)\n",
    "        resamp_meanresps[roi_i, :] = deconv_resamp_norm_trace(meanresps[roi_i, :], stim[:, 0],\n",
    "                                                                stim_ref[:, 0], None, ker_len,\n",
    "                                                                smooth_wnd=4,\n",
    "                                                                normalization=normalization)\n",
    "    \n",
    "    cluster_resps = np.empty((n_cluster, stim_ref.shape[0]))\n",
    "    for clust_i in range(n_cluster):\n",
    "        cluster_resp = np.nanmean(deconv_meanresps[labels==clust_i, :], 0)  # average cluster responses\n",
    "        cluster_resps[clust_i, :] = nanzscore(cluster_resp)  # normalize\n",
    "\n",
    "\n",
    "    # Add everything to dictionary:\n",
    "    data_dict[brain_region][\"linkage_mat\"] = linked\n",
    "    data_dict[brain_region][\"clust_labels\"] = labels\n",
    "    #data_dict[brain_region][\"raw_mn_resps\"] = meanresps\n",
    "    data_dict[brain_region][\"traces\"] = traces\n",
    "    #data_dict[brain_region][\"deconv_mn_resps\"] = deconv_meanresps\n",
    "    #data_dict[brain_region][\"resamp_mn_resps\"] = resamp_meanresps\n",
    "    data_dict[brain_region][\"rel_idxs\"] = rel_idxs[rel_idxs > rel_thr]\n",
    "    data_dict[brain_region][\"rel_thr\"] = rel_thr\n",
    "    data_dict[brain_region][\"clust_resps\"] = cluster_resps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the model\n",
    "\n",
    "\n",
    "The goal of the model is to reconstruct the activity of PCs based on the activity observed for GCs and IONs.\n",
    "The function that we will use to model a PC is the following:\n",
    "$$ trace_{PC}^i = o^i + clusters_{GC} * w^i_{GC} + clusters_{IO} * w^i_{IO}$$\n",
    "\n",
    "\n",
    " - $trace_{PC}^i$ is the $i^{th}$ PC cell trace;\n",
    " - $o^i$ is an offset term:\n",
    " - $clusters_{GC}$, $clusters_{IO}$ are matrices with the average activation of all GC&IO clusters;\n",
    " - $w^i_{GC}$, $w^i_{IO}$ are weights vectors for each of the GC and IO cluster. We will allow positive and negative $w^i_{GC}$, but only positive $w^i_{IO}$. This is a quite safe assumption considering the known PC physiology. \n",
    "\n",
    "\n",
    "### Approach\n",
    "\n",
    "Here is a summary of the modelling approach:\n",
    "- **Create a panel of regressors**:\n",
    "    - Calculate clusters of GC and IO responses; \n",
    "    - Deconvolve average response of each cluster with 6fe05 kernel;\n",
    "    - Reconvolve it with 6s kernel;\n",
    "    - Normalize it to be  > 0, and with integral = 1.\n",
    "\n",
    "\n",
    "- **Clean up PC traces**:\n",
    "    - For each cell, take raw fluorescence if valid trials, and zscore them on a trial-to-trial base (for changes in offset F across planes);\n",
    "    - concatenate repetitions;\n",
    "    - high-pass filter them with very low cutoff freq (1/80 Hz) to remove slow fluctuations;\n",
    "    - smooth them with a 3 pts mean boxcar rolling window;\n",
    "    \n",
    "    \n",
    "- **Split fit and test data**:\n",
    "    - Randomly pick from each cell:\n",
    "        - 2 repetitions that will be left out for the analysis (**test traces**);\n",
    "        - 4 repetitions (or more, if there are more planes) that will be used for finding the regularization term and for the actual fitting (**fit traces**);\n",
    "\n",
    "\n",
    "- **Define boundaries, cost function and regularization function**:\n",
    "    - Parameters to be optimized are:\n",
    "        - *offset*: a constant term, bound to be between -5 and 5;\n",
    "        - *coefs_GC*: coefficients for GC regressors, bound to be between -1000 and 1000 (the large difference comes from the different normalizations applied on regressors -norm- and on trace - Z scoring)\n",
    "        - *coefs_IO*: coefficients for GC regressors, bound to be between 0 and 1000, as we have good reasons to postulate that IO contributions are strictly positive\n",
    "        - cost function: L2 distance to target trace;\n",
    "        - regularization function: L1 (sum of absolute value of parameters)\n",
    "        \n",
    "        \n",
    "- **Find regularization parameter**:\n",
    "    - Find regularization parameter (leave one out cross-validation):\n",
    "    - For each lambda parameter, train the model on all the fit traces but one (**train traces**);\n",
    "    - Then, calculate the cost of the fit on the one trace that was left out (**validation trace**);\n",
    "    - Do this iterating over all possible combinations of n-1 and 1 traces;\n",
    "    - Calculate average cross over all combinations, over all cells;\n",
    "\n",
    "\n",
    "- **Fit the trace**:\n",
    "    - Use the resulting regularization term for fitting the fit repetitions, and use the obtained coefficients for plots / further analyses on the test repetitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a panel of regressors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create regressor panel, making traces non-0 and with integral equal to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gc_clust = data_dict[\"GC\"][\"clust_resps\"].shape[0]\n",
    "n_io_clust = data_dict[\"IO\"][\"clust_resps\"].shape[0]\n",
    "regressors_mat = np.concatenate([data_dict[\"GC\"][\"clust_resps\"], data_dict[\"IO\"][\"clust_resps\"]])\n",
    "\n",
    "# Reconvolve and normalize regressors:\n",
    "for i in range(regressors_mat.shape[0]):\n",
    "    reconvolved = np.convolve(regressors_mat[i, :], get_kernel(ker_len=100, tau=tau_6s))[:regressors_mat.shape[1]]\n",
    "    \n",
    "    # Make strictly positive and with integral == 1:\n",
    "    reconvolved -= np.min(reconvolved)  # offset at 0\n",
    "    regressors_mat[i, :] = reconvolved / np.sum(reconvolved)\n",
    "\n",
    "# Arbitrary cluster names (do we need them?):\n",
    "gc_cluster_names = ['ON 1', 'ON 2', 'ON abs', 'ON inter.1', 'ON inter.2', 'OFF 1', 'OFF 2', 'OFF inter.']\n",
    "io_cluster_names = ['Onset', 'ON max', 'Offset 1', 'Offset 2', 'On inter.', 'Offset 3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the regressors panel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regressor panel:\n",
    "def reg_panel_plot(regressors_mat, figure=None, ax=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3, 3))\n",
    "\n",
    "    offset = 0.01\n",
    "    if ax is None:\n",
    "        ax = add_offset_axes(figure, (0., 0., 1, 1), frameon=False, frame=frame)\n",
    "    cols = sns.color_palette()\n",
    "    for i, col in enumerate([cols[0], ]*n_gc_clust + [cols[1], ]*n_io_clust):\n",
    "        ax.fill_between(stim[:, 0], np.zeros(stim[:, 0].shape) - i*offset, \n",
    "                        regressors_mat[i, :] - i*offset, color=col)\n",
    "        \n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a0b51bfc7845e3b0c46ba32ac28a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_panel_plot(regressors_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up PC traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luminance_analysis.utilities import smooth_traces, butter_highpass_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cell_rep_block(cellmat, cutoff=1/80, smooth_wnd=3):\n",
    "    \"\"\" Filter traces from the raw traces block.\n",
    "    Return a repetitions block containing only the valid repetitions.\n",
    "    \"\"\"\n",
    "    cutoff = 1 / 80\n",
    "    dt = stim[1, 0]\n",
    "    \n",
    "    # Select entries with valid numbers in the repetition matrix:\n",
    "    cellmat = cellmat[:, ~np.isnan(cellmat).all(0)].copy()\n",
    "    \n",
    "    # zscore repetition-wise, important for ROIs spanning more than one plane\n",
    "    cellmat = (cellmat - np.nanmean(cellmat, 0)) / np.nanstd(cellmat, 0)\n",
    "    \n",
    "    # concatenate, highpass filter with very low cutoff, and smooth:\n",
    "    trace = np.concatenate(cellmat.T, 0)\n",
    "    filtered = butter_highpass_filter(trace, cutoff, 1 / dt)  # filt trace\n",
    "    filtered = smooth_traces(filtered[np.newaxis, :], win=3, method=\"mean\")[0, :]  # smooth\n",
    "    filtered[np.isnan(filtered)] = 0\n",
    "    \n",
    "    # reshape in original form, and zscore again after filtering and smoothing:\n",
    "    reshaped = filtered.reshape(cellmat.T.shape).T  \n",
    "    reshaped = (reshaped - np.nanmean(reshaped, 0))/np.nanstd(reshaped, 0)\n",
    "    \n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup parameters:\n",
    "cutoff_hz = 1 / 80  # long cutoff for highpass filter - remove long fluctuations in PC signal\n",
    "smooth_wnd = 3  # smoothing window to reduce noise. Our data is sampled ar around 0.25 seconds\n",
    "\n",
    "raw_traces = data_dict[\"PC\"][\"traces\"]  # raw PC fluorescences\n",
    "rel_idxs = data_dict[\"PC\"][\"rel_idxs\"]  # reliability indexes for each PC cell\n",
    "\n",
    "n_rois = raw_traces.shape[0]  # number of ROIs\n",
    "n_rep_timepts = raw_traces.shape[1]  # timepoints per repetition\n",
    "n_reps_max = raw_traces.shape[2]  # maximum number of repetitions in a cell\n",
    "\n",
    "# Find number of valid repetitions for each cell:\n",
    "n_valid_reps = (~np.isnan(raw_traces).all(1)).sum(1)\n",
    "\n",
    "# Clean up:\n",
    "clean_traces = np.full(raw_traces.shape, np.nan)\n",
    "for i_roi in range(n_rois):\n",
    "    clean_block = filter_cell_rep_block(raw_traces[i_roi, :, :], cutoff=cutoff_hz, smooth_wnd=smooth_wnd)\n",
    "    clean_traces[i_roi, :, :n_valid_reps[i_roi]] = clean_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a trace panel:\n",
    "def little_trace_plot(clean_traces, i=0, figure=None, ax=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3, 1))\n",
    "\n",
    "    if ax is None:\n",
    "        ax = add_offset_axes(figure, (0., 0., 1, 1), frameon=False, frame=frame)\n",
    "    offset = 0.01\n",
    "    plt.plot(clean_traces[i, :, :1].T.flatten())\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c9b3108a914d1da2ff5e3208113f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "little_trace_plot(clean_traces, i=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate testing and training traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix randomness for reproducibility:\n",
    "np.random.seed(572704)\n",
    "seed(572704)\n",
    "\n",
    "# Generate list of 2 indexes for each cell which will be used to keep traces out for the testing part.\n",
    "# Generate randomly indexes for test and train set of traces:\n",
    "n_test_reps = 3\n",
    "\n",
    "test_idxs = []\n",
    "fit_idxs = []\n",
    "for n_resps in n_valid_reps:\n",
    "    idxs = np.arange(n_resps)  # possible repetitions indexes\n",
    "    shuffle(idxs)  # shuffle index list\n",
    "    test_idxs.append(idxs[:n_test_reps])  # test idxs will be the first 2\n",
    "    fit_idxs.append(idxs[n_test_reps:])  # the rest goes for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define boundaries, function & regularisation/cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for the regression.\n",
    "\n",
    "# This is the the main function that we actually use to describe PC activity:\n",
    "def offset_cluster_combine(coefs, regressors):\n",
    "    \"\"\" Compute trace from offset/coefficients and regressors.\n",
    "    It assumes coefs and regressors for GC and IO are all concatenated,\n",
    "    and first element of coefs array is the offset.\n",
    "    \"\"\"\n",
    "    return coefs[0] + np.sum(coefs[1:] * regressors, 1)  # first term is baseline\n",
    "\n",
    "def cost_func(fit_coefs, regressors, trace2fit, model):\n",
    "    \"\"\" Cost function: sum of squares.\n",
    "    \"\"\"\n",
    "    diff = trace2fit - model(fit_coefs, regressors)\n",
    "    return np.sum(diff**2) / trace2fit.shape[0]\n",
    "\n",
    "def reg_func(fit_coefs, reg_coef=0):\n",
    "    \"\"\" Regularization function: sum of absolute coefs values.\n",
    "    Does not regularize the offset, so first term is excluded:\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(fit_coefs[1:]))\n",
    "\n",
    "def minimization_func(fit_coefs, regressors, trace2fit, model, cost_func, reg_func, reg_lamda=0):\n",
    "    \"\"\"Full function to minimize, including cost and regularization terms.\n",
    "    \"\"\"\n",
    "    return cost_func(fit_coefs, regressors, trace2fit, model) + reg_func(fit_coefs) * reg_lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set starting values and bounds for the offset (the +1 below) and the coefficients.\n",
    "\n",
    "# Initial guesses:\n",
    "coefs_init_guess = np.zeros(regressors_mat.shape[0] + 1) \n",
    "\n",
    "# We know that IO input can only positively contribute to PC activity, \n",
    "# so we set IO coefficients to be positive:\n",
    "w_bound = 1000  # bound for regressors weights (high b/c of normalization differences) \n",
    "off_bound = 5  # bound for the offset\n",
    "coefs_bounds =[(-off_bound, off_bound)] + \\\n",
    "              [(0, w_bound) for _ in range(n_gc_clust)] + \\\n",
    "              [(0, w_bound) for _ in range(n_io_clust)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_bounds_dict = {'GC':coefs_bounds[:n_cluster_list[0]+1],\n",
    "                    'IO': [coefs_bounds[0]] + coefs_bounds[-n_cluster_list[1]:],\n",
    "                    'combo': coefs_bounds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test for the optimal regularization lambda. As this parameter search can take quite long, you can just skip the section and execute from the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = ['GC', 'IO', 'combo']\n",
    "\n",
    "regressors_mat_dict = {'GC': regressors_mat[:n_cluster_list[0], :],\n",
    "                       'IO': regressors_mat[-n_cluster_list[1]:, :],\n",
    "                       'combo': regressors_mat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the cost of a fit with all 0 coefficients is 1 - the std of the trace (which is zscored),\n",
    "# this will be our estimation of the cost that we use to decide the regularization lambda range \n",
    "# (2 orders of mag below and above the expected cost):\n",
    "reg_lambda_arr = np.insert(10**np.arange(-7., -2, 0.35), 0, 0)\n",
    "\n",
    "# Initialise empty matrices for storing the costs and the lambda parameters for all left-one-out fits:\n",
    "n_lambdas = reg_lambda_arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not force_rerun:\n",
    "    costs = fl.load(save_path/'regularization_costs.h5')\n",
    "\n",
    "else:\n",
    "    costs = {cell_type:np.full((n_rois, n_lambdas, n_reps_max - n_test_reps), np.nan) for cell_type in cell_types}\n",
    "\n",
    "    for cell_type in cell_types:\n",
    "        print('Working on fittings with {} regressors'.format(cell_type))\n",
    "\n",
    "        coefs_init_guess = np.zeros(regressors_mat_dict[cell_type].shape[0] + 1) \n",
    "\n",
    "        # Prepare a concatenation of regressors long enough to fit the longest possible trace:\n",
    "        regressors_concat = np.concatenate([regressors_mat_dict[cell_type],]*(n_reps_max - n_test_reps), 1).T\n",
    "\n",
    "        # Use scikit learn leave-one-out iterator:\n",
    "        loo = LeaveOneOut()\n",
    "\n",
    "        n_downsample = 1  # skip cells if we are testing. Otherwise, set to 1\n",
    "\n",
    "        for i_roi in range(0, n_rois, n_downsample):\n",
    "            if np.mod(i_roi, 50) == 0:\n",
    "                print(i_roi)\n",
    "            roi_fit_idxs = fit_idxs[i_roi]\n",
    "\n",
    "            # Hyperparameter grid search:\n",
    "            for i_lambda, reg_lambda in enumerate(reg_lambda_arr):\n",
    "\n",
    "                # Leave-one-out validation:\n",
    "                for i_loo, (idxs_train, idxs_valid) in enumerate(loo.split(roi_fit_idxs)):\n",
    "                    roi_train_trace = clean_traces[i_roi, :, roi_fit_idxs[idxs_train]].flatten()\n",
    "                    roi_valid_trace = clean_traces[i_roi, :, roi_fit_idxs[idxs_valid[0]]]\n",
    "                    res = optimize.minimize(minimization_func, method='SLSQP', \n",
    "                                            args=(regressors_concat[:roi_train_trace.shape[0], :], \n",
    "                                                  roi_train_trace, offset_cluster_combine, \n",
    "                                                  cost_func, reg_func, reg_lambda),\n",
    "                                            x0=coefs_init_guess, bounds=coef_bounds_dict[cell_type])\n",
    "\n",
    "                    costs[cell_type][i_roi, i_lambda, i_loo] = cost_func(res.x, regressors_concat[:roi_valid_trace.shape[0], :], \n",
    "                                                              roi_valid_trace, offset_cluster_combine)\n",
    "\n",
    "\n",
    "    fl.save(save_path/'regularization_costs.h5', costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418a92b7e0674ad1ad82999f061fda9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cell_type_cols = [cols[i] for i in [0,1,4]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5), sharey=True)\n",
    "\n",
    "for ax, cell_type, col in zip(axes, cell_types, cell_type_cols):\n",
    "    cost_arr_mean = np.nanmean(costs[cell_type], 2)\n",
    "    \n",
    "    ax.plot(range(n_lambdas), np.nanmean(cost_arr_mean, 0), c=col)\n",
    "    ax.fill_between(range(n_lambdas), \n",
    "                    np.nanmean(cost_arr_mean, 0)-np.nanstd(cost_arr_mean, 0),\n",
    "                    np.nanmean(cost_arr_mean, 0)+np.nanstd(cost_arr_mean, 0), color=col, alpha=.2, edgecolor=\"None\")\n",
    "    \n",
    "    ax.set_title(cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'reg_opti_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_within_std_err(cell_costs):\n",
    "    mean_cost = np.nanmean(cell_costs, 1)\n",
    "    std_err_cost = np.nanstd(cell_costs, 1) / np.sqrt(np.sum(~np.isnan(cell_costs[0, :])) - 1)\n",
    "\n",
    "    min_idx = np.argmin(mean_cost)\n",
    "    std_err_min = std_err_cost[min_idx]\n",
    "\n",
    "    i = min_idx\n",
    "    while i < len(mean_cost) - 1 and mean_cost[i + 1] < mean_cost[min_idx] + std_err_min:\n",
    "        i += 1\n",
    "    \n",
    "    if i != len(mean_cost) and mean_cost[i] < 1:\n",
    "        return i\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not force_rerun:\n",
    "    costs_final = fl.load(save_path/'costs_final.h5')\n",
    "    coefs_final = fl.load(save_path/'coefs_final.h5')\n",
    "    valid_roi_idxs = fl.load(save_path/'valid_roi_idxs.h5')\n",
    "\n",
    "    \n",
    "else:\n",
    "    costs_final = {cell_type: np.full(n_rois, np.nan) for cell_type in cell_types}  # Costs of our final fit\n",
    "    coefs_final = {cell_type: np.full((n_rois, regressors_mat_dict[cell_type].shape[0] + 1), np.nan) for cell_type in cell_types}  # Coefs from our final fit\n",
    "    valid_roi_idxs = {cell_type:[] for cell_type in cell_types}\n",
    "\n",
    "\n",
    "    for cell_type in cell_types:\n",
    "        print('Working on fittings with {} regressors'.format(cell_type))\n",
    "\n",
    "        #Set initial guesses\n",
    "        coefs_init_guess = np.zeros(regressors_mat_dict[cell_type].shape[0] + 1) \n",
    "\n",
    "        #Prepare a concatenation of regressors long enough to fit the longest possible trace:\n",
    "        regressors_concat = np.concatenate([regressors_mat_dict[cell_type],]*(n_reps_max - n_test_reps), 1).T\n",
    "\n",
    "        for i_roi in range(n_rois):\n",
    "            if np.mod(i_roi, 100) == 0:\n",
    "                print(i_roi)\n",
    "            cost_idx = max_within_std_err(costs[cell_type][i_roi, :, :])\n",
    "\n",
    "            if not np.isnan(cost_idx):\n",
    "                final_lambda_reg = reg_lambda_arr[cost_idx]\n",
    "\n",
    "                # Get test and fit indexes and traces:\n",
    "                roi_test_idxs = test_idxs[i_roi]\n",
    "                roi_test_trace = clean_traces[i_roi, :, roi_test_idxs].flatten()\n",
    "\n",
    "                roi_fit_idxs = fit_idxs[i_roi]\n",
    "                roi_fit_trace = clean_traces[i_roi, :, roi_fit_idxs].flatten()  \n",
    "\n",
    "                # Fit the train set:\n",
    "                res = optimize.minimize(minimization_func, method='SLSQP', \n",
    "                                        args=(regressors_concat[:roi_fit_trace.shape[0], :], \n",
    "                                              roi_fit_trace, offset_cluster_combine, \n",
    "                                              cost_func, reg_func, final_lambda_reg),\n",
    "                                              x0=coefs_init_guess, bounds=coef_bounds_dict[cell_type])\n",
    "\n",
    "                # Calculate cost on the test set:\n",
    "                costs_final[cell_type][i_roi] = cost_func(res.x, regressors_concat[:roi_test_trace.shape[0], :], \n",
    "                                                          roi_test_trace, offset_cluster_combine)\n",
    "                # Save the coefficients:\n",
    "                coefs_final[cell_type][i_roi, :] = res.x\n",
    "\n",
    "                valid_roi_idxs[cell_type].append(i_roi)\n",
    "                \n",
    "    \n",
    "    fl.save(save_path/'costs_final.h5', costs_final)\n",
    "    fl.save(save_path/'coefs_final.h5', coefs_final)\n",
    "    fl.save(save_path/'valid_roi_idxs.h5', valid_roi_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_roi_idxs_dict = {cell_type: np.array(valid_roi_idxs[cell_type]) for cell_type in cell_types}\n",
    "n_valid_rois = {cell_type: len(valid_roi_idxs[cell_type]) for cell_type in cell_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep data only from properly fit ROIs\n",
    "coefs_final_sel = {} \n",
    "costs_final_sel = {} \n",
    "clean_traces_sel = {} \n",
    "test_idxs_sel = {}\n",
    "fit_idxs_sel = {}\n",
    "rel_idx_sel = {}\n",
    "clust_lab_sel = {}\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    coefs_final_sel[cell_type] = coefs_final[cell_type][valid_roi_idxs[cell_type], :]\n",
    "    costs_final_sel[cell_type] = costs_final[cell_type][valid_roi_idxs[cell_type]]\n",
    "    clean_traces_sel[cell_type] = clean_traces[valid_roi_idxs[cell_type], :, :]\n",
    "    test_idxs_sel[cell_type] = [test_idxs[i] for i in valid_roi_idxs[cell_type]]\n",
    "    fit_idxs_sel[cell_type] = [fit_idxs[i] for i in valid_roi_idxs[cell_type]]\n",
    "    rel_idx_sel[cell_type] = data_dict[\"PC\"][\"rel_idxs\"][valid_roi_idxs[cell_type]]\n",
    "    clust_lab_sel[cell_type] = data_dict[\"PC\"][\"clust_labels\"][valid_roi_idxs[cell_type]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting with shuffled coefficients to set a random fit baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_shuf = {cell_type: np.full_like(coefs_final_sel[cell_type], np.nan) for cell_type in cell_types}\n",
    "costs_shuf = {cell_type: np.full(n_valid_rois[cell_type], np.nan) for cell_type in cell_types}  # Costs from shuffled weights\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    \n",
    "    #Prepare a concatenation of regressors long enough to fit the longest possible trace:\n",
    "    regressors_concat = np.concatenate([regressors_mat_dict[cell_type],]*(n_reps_max - n_test_reps), 1).T\n",
    "    \n",
    "    for i in range(coefs_final_sel[cell_type].shape[1]):\n",
    "        shuf_idx = np.random.permutation(coefs_final_sel[cell_type].shape[0])\n",
    "        coefs_shuf[cell_type][:, i] = coefs_final_sel[cell_type][shuf_idx, i]\n",
    "    \n",
    "    for i_roi in range(n_valid_rois[cell_type]):\n",
    "    \n",
    "        # Get test and fit indexes and traces:\n",
    "        roi_test_idxs = test_idxs_sel[cell_type][i_roi]\n",
    "        roi_test_trace = clean_traces_sel[cell_type][i_roi, :,roi_test_idxs].flatten()\n",
    "        \n",
    "        # Calculate cost on the test set with shuffled weights:\n",
    "        costs_shuf[cell_type][i_roi] = cost_func(coefs_shuf[cell_type][i_roi, :], regressors_concat[:roi_test_trace.shape[0], :], \n",
    "                                                 roi_test_trace, offset_cluster_combine)\n",
    "\n",
    "cost_threshold = {cell_type: np.percentile(costs_shuf[cell_type], 5) for cell_type in cell_types}\n",
    "sel_fit = {cell_type: np.argwhere(costs_final_sel[cell_type] < cost_threshold[cell_type])[:, 0] for cell_type in cell_types}\n",
    "n_valid_rois = {cell_type: len(sel_fit[cell_type]) for cell_type in cell_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieve original indexes of ROIs with a good fitting\n",
    "inclusion_mask = {cell_type: costs_final_sel[cell_type] < cost_threshold[cell_type] for cell_type in cell_types}\n",
    "final_sel_idxs = {cell_type:{} for cell_type in cell_types}\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    final_sel_idxs[cell_type] = np.array(valid_roi_idxs[cell_type])[inclusion_mask[cell_type]]\n",
    "    \n",
    "#And find ROIs with a good fitting with both GC and IO regressors\n",
    "total_fit_idxs = np.intersect1d(final_sel_idxs['GC'], final_sel_idxs['IO'])\n",
    "total_fit_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_figure(costs_final, costs_shuf, cost_threshold, cell_col, ax_coefs=None, frame=None):\n",
    "    \n",
    "    bin_array = np.arange(0.01, 1.6, 0.05)\n",
    "    costs_shuf_hist, b = np.histogram(costs_shuf, bin_array)\n",
    "    costs_final_hist, b = np.histogram(costs_final, bin_array)\n",
    "    costs_final_sel_hist, b = np.histogram(costs_final[costs_final < cost_threshold], bin_array)\n",
    "    \n",
    "    sel_fract = np.nansum(costs_final < cost_threshold) / np.sum(~np.isnan(costs_final))\n",
    "        \n",
    "    if ax_coefs is None:\n",
    "        figure = plt.figure(figsize=(3.,2))\n",
    "        ax_coefs = add_offset_axes(figure, (0.2, 0.2, 0.7, 0.7), frame=frame)\n",
    "            \n",
    "    a = 0.7\n",
    "    x = (bin_array[1:] + bin_array[:-1]) / 2\n",
    "    ax_coefs.fill_between(x, costs_shuf_hist, step=\"mid\", alpha=a, edgecolor=None, facecolor='lightgray')\n",
    "    ax_coefs.fill_between(x, costs_final_sel_hist, step=\"mid\", alpha=a, edgecolor=None, facecolor=cell_col)\n",
    "    ax_coefs.step(x, costs_final_hist, where=\"mid\", alpha=a, color=cell_col)\n",
    "    \n",
    "    ax_coefs.axvline(cost_threshold, c=(0.4,)*3)\n",
    "    ax_coefs.text(0.05, .95, '{:.2f}% PCs'.format(sel_fract*100), transform=ax_coefs.transAxes, c=cell_col, ha='left', fontsize=8.5)\n",
    "    ax_coefs.set_xlabel(\"Cost (on test)\")\n",
    "    ax_coefs.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f6950e9bb448ea8f8d0d21a99da15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(1, 0.45, 'Shuffled fits')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(13, 5), sharey=True)\n",
    "\n",
    "for i, cell_type in enumerate(cell_types):\n",
    "    cost_figure(costs_final[cell_type], costs_shuf[cell_type], cost_threshold[cell_type], cell_col=cell_type_cols[i], ax_coefs=axes[i])\n",
    "    axes[i].set_title('Fitting cost with {} regressors'.format(cell_type), c=(0.4,)*3)\n",
    "    \n",
    "# axes[2].text(1, .5, 'Regressor fits', transform=axes[2].transAxes, c=sns.color_palette()[3], ha='left', va='top', fontsize=8.5)\n",
    "axes[2].text(1, .45, 'Shuffled fits', transform=axes[2].transAxes, c='lightgray', ha='left', va='top', fontsize=8.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0e8db82698403a80ab773096653a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "\n",
    "for cell_type, col in zip(cell_types, cell_type_cols):\n",
    "    sns.kdeplot(costs_final[cell_type], c=col, ax=axes[0])\n",
    "axes[0].set_title('Regressor fits')\n",
    "    \n",
    "for cell_type, col in zip(cell_types, cell_type_cols):\n",
    "    sns.kdeplot(costs_shuf[cell_type], c=col, ax=axes[1])\n",
    "axes[1].set_title('Shuffled weigths')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Fitting costs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'fitting_costs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI fit explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roi_fits(roi_idx):\n",
    "    gc_fit_rank = ((np.argwhere(np.argsort(costs_final['GC']) == roi_idx)[0][0])/n_rois)*100\n",
    "    io_fit_rank = ((np.argwhere(np.argsort(costs_final['IO']) == roi_idx)[0][0])/n_rois)*100\n",
    "    combo_fit_rank = ((np.argwhere(np.argsort(costs_final['combo']) == roi_idx)[0][0])/n_rois)*100\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 5))\n",
    "\n",
    "    #Find train-test trials\n",
    "    roi_test_idxs = test_idxs[roi_idx]\n",
    "    test_traces = clean_traces[roi_idx, :, roi_test_idxs]\n",
    "\n",
    "    #Recover traces\n",
    "    roi_fit_idxs = fit_idxs[roi_idx]\n",
    "    fit_traces = clean_traces[roi_idx, :, roi_fit_idxs]\n",
    "\n",
    "    #Recover fit coefficients\n",
    "    gc_coefs = coefs_final['GC'][roi_idx, :]\n",
    "    io_coefs = coefs_final['IO'][roi_idx, :]\n",
    "    combo_coefs = coefs_final['combo'][roi_idx, :]\n",
    "\n",
    "    #Reconstruct fits\n",
    "    gc_fit = offset_cluster_combine(gc_coefs, regressors_mat_dict['GC'].T)\n",
    "    io_fit = offset_cluster_combine(io_coefs, regressors_mat_dict['IO'].T)\n",
    "    combo_fit = offset_cluster_combine(combo_coefs, regressors_mat_dict['combo'].T)\n",
    "\n",
    "    for row, traces in zip(range(2), [fit_traces, test_traces]):\n",
    "        for col, fit in enumerate([gc_fit, io_fit, combo_fit]):\n",
    "            for rep in range(traces.shape[0]):\n",
    "                axes[row, col].plot(traces[rep, :], 'gray', alpha=.2)\n",
    "            axes[row, col].plot(np.nanmean(traces, 0), c=cols[2])\n",
    "            axes[row, col].plot(fit, c=cell_type_cols[col])\n",
    "\n",
    "        for row, label in zip(range(len(cell_types)), ['Training set', 'Test set']):\n",
    "            axes[row, 0].set_ylabel(label, c='gray')\n",
    "\n",
    "        for col, title, rank in zip(range(len(cell_types)), ['GC regressors', 'IO regressors', 'combo regressors'], [gc_fit_rank, io_fit_rank, combo_fit_rank]):\n",
    "            axes[0, col].set_title('{} (best {:.2f}%)'.format(title, rank), c='gray')\n",
    "\n",
    "    plt.suptitle('ROI {} fits'.format(roi_idx), c='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbf1019a0034673bdf0edda1f5c031a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='roi_idx', max=671), Output()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_roi_fits(roi_idx)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_roi_fits,\n",
    "         roi_idx=widgets.IntSlider(min=0, max=n_rois-1, step=1, continuous_update=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387db85f7ed94ab587d876f86de24667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roi_fits(np.argsort(costs_final['combo'])[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'best_GC_fit.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefs_plot(clust_lab, coefs_final, cell_type, col, ax_coefs=None, frame=None):\n",
    "    \n",
    "    if ax_coefs is None:\n",
    "        figure = plt.figure(figsize=(4, 3))\n",
    "        ax_coefs = add_offset_axes(figure, (0.05, 0.2, 0.75, 0.8), frame=frame)\n",
    "    \n",
    "    idxs_sort = np.argsort(clust_lab)\n",
    "\n",
    "    c_lim = 125\n",
    "    im = ax_coefs.imshow(coefs_final[idxs_sort, 1:].T, vmin=0, vmax=c_lim, aspect=\"auto\", cmap=\"Reds\")\n",
    "    ax_coefs.set_xlabel(\"Roi n.\")\n",
    "\n",
    "    ax_coefs.set_yticks([])\n",
    "    ax_coefs.set_ylabel('{}'.format(cell_type), rotation=90, c=col, fontsize=10)\n",
    "    [ax_coefs.axes.spines[s].set_visible(False) for s in\n",
    "         [\"left\", \"right\", \"top\", \"bottom\"]]\n",
    "    for ytick, color in zip(ax_coefs.get_yticklabels(), sns.color_palette()[:2]):\n",
    "        ytick.set_color(color)\n",
    "\n",
    "    k = np.sum(clust_lab == 0)\n",
    "    for n in range(1, clust_lab.max() + 1): \n",
    "        ax_coefs.axvline(k, c='black')\n",
    "        k += np.sum(clust_lab == n)\n",
    "        \n",
    "#     axcolor = add_offset_axes(figure, [0.86, 0.2, 0.02, 0.12], frame=frame)\n",
    "#     cbar = plt.colorbar(im, orientation=\"vertical\")\n",
    "#     cbar.set_ticks([-c_lim, c_lim])\n",
    "#     cbar.ax.tick_params(length=3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6000178d04489d844caa51f8ae9f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\rplab\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: This figure was using constrained_layout, but that is incompatible with subplots_adjust and/or tight_layout; disabling constrained_layout.\n"
     ]
    }
   ],
   "source": [
    "figure, axes = plt.subplot_mosaic([['GC', 'combo'], ['IO', 'combo']],\n",
    "                              constrained_layout=True, figsize=(10, 5))\n",
    "\n",
    "for i, cell_type in enumerate(cell_types):\n",
    "    im = coefs_plot(clust_lab_sel[cell_type], coefs_final_sel[cell_type], cell_type, col=cell_type_cols[i], ax_coefs=axes[cell_type])\n",
    "    \n",
    "axes['combo'].axhline(n_cluster_list[0]-.5, c='black', ls='--')\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axes['combo'], orientation='vertical', shrink=.25)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure.savefig(fig_fold/'fitting_coefs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GC': 269, 'IO': 228, 'combo': 339}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_valid_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sel_idxs['IO'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sel_idxs['GC'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sel_idxs['combo'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# costs_arr = np.stack([costs_final[cell_type][final_sel_idxs['combo']] for cell_type in ['GC', 'IO', 'combo']]).T\n",
    "costs_arr = np.stack([costs_final[cell_type] for cell_type in ['GC', 'IO', 'combo']]).T\n",
    "\n",
    "cost_improv = {'GC': costs_arr[:, 2] - costs_arr[:, 0],\n",
    "               'IO': costs_arr[:, 2] - costs_arr[:, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b235ba7e567648fa9600e4edfa50a2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Single regressor fitting costs')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "\n",
    "for i, cell_type in enumerate(['GC', 'IO']):\n",
    "    axes[i].scatter(cost_improv[cell_type], costs_arr[:, i], c=cell_type_cols[i])\n",
    "    axes[i].axvline(0, ls='--', c='gray')\n",
    "    axes[i].set_xlabel('Combined fit cost change', fontsize=8)\n",
    "    axes[i].set_title('{} regressor fits'.format(cell_type), c='gray', fontsize=10)\n",
    "\n",
    "axes[0].set_ylabel('Single regressor fitting costs', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd7fd0a47ad4ea8b3389c10e601e1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Combined fitting costs')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "\n",
    "for i, cell_type in enumerate(['GC', 'IO']):\n",
    "    axes[i].scatter(cost_improv[cell_type], costs_arr[:, 2], c=cell_type_cols[i])\n",
    "    axes[i].axvline(0, ls='--', c='gray')\n",
    "    axes[i].axhline(cost_threshold['combo'], ls='--', c='gray', alpha=.5)\n",
    "    axes[i].set_xlabel('Combined fit cost change', fontsize=8)\n",
    "    axes[i].set_title('{} regressor fits'.format(cell_type), c='gray', fontsize=10)\n",
    "     \n",
    "\n",
    "axes[0].set_ylabel('Combined fitting costs', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66229716dddc4d2191bcd4163fe5ae06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "gs = gridspec.GridSpec(4, 4)\n",
    "\n",
    "scatter_ax = plt.subplot(gs[1:, 0:3])\n",
    "xkde_ax = plt.subplot(gs[0:1, 0:3], sharex=scatter_ax)\n",
    "ykde_ax = plt.subplot(gs[1:, 3:], sharey=scatter_ax)\n",
    "\n",
    "for i, cell_type in enumerate(['GC', 'IO']):\n",
    "    scatter_ax.scatter(cost_improv[cell_type], costs_arr[:, 2], c=cell_type_cols[i], edgecolors='none', alpha=.5)\n",
    "#     sns.kdeplot(cost_improv[cell_type], costs_arr[:, 2], c=cell_type_cols[i], ax=scatter_ax, alpha=.5)\n",
    "\n",
    "    sns.kdeplot(x=cost_improv[cell_type], c=cell_type_cols[i], ax=xkde_ax)\n",
    "    sns.kdeplot(y=costs_arr[:, 2], c=sns.color_palette()[4], ax=ykde_ax)\n",
    "\n",
    "scatter_ax.set_xlabel('Combined fit cost change', fontsize=8)\n",
    "scatter_ax.set_ylabel('Combined fitting costs', fontsize=8)\n",
    "\n",
    "scatter_ax.axvline(0, ls='--', c='gray', alpha=.5)\n",
    "scatter_ax.axhline(cost_threshold['combo'], ls='--', c='gray', alpha=.5)\n",
    "\n",
    "xkde_ax.axvline(0, ls='--', c='gray', alpha=.5)\n",
    "ykde_ax.axhline(cost_threshold['combo'], ls='--', c='gray', alpha=.5)\n",
    "    \n",
    "[label.set_visible(False) for label in xkde_ax.get_xticklabels()]\n",
    "[label.set_visible(False) for label in ykde_ax.get_yticklabels()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate stdevs\n",
    "combo_cost_std = np.nanstd(costs_arr[:, 2])\n",
    "\n",
    "cell_improv_std = {}\n",
    "for cell_type in ['GC', 'IO']:\n",
    "    cell_improv_std[cell_type] = np.nanstd(cost_improv[cell_type])\n",
    "    \n",
    "#Specify some cells that do not improve their fitting when combining regressors\n",
    "rebel_cells = {}\n",
    "\n",
    "for cell_type in ['GC', 'IO']:\n",
    "    rebel_cells[cell_type] = np.logical_and(cost_improv[cell_type]>(0-cell_improv_std[cell_type]/2), cost_improv[cell_type]<cell_improv_std[cell_type]/2)\n",
    "    \n",
    "rebelest_cells = np.logical_and(rebel_cells['GC'], rebel_cells['IO'])\n",
    "    \n",
    "#Specify some cells that are not fitted well\n",
    "poor_fits = costs_final['combo']>(cost_threshold['combo'] - (combo_cost_std/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_sel = np.nanmean(clean_traces, 2)[poor_fits, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   4,   5,   6,   7,   8,  10,  12,  13,  14,  15,  16,  18,\n",
       "        19,  21,  22,  26,  27,  28,  30,  31,  32,  34,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  45,  46,  52,  53,  54,  59,  61,  66,\n",
       "        67,  68,  69,  71,  72,  74,  75,  78,  80,  84,  85,  86,  88,\n",
       "        89,  90,  91,  95,  98, 101, 103, 104, 107, 108, 109, 110, 111,\n",
       "       112, 113, 114, 116, 117, 120, 121, 124, 127, 129, 137, 139, 140,\n",
       "       141, 144, 145, 146, 149, 150, 153, 155, 156, 158, 159, 160, 161,\n",
       "       162, 164, 166, 169, 172, 173, 179, 181, 183, 185, 188, 191, 193,\n",
       "       197, 198, 204, 207, 210, 211, 212, 214, 215, 216, 217, 220, 224,\n",
       "       225, 226, 227, 228, 229, 233, 239, 243, 245, 249, 255, 259, 260,\n",
       "       261, 267, 269, 270, 271, 272, 275, 278, 279, 281, 284, 287, 288,\n",
       "       290, 293, 295, 298, 299, 300, 302, 304, 305, 307, 308, 311, 313,\n",
       "       314, 316, 319, 320, 323, 324, 325, 327, 328, 329, 332, 333, 334,\n",
       "       338, 339, 340, 343, 347, 348, 349, 351, 352, 356, 358, 359, 360,\n",
       "       362, 364, 366, 367, 371, 374, 375, 377, 378, 380, 383, 386, 388,\n",
       "       391, 393, 396, 398, 400, 401, 404, 405, 406, 409, 410, 411, 415,\n",
       "       416, 419, 420, 423, 427, 428, 429, 430, 434, 435, 436, 437, 438,\n",
       "       442, 444, 445, 446, 447, 450, 451, 452, 454, 456, 457, 459, 460,\n",
       "       461, 463, 464, 465, 466, 467, 468, 469, 472, 473, 475, 477, 480,\n",
       "       481, 482, 484, 486, 487, 488, 489, 491, 492, 494, 496, 498, 499,\n",
       "       505, 506, 507, 508, 510, 511, 512, 513, 514, 515, 517, 518, 519,\n",
       "       521, 522, 523, 524, 525, 527, 529, 530, 532, 533, 534, 535, 536,\n",
       "       538, 539, 540, 543, 545, 546, 547, 548, 549, 550, 551, 553, 554,\n",
       "       556, 559, 560, 564, 568, 569, 570, 571, 573, 578, 580, 584, 585,\n",
       "       588, 589, 591, 592, 594, 595, 596, 597, 600, 603, 608, 613, 618,\n",
       "       619, 622, 624, 625, 626, 628, 629, 632, 634, 635, 639, 642, 643,\n",
       "       646, 647, 648, 649, 651, 656, 659, 664, 666, 668, 670], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(poor_fits)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b17d186646429392b358a4e58c09db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roi_fits(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=25)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform PCA\n",
    "pca = PCA(n_components=25) #Start by looking at the firts 25 PCs.\n",
    "pca.fit(cell_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d438c86433d24c8ba5bd0629967314b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the cumulative explained variance by the main PCs.\n",
    "x=np.arange(0,25,1)\n",
    "expl_var=np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "plt.plot(x, expl_var)\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of principal components based on the explained variance per PC above\n",
    "n_components = 18\n",
    "\n",
    "pca=PCA(n_components=n_components)\n",
    "roi_meanresps_pca=pca.fit_transform(cell_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e2499845754cbdb33da9b025f8c17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make elbow plot to choose optimal size of clusters\n",
    "distorsions = []\n",
    "\n",
    "for k in range(1, 25):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(roi_meanresps_pca) #Computes the clustering\n",
    "    distorsions.append(kmeans.inertia_) #Appends the inertia attirbute of the fit: Sum of squared distances of samples to their closest cluster center.\n",
    "\n",
    "figu = plt.figure(figsize=(5, 3))\n",
    "plt.plot(range(1,25), distorsions)\n",
    "plt.grid(True)\n",
    "plt.title('Elbow curve')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select number of clusters and clusterize\n",
    "n_clusters = 10\n",
    "\n",
    "kmeans_traces_pca = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(roi_meanresps_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"#45b2c4\",\n",
    "\"#cd5136\",\n",
    "\"#6977ca\",\n",
    "\"#9a9f3f\",\n",
    "\"#a35ac7\",\n",
    "\"#56a95d\",\n",
    "\"#cf4597\",\n",
    "\"#c08340\",\n",
    "\"#c17ab4\",\n",
    "\"#c6596a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347f2c3b35bf48b1b2ddbd252e04866b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\rplab\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Use the colorbar set_ticks() method instead.\n",
      "C:\\tools\\miniconda3\\envs\\rplab\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Use the colorbar set_ticks() method instead.\n"
     ]
    }
   ],
   "source": [
    "#Define Gridspec\n",
    "cluster_fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "gs = gridspec.GridSpec(8,22)\n",
    "gs.update(wspace=0.25, hspace=0)\n",
    "ax1 = plt.subplot(gs[:1, 2:12])\n",
    "ax2 = plt.subplot(gs[:1, 12:])\n",
    "ax3 = plt.subplot(gs[1:, 2:12])\n",
    "ax4 = plt.subplot(gs[1:, 12:])\n",
    "ax5 = plt.subplot(gs[3:6, 0:1])\n",
    "\n",
    "#Stimulus panels\n",
    "ax1.plot(stim_ref[:, 0], stim_ref[:, 1], c='black')\n",
    "ax1.set_xlim(np.min(stim_ref[:, 0]), np.max(stim_ref[:, 0]))\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.plot(stim_ref[:, 0], stim_ref[:, 1], c='black')\n",
    "ax2.set_xlim(np.min(stim_ref[:, 0]), np.max(stim_ref[:, 0]))\n",
    "ax2.axis('off')\n",
    "\n",
    "#Traces heatmap\n",
    "heatmap = ax3.imshow(cell_sel[np.argsort(kmeans_traces_pca),:], aspect='auto', cmap='RdBu_r', vmin=-2.5, vmax=2.5, origin='upper')\n",
    "unique, counts = np.unique(kmeans_traces_pca, return_counts=True)\n",
    "yticks=[]\n",
    "tick = 0\n",
    "\n",
    "for cluster, roi_num in zip(unique, counts):\n",
    "    yticks.append(tick)\n",
    "    tick += counts[cluster]\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks(yticks)\n",
    "ax3.set_yticklabels(unique+1)\n",
    "for tick in yticks:\n",
    "    ax3.axhline(tick, ls=':', color='black')\n",
    "\n",
    "for tick, col in zip(ax3.yaxis.get_major_ticks(), color_list):\n",
    "    tick.label1.set_color(col)\n",
    "\n",
    "#Average cluster responses\n",
    "cluster, cells = np.unique(kmeans_traces_pca, return_counts=True)\n",
    "cluster_roi_count = dict(zip(cluster, cells))\n",
    "\n",
    "for cluster, color in zip(np.unique(kmeans_traces_pca), color_list):\n",
    "    cluster_traces = cell_sel[kmeans_traces_pca==cluster,:]\n",
    "    mean = np.nanmean(cluster_traces, 0)\n",
    "    std = np.nanstd(cluster_traces, 0)\n",
    "\n",
    "    ax4.plot(stim_ref[:, 0], nanzscore(cell_sel[kmeans_traces_pca==cluster,:].mean(0))-cluster*5, c=color, label=cluster)\n",
    "\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticks([])\n",
    "ax4.set_xlim([stim_ref[0,0], stim_ref[-1, 0]])\n",
    "\n",
    "sns.despine(left=True)\n",
    "cluster_fig.suptitle('Clustered responses by {} main PCs'.format(n_components))\n",
    "\n",
    "plt.colorbar(heatmap, cax=ax5)\n",
    "ax5.set_yticks([])\n",
    "ax5.set_xticks([])\n",
    "ax5.set_ylabel('Fluorescence (norm.)')\n",
    "ax5.yaxis.set_label_position('left')\n",
    "ax5.yaxis.tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 426)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "gs = gridspec.GridSpec(4, 4)\n",
    "\n",
    "scatter_ax = plt.subplot(gs[1:, 0:3])\n",
    "xkde_ax = plt.subplot(gs[0:1, 0:3], sharex=scatter_ax)\n",
    "ykde_ax = plt.subplot(gs[1:, 3:], sharey=scatter_ax)\n",
    "\n",
    "for i, cell_type in enumerate(['GC', 'IO']):\n",
    "    scatter_ax.scatter(cost_improv[cell_type][rebel_cells[cell_type]], costs_arr[:, 2][rebel_cells[cell_type]], c=cell_type_cols[i], edgecolors='none', alpha=.35)\n",
    "#     sns.kdeplot(cost_improv[cell_type], costs_arr[:, 2], c=cell_type_cols[i], ax=scatter_ax, alpha=.5)\n",
    "\n",
    "    sns.kdeplot(x=cost_improv[cell_type], c=cell_type_cols[i], ax=xkde_ax)\n",
    "    sns.kdeplot(y=costs_arr[:, 2], c=cell_type_cols[i], ax=ykde_ax)\n",
    "\n",
    "for line in ykde_ax.get_lines():\n",
    "    line.set_alpha(0.5)\n",
    "\n",
    "scatter_ax.set_xlabel('Combined fit cost change', fontsize=8)\n",
    "scatter_ax.set_ylabel('Combined fitting costs', fontsize=8)\n",
    "\n",
    "scatter_ax.axvline(0, ls='--', c='gray', alpha=.5)\n",
    "scatter_ax.axhline(cost_threshold['combo'], ls='--', c='gray', alpha=.5)\n",
    "\n",
    "xkde_ax.axvline(0, ls='--', c='gray', alpha=.5)\n",
    "ykde_ax.axhline(cost_threshold['combo'], ls='--', c='gray', alpha=.5)\n",
    "    \n",
    "[label.set_visible(False) for label in xkde_ax.get_xticklabels()]\n",
    "[label.set_visible(False) for label in ykde_ax.get_yticklabels()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "gs = gridspec.GridSpec(4, 4)\n",
    "\n",
    "scatter_ax = plt.subplot(gs[1:, 0:3])\n",
    "xkde_ax = plt.subplot(gs[0:1, 0:3], sharex=scatter_ax)\n",
    "ykde_ax = plt.subplot(gs[1:, 3:], sharey=scatter_ax)\n",
    "\n",
    "for i, cell_type in enumerate(['GC', 'IO']):\n",
    "    scatter_ax.scatter(cost_improv[cell_type][poor_fits], costs_arr[:, 2][poor_fits], c=cell_type_cols[i], edgecolors='none', alpha=.35)\n",
    "#     sns.kdeplot(cost_improv[cell_type], costs_arr[:, 2], c=cell_type_cols[i], ax=scatter_ax, alpha=.5)\n",
    "\n",
    "    sns.kdeplot(x=cost_improv[cell_type], c=cell_type_cols[i], ax=xkde_ax)\n",
    "    sns.kdeplot(y=costs_arr[:, 2], c=cell_type_cols[i], ax=ykde_ax)\n",
    "\n",
    "for line in ykde_ax.get_lines():\n",
    "    line.set_alpha(0.5)\n",
    "\n",
    "scatter_ax.set_xlabel('Combined fit cost change', fontsize=8)\n",
    "scatter_ax.set_ylabel('Combined fitting costs', fontsize=8)\n",
    "\n",
    "scatter_ax.axvline(0, ls='--', c='gray', alpha=.5)\n",
    "scatter_ax.axhline(cost_threshold['combo'], ls='--', c='gray', alpha=.5)\n",
    "\n",
    "xkde_ax.axvline(0, ls='--', c='gray', alpha=.5)\n",
    "ykde_ax.axhline(cost_threshold['combo'], ls='--', c='gray', alpha=.5)\n",
    "    \n",
    "[label.set_visible(False) for label in xkde_ax.get_xticklabels()]\n",
    "[label.set_visible(False) for label in ykde_ax.get_yticklabels()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poor_fits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(poor_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_idxs = {}\n",
    "\n",
    "for cell_type in ['GC', 'IO']:\n",
    "    \n",
    "    inspect_idxs[cell_type] = rebel_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(rebel_cells['GC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebel_cells[cell_type] and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanargmin(a[[0,2], :], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin([0,np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(np.nanmean(a[1] - a[0]))\n",
    "plt.plot( a[1] - a[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(costs_final['GC'], costs_final['IO'], c=cols[2])\n",
    "ax.axline([.4,.40], [1,1], c='gray', ls='--')\n",
    "ax.set_xlim([0.4, 1.3])\n",
    "ax.set_ylim([0.4, 1.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(costs_final['GC'], costs_final['IO'], costs_final['combo'], c=cols[2])\n",
    "\n",
    "# ax.set_xlim3d(0, 3.5)\n",
    "# ax.set_ylim3d(0, 3.5)\n",
    "# ax.set_zlim3d(0, 3.5)\n",
    "\n",
    "ax.set_xlabel('{} fit cost'.format(cell_types[0]))\n",
    "ax.set_ylabel('{} fit cost'.format(cell_types[1]))\n",
    "ax.set_zlabel('{} fit cost'.format(cell_types[2]))\n",
    "\n",
    "plt.title('Velocity effect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time contribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contributions_mat = np.zeros((n_rep_timepts, n_valid_rois['combo']))\n",
    "coefs_gc = np.zeros(coefs_final_sel['combo'].shape)\n",
    "coefs_io = np.zeros(coefs_final_sel['combo'].shape)\n",
    "coefs_gc[:, 1:9] = coefs_final_sel['combo'][:, 1:9]\n",
    "coefs_io[:, 9:] = coefs_final_sel['combo'][:, 9:]\n",
    "\n",
    "for i_roi in range(n_valid_rois['combo']):\n",
    "       \n",
    "    gc_contribution = offset_cluster_combine(coefs_gc[i_roi, :], regressors_mat.T)\n",
    "    io_contribution = offset_cluster_combine(coefs_io[i_roi, :], regressors_mat.T)\n",
    "    \n",
    "    contribution_ratio = (np.abs(gc_contribution) - np.abs(io_contribution)) / \\\n",
    "                (np.abs(gc_contribution) + np.abs(io_contribution))\n",
    "    \n",
    "    time_contributions_mat[:, i_roi] = contribution_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_contr_plot(time_contributions_mat, stim, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(7, 3))\n",
    "    \n",
    "        ax = add_offset_axes(figure, (0.1, 0.1, 0.9, 0.9), frame=frame)\n",
    "\n",
    "    # Find quartiles:\n",
    "    median_contr = np.nanmedian(time_contributions_mat, 1)\n",
    "    low_quart_contr = np.nanquantile(time_contributions_mat, 0.25, axis=1)\n",
    "    high_quart_contr = np.nanquantile(time_contributions_mat, 0.75, axis=1)\n",
    "    \n",
    "    # Plot trace and filling:\n",
    "    i_col=5\n",
    "    ax.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "    ax.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col], \n",
    "                         alpha=.3, zorder=100, edgecolor=None)\n",
    "    shade_plot(stim, ax, shade_range=(0.75, 0.98))\n",
    "    ax.axhline(0, c = (0.3,)*3, zorder=1)\n",
    "    ax.set_ylim(-1., 1.)\n",
    "    ax.set_xlim(0, stim[-1, 0])\n",
    "#     for y_line in [-1, 1]:\n",
    "#         ax.axhline(y_line, color=(0.3,)*3, linewidth=0.5)\n",
    "    \n",
    "    make_bar(ax, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "    ax.set_ylabel('Contribution ratio')\n",
    "    ax.text(0.025, .95, 'GC contributions dominates', fontsize=9, color=sns.color_palette()[0], transform=ax.transAxes, va='center')\n",
    "    ax.text(0.025, .05, 'IO contributions dominates', fontsize=9, color=sns.color_palette()[1], transform=ax.transAxes, va='center')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contr_plot(time_contributions_mat, stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_final_sel['GC'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_final_sel['IO'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_final_sel['combo'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check error histogram and relationship with cell reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check error of the fit as a function of the cell reliability index. We expect a negative relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(7, 3), sharey=True)\n",
    "\n",
    "for ax, cell_type, c in zip(axes, cell_types, range(2)):\n",
    "    ax.scatter(rel_idxs, costs_final[cell_type], c='none', edgecolors=cols[c], linewidths=.25, s=7)\n",
    "    ax.scatter(rel_idxs[final_sel_idxs[cell_type]], costs_final[cell_type][final_sel_idxs[cell_type]], c=cols[c], s=7)\n",
    "    \n",
    "#     error_vs_reliabil(rel_idx_sel[cell_type], costs_final_sel[cell_type], ax, c=cols[c])\n",
    "    \n",
    "for ax, cell_type in zip(axes, cell_types):\n",
    "    ax.set_title('Fits with {} regressors'.format(cell_type), c='gray', fontsize=10)\n",
    "    ax.set_xlabel(\"Reliability idx\", fontsize=8.5)\n",
    "    ax.set_ylabel(\"Fit error\", fontsize=8.5)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2, figsize=(7, 3), sharey=True)\n",
    "\n",
    "# for ax, cell_type, c in zip(axes, cell_types, range(2)):\n",
    "#     ax.scatter(rel_idx_sel[cell_type], costs_final_sel[cell_type], c=cols[c], s=5)\n",
    "    \n",
    "# #     error_vs_reliabil(rel_idx_sel[cell_type], costs_final_sel[cell_type], ax, c=cols[c])\n",
    "    \n",
    "# for ax, cell_type in zip(axes, cell_types):\n",
    "#     ax.set_title('Fits with {} regressors'.format(cell_type), c='gray', fontsize=10)\n",
    "#     ax.set_xlabel(\"Reliability idx\", fontsize=8.5)\n",
    "#     ax.set_ylabel(\"Fit error\", fontsize=8.5)\n",
    "    \n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'fitting_coefs_rel.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GC-IO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_io_idx = (1/(costs_final['GC']) - 1/(cost\n",
    "                                        nal['IO']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a IO-GC colormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors = [sns.color_palette()[1], (.72,)*3, sns.color_palette()[0]]\n",
    "n_bins = 200\n",
    "cmap_name = 'contributions_cmap'\n",
    "custom_cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].scatter(costs_final['GC'], costs_final['IO'], c='none', edgecolor=cols[2], linewidth=.25, s=7)\n",
    "axes[0].scatter(costs_final['GC'][total_fit_idxs], costs_final['IO'][total_fit_idxs], c=cols[2], s=7)\n",
    "axes[0].plot([0, 1], [0, 1], transform=axes[0].transAxes, c='gray', ls='--')\n",
    "\n",
    "axes[0].set_ylabel('IO fitting costs', fontsize=8)\n",
    "axes[0].set_xlabel('GC fitting costs', fontsize=8)\n",
    "\n",
    "\n",
    "r = stats.spearmanr(gc_io_idx[total_fit_idxs], rel_idxs[total_fit_idxs])\n",
    "axes[1].axvline(0, c = (0.6, )*3, zorder=-100)\n",
    "\n",
    "edge_cols = custom_cmap(gc_io_idx)\n",
    "axes[1].scatter(gc_io_idx, rel_idxs, facecolor='none', edgecolor='white', s=7, linewidths=.075)\n",
    "axes[1].scatter(gc_io_idx[total_fit_idxs], rel_idxs[total_fit_idxs], c=gc_io_idx[total_fit_idxs], cmap=custom_cmap, s=6, vmin=-0.1, vmax=0.1, \n",
    "           edgecolor=(0.3,)*3, linewidths=0.1)\n",
    "\n",
    "#     ax.set_xlim(-1.1, 1.1)\n",
    "axes[1].set_ylabel(\"Reliability index\")\n",
    "axes[1].set_xlabel(\"GC-IO idx\")\n",
    "#     numbers = \n",
    "axes[1].text(.05, .95, \"$\\\\rho$\" + \"={:1.2f} \\np={:1.2}\".format(r.correlation, r.pvalue), fontsize=7, color=(0.3,)*3, transform=axes[1].transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_fold/'gc_io_idx.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_diffs = {cell_type: np.full((n_rois, clean_traces.shape[1]), np.nan) for cell_type in cell_types}\n",
    "\n",
    "for roi_idx in range(n_rois):\n",
    "    \n",
    "    #Find train-test trials\n",
    "    roi_test_idxs = test_idxs[roi_idx]\n",
    "    test_traces = clean_traces[roi_idx, :, roi_test_idxs]\n",
    "\n",
    "    #Recover traces\n",
    "    roi_fit_idxs = fit_idxs[roi_idx]\n",
    "    fit_traces = clean_traces[roi_idx, :, roi_fit_idxs]\n",
    "\n",
    "    #Recover fit coefficients\n",
    "    gc_coefs = coefs_final['GC'][roi_idx, :]\n",
    "    io_coefs = coefs_final['IO'][roi_idx, :]\n",
    "\n",
    "    #Reconstruct fits\n",
    "    gc_fit = offset_cluster_combine(gc_coefs, regressors_mat_dict['GC'].T)\n",
    "    io_fit = offset_cluster_combine(io_coefs, regressors_mat_dict['IO'].T)\n",
    "\n",
    "    #Calculate error between fit and average test trace   \n",
    "    fit_diffs['GC'][roi_idx, :] = (np.nanmean(test_traces, 0) - gc_fit)**2\n",
    "    fit_diffs['IO'][roi_idx, :] = (np.nanmean(test_traces, 0) - io_fit)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contributions_mat = np.full((n_rois, clean_traces.shape[1]), np.nan)\n",
    "\n",
    "for roi in range(n_rois):\n",
    "    time_contributions_mat[roi, :] = fit_diffs['GC'][roi, :] - fit_diffs['IO'][roi, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contributions_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.argsort(costs_final['IO'])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(14,4))\n",
    "\n",
    "ax = add_offset_axes(figure, (0.1, 0.1, 0.9, 0.9))\n",
    "\n",
    "# Find quartiles:\n",
    "median_contr = np.nanmedian(time_contributions_mat[total_fit_idxs], 0)\n",
    "low_quart_contr = np.nanquantile(time_contributions_mat[total_fit_idxs], 0.25, axis=0)\n",
    "high_quart_contr = np.nanquantile(time_contributions_mat[total_fit_idxs], 0.75, axis=0)\n",
    "\n",
    "# Plot trace and filling:\n",
    "i_col=5\n",
    "ax.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "ax.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col], \n",
    "                     alpha=.3, zorder=100, edgecolor=None)\n",
    "shade_plot(stim, ax, shade_range=(0.75, 0.98))\n",
    "ax.axhline(0, c = (0.3,)*3, zorder=1)\n",
    "ax.set_xlim(0, stim[-1, 0])\n",
    "#     for y_line in [-1, 1]:\n",
    "#         ax.axhline(y_line, color=(0.3,)*3, linewidth=0.5)\n",
    "\n",
    "make_bar(ax, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "ax.set_ylabel('Fitting error')\n",
    "ax.text(0.025, .97, 'Fits w/ GC', fontsize=7, color=sns.color_palette()[0], transform=ax.transAxes, va='center')\n",
    "ax.text(0.025, .03, 'Fits w/ IO', fontsize=7, color=sns.color_palette()[1], transform=ax.transAxes, va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure.savefig(fig_fold/'time_contr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 1.5))\n",
    "    \n",
    "# Find quartiles:\n",
    "median_contr = np.nanmedian(time_contributions_mat, 0)\n",
    "low_quart_contr = np.nanquantile(time_contributions_mat, 0.25, axis=0)\n",
    "high_quart_contr = np.nanquantile(time_contributions_mat, 0.75, axis=0)\n",
    "\n",
    "plt.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "plt.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contributions_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trace and filling:\n",
    "i_col=5\n",
    "ax.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "ax.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col], \n",
    "                     alpha=.3, zorder=100, edgecolor=None)\n",
    "shade_plot(stim, ax, shade_range=(0.75, 0.98))\n",
    "ax.axhline(0, c = (0.3,)*3, zorder=1)\n",
    "ax.set_xlim(0, stim[-1, 0])\n",
    "#     for y_line in [-1, 1]:\n",
    "#         ax.axhline(y_line, color=(0.3,)*3, linewidth=0.5)\n",
    "\n",
    "make_bar(ax, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "ax.set_ylabel('Contribution ratio')\n",
    "ax.text(0.5, 1.05, 'GC contributions dominates', fontsize=7, color=sns.color_palette()[0])\n",
    "ax.text(0.5, -1.15, 'IO contributions dominates', fontsize=7, color=sns.color_palette()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.fill_between(stim[:,0], low_quart_contr, high_quart_contr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_quart_contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_idx = np.argsort(costs_final['GC'])[2]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 5))\n",
    "\n",
    "#Find train-test trials\n",
    "roi_test_idxs = test_idxs[roi_idx]\n",
    "test_traces = clean_traces[roi_idx, :, roi_test_idxs]\n",
    "\n",
    "#Recover traces\n",
    "roi_fit_idxs = fit_idxs[roi_idx]\n",
    "fit_traces = clean_traces[roi_idx, :, roi_fit_idxs]\n",
    "\n",
    "#Recover fit coefficients\n",
    "gc_coefs = coefs_final['GC'][roi_idx, :]\n",
    "io_coefs = coefs_final['IO'][roi_idx, :]\n",
    "\n",
    "#Reconstruct fits\n",
    "gc_fit = offset_cluster_combine(gc_coefs, regressors_mat_dict['GC'].T)\n",
    "io_fit = offset_cluster_combine(io_coefs, regressors_mat_dict['IO'].T)\n",
    "\n",
    "\n",
    "\n",
    "for row, traces in zip(range(2), [fit_traces, test_traces]):\n",
    "    for col, fit in zip(range(2), [gc_fit, io_fit]):\n",
    "        for rep in range(traces.shape[0]):\n",
    "            axes[row, col].plot(traces[rep, :], 'gray', alpha=.2)\n",
    "        axes[row, col].plot(np.nanmean(traces, 0), c=cols[2])\n",
    "        axes[row, col].plot(fit, c=cols[col])\n",
    "        \n",
    "\n",
    "    for row, label in zip(range(2), ['Training set', 'Test set']):\n",
    "        axes[row, 0].set_ylabel(label, c='gray')\n",
    "        \n",
    "    for col, title in zip(range(2), ['GC regressors', 'IO regressors']):\n",
    "        axes[0, col].set_title(title, c='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at distribution of IO and GC coefficients weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_coefs = coefs_final_sel.copy()\n",
    "cleaned_coefs = cleaned_coefs[~(cleaned_coefs == 0).all(1), :]\n",
    "coefs_sum = np.nansum(np.abs(cleaned_coefs), 1)\n",
    "norm_coefs = (cleaned_coefs.T / coefs_sum).T\n",
    "non_zero_coefs = np.abs(norm_coefs) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_io_weights_hist(cleaned_coefs, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3,2))\n",
    "        \n",
    "    ax = add_offset_axes(figure, (0.2, 0.2, 0.7, 0.7), frame=frame)\n",
    "    l=400\n",
    "    ax.hist(cleaned_coefs[:, 1:9].sum(1), np.arange(-l, l, 20), alpha=0.6, label=\"GC\")\n",
    "    ax.hist(cleaned_coefs[:, 9:].sum(1), np.arange(-l, l, 20), alpha=0.6, label=\"IO\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Weight of coefs\")\n",
    "    ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_io_weights_hist(cleaned_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at distribution of number of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_io_nonzero_hist(non_zero_coefs, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3,2))\n",
    "        \n",
    "    ax = add_offset_axes(figure, (0.2, 0.2, 0.7, 0.7), frame=frame)\n",
    "    ax.hist(non_zero_coefs[:, 1:9].sum(1), np.arange(0, 15), \n",
    "            label=\"GC (mn={:2.1f})\".format(np.nanmean(non_zero_coefs[:, 1:9].sum(1))), alpha=0.6)\n",
    "    ax.hist(non_zero_coefs[:, 9:].sum(1), np.arange(0, 15), \n",
    "            label=\"IO (mn={:2.1f})\".format(np.nanmean(non_zero_coefs[:, 9:].sum(1))), alpha=0.6)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"N. of coefs\")\n",
    "    ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_io_nonzero_hist(non_zero_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GC-IO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"GC vs IO-ness index\", looking at the ratio of coefficients of GC clusters and IO clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gc = np.abs(coefs_final_sel[:, 1:n_gc_clust+1]).mean(1)\n",
    "w_io = np.abs(coefs_final_sel[:, n_gc_clust+1:]).mean(1)\n",
    "gc_io_idx = (w_gc - w_io) / (w_gc + w_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a IO-GC colormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors = [sns.color_palette()[1], (.72,)*3, sns.color_palette()[0]]\n",
    "n_bins = 200\n",
    "cmap_name = 'contributions_cmap'\n",
    "custom_cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_plot(gc_io_idx, rel_idxs, figure=None, frame=None):\n",
    "    r = stats.spearmanr(gc_io_idx[~np.isnan(gc_io_idx)], rel_idxs[~np.isnan(gc_io_idx)])\n",
    "    \n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3., 2.))\n",
    "    \n",
    "    ax = add_offset_axes(figure, (0.2, 0.2, 0.7, 0.7), frame=frame)\n",
    "    ax.axvline(0, c = (0.6, )*3, zorder=-100)\n",
    "    ax.scatter(gc_io_idx, rel_idxs, c=gc_io_idx, cmap=custom_cmap, s=6, vmin=-1, vmax=1, \n",
    "               edgecolor=(0.3,)*3, linewidths=0.1)\n",
    "    ax.set_xlim(-1.1, 1.1)\n",
    "    ax.set_ylabel(\"Reliability index\")\n",
    "    ax.set_xlabel(\"GC/IO idx\")\n",
    "#     numbers = \n",
    "    ax.text(-1, 0.7, \"$\\\\rho$\" + \"={:1.2f} \\np={:1.2}\".format(r.correlation, r.pvalue), fontsize=7, color=(0.3,)*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_plot(gc_io_idx, rel_idx_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single cell example fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11, 17, 32, 33, (44), 71\n",
    "\n",
    "37, 60, 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_cell_plot(traces, all_coefs, roi_test_idxs, idx, \n",
    "                          legend=True, bar=True, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(7, 2))\n",
    "    coefs = all_coefs[idx, :]\n",
    "    roi_test_idxs = test_idxs[idx]\n",
    "    reshaped = traces[idx, :, roi_test_idxs]\n",
    "    \n",
    "    ylim = 3.7\n",
    "    axtrace = add_offset_axes(figure, (0.0, 0.1, 0.58, 0.92), frame=frame)\n",
    "    axtrace.plot(stim[:, 0], reshaped.T, color=sns.color_palette()[2], linewidth=0.5)\n",
    "    axtrace.plot(stim[:, 0], np.nanmean(reshaped, 0), color=sns.color_palette()[2], linewidth=2, label=\"PC trace\")\n",
    "    axtrace.plot(stim[:, 0], nanzscore(offset_cluster_combine(coefs, regressors_mat.T)), color=\"k\", label=\"Fit\")\n",
    "    shade_plot(stim, axtrace, shade_range=(0.75, 0.98))\n",
    "    \n",
    "    axtrace.set_ylim(-ylim, ylim)\n",
    "    axtrace.set_xlim(0, stim[-1, 0])\n",
    "    axtrace.spines[\"left\"].set_visible(False)\n",
    "    axtrace.set_yticks([])\n",
    "    if bar:\n",
    "        make_bar(axtrace, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "    else:\n",
    "        axtrace.spines[\"bottom\"].set_visible(False)\n",
    "        axtrace.set_xticks([])\n",
    "    \n",
    "    # Legend\n",
    "    handles, labels = axtrace.get_legend_handles_labels()\n",
    "    unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]\n",
    "    if legend:\n",
    "        plt.legend(*zip(*unique), loc=\"lower left\", fontsize=7)\n",
    "    \n",
    "    # Inserts\n",
    "    ylim = 1.5\n",
    "    y_off = -0.5\n",
    "    coefs_gc = np.zeros(coefs.shape)\n",
    "    coefs_io = np.zeros(coefs.shape)\n",
    "    coefs_gc[1:9] = coefs[1:9]\n",
    "    coefs_io[9:] = coefs[9:]\n",
    "    for n, (ax_pos, lab, c_coefs) in enumerate(zip([(0.6, 0.6, 0.4, 0.4), (0.6, 0.1, 0.4, 0.4)], \n",
    "                                                   [\"GC\", \"IO\"],\n",
    "                                                   [coefs_gc, coefs_io])):\n",
    "        col = sns.color_palette()[n]\n",
    "        ax_little = add_offset_axes(figure, ax_pos, frame=frame)\n",
    "        ax_little.plot(stim[:, 0], offset_cluster_combine(c_coefs, regressors_mat.T), color=col)\n",
    "        shade_plot(stim, ax_little, shade_range=(0.75, 0.98))\n",
    "        ax_little.set_ylim(-ylim-y_off, ylim-y_off)\n",
    "        ax_little.axis(\"off\")\n",
    "        \n",
    "        if legend:\n",
    "            ax_little.text(2, -ylim-y_off + 0.2, lab + \" contribution\", color=col, fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cells  # (gc_io idx sort): \n",
    "- 97, 254 example IO\n",
    "- 197, example comb\n",
    "- 89, 115, 60 example comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "97, 197, 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = costs_final_sel < 0.9\n",
    "idx = np.argsort(gc_io_idx[sel])[-11]\n",
    "make_single_cell_plot(clean_traces_sel, coefs_final_sel, fit_idxs_sel, idx, figure=None, frame=None)\n",
    "# for idx in [98]:\n",
    "#     make_single_cell_plot(clean_traces_sel, coefs_final_sel, fit_idxs_sel, idx, figure=None, frame=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time contribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contributions_mat = np.zeros((n_rep_timepts, n_valid_rois))\n",
    "coefs_gc = np.zeros(coefs_final_sel.shape)\n",
    "coefs_io = np.zeros(coefs_final_sel.shape)\n",
    "coefs_gc[:, 1:9] = coefs_final_sel[:, 1:9]\n",
    "coefs_io[:, 9:] = coefs_final_sel[:, 9:]\n",
    "\n",
    "for i_roi in range(n_valid_rois):\n",
    "       \n",
    "    gc_contribution = offset_cluster_combine(coefs_gc[i_roi, :], regressors_mat.T)\n",
    "    io_contribution = offset_cluster_combine(coefs_io[i_roi, :], regressors_mat.T)\n",
    "    \n",
    "    contribution_ratio = (np.abs(gc_contribution) - np.abs(io_contribution)) / \\\n",
    "                (np.abs(gc_contribution) + np.abs(io_contribution))\n",
    "    \n",
    "    time_contributions_mat[:, i_roi] = contribution_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_contr_plot(time_contributions_mat, stim, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(7, 1.5))\n",
    "    \n",
    "    ax = add_offset_axes(figure, (0.1, 0.1, 0.9, 0.9), frame=frame)\n",
    "\n",
    "    # Find quartiles:\n",
    "    median_contr = np.nanmedian(time_contributions_mat, 1)\n",
    "    low_quart_contr = np.nanquantile(time_contributions_mat, 0.25, axis=1)\n",
    "    high_quart_contr = np.nanquantile(time_contributions_mat, 0.75, axis=1)\n",
    "    \n",
    "    # Plot trace and filling:\n",
    "    i_col=5\n",
    "    ax.plot(stim[:, 0], median_contr, color=sns.color_palette()[i_col])\n",
    "    ax.fill_between(stim[:,0], low_quart_contr, high_quart_contr, facecolor=sns.color_palette()[i_col], \n",
    "                         alpha=.3, zorder=100, edgecolor=None)\n",
    "    shade_plot(stim, ax, shade_range=(0.75, 0.98))\n",
    "    ax.axhline(0, c = (0.3,)*3, zorder=1)\n",
    "    ax.set_ylim(-1., 1.)\n",
    "    ax.set_xlim(0, stim[-1, 0])\n",
    "#     for y_line in [-1, 1]:\n",
    "#         ax.axhline(y_line, color=(0.3,)*3, linewidth=0.5)\n",
    "    \n",
    "    make_bar(ax, (stim[-1, 0]-10, stim[-1, 0]), label=\"10 s\")\n",
    "    ax.set_ylabel('Contribution ratio')\n",
    "    ax.text(0.5, 1.05, 'GC contributions dominates', fontsize=7, color=sns.color_palette()[0])\n",
    "    ax.text(0.5, -1.15, 'IO contributions dominates', fontsize=7, color=sns.color_palette()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_contr_plot(time_contributions_mat, stim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble final panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_names = [\"IO{}\".format(i+1) for i in range(n_io_clust)] + [\"GC{}\".format(i+1) for i in range(n_gc_clust)]\n",
    "cols = [sns.color_palette()[1]]*n_io_clust + [sns.color_palette()[0]]*n_gc_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the regressor panel:\n",
    "def reg_panel_plot(regressors_mat, figure=None, ax=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3, 3))\n",
    "\n",
    "    offset = 0.01\n",
    "    if ax is None:\n",
    "        ax = add_offset_axes(figure, (0., 0., 1, 1), frameon=False, frame=frame)\n",
    "    cols = sns.color_palette()\n",
    "    for i, col in enumerate([cols[0], ]*n_gc_clust + [cols[1], ]*n_io_clust):\n",
    "        ax.fill_between(stim[:, 0], np.zeros(stim[:, 0].shape) - i*offset, \n",
    "                        regressors_mat[i, :] - i*offset, color=col)\n",
    "        \n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "# Plot a trace panel:\n",
    "def little_trace_plot(clean_traces, i=0, figure=None, ax=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3, 1))\n",
    "\n",
    "    if ax is None:\n",
    "        ax = add_offset_axes(figure, (0., 0., 1, 1), frameon=False, frame=frame)\n",
    "    offset = 0.01\n",
    "    ax.plot(clean_traces[i, :, :1].T.flatten(), c=sns.color_palette()[2])\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema_panel(clean_traces, regressors_mat, i=9, figure=None, frame=None):\n",
    "    if figure is None:        \n",
    "        figure = plt.figure(figsize=(7, 3))\n",
    "\n",
    "    schema_y = 0.3\n",
    "\n",
    "    h_cent = 0.5\n",
    "    trace_h = 0.2\n",
    "    reg_h = 0.9\n",
    "    schema_h = 0.9\n",
    "    ax_trace = add_offset_axes(figure, [0.7, h_cent - trace_h/2, 0.3, trace_h], frameon=False, frame=frame)\n",
    "    ax_regressors = add_offset_axes(figure, [0.02, h_cent - reg_h/2 - 0.01, 0.3, reg_h], frameon=False, frame=frame)\n",
    "    ax_schema = add_offset_axes(figure, [0.31, h_cent - schema_h/2, 0.4, schema_h], frameon=False, aspect=1., frame=frame)\n",
    "    little_trace_plot(clean_traces, i=18, figure=figure, ax=ax_trace)\n",
    "\n",
    "    reg_panel_plot(regressors_mat, figure=figure, ax=ax_regressors)\n",
    "\n",
    "    ax_schema.xaxis.set_visible(False)\n",
    "    ax_schema.yaxis.set_visible(False)\n",
    "\n",
    "    n_clust = 14\n",
    "    n_gc_clust\n",
    "    n_io_clust\n",
    "    c_cent = (0.6, 0.5)  # x, y\n",
    "    p = mpatches.Circle(c_cent, 0.1, edgecolor=\"k\", facecolor=\"w\")\n",
    "\n",
    "    w_pos_x = 0.0\n",
    "    line_displ_x = 0.2\n",
    "    for i_clust, (label, col) in enumerate(zip(clust_names, cols)):\n",
    "        c = 1/(2*(n_clust + 1)) + i_clust/(n_clust + 1)\n",
    "        l = lines.Line2D([w_pos_x + line_displ_x, c_cent[0]], [c, c_cent[1]], c=\"k\", zorder=-100)\n",
    "        ax_schema.add_line(l)\n",
    "        ax_schema.text(w_pos_x, c, \"$\\cdot w_i^{\" + label + \"}$\", ha=\"left\", va=\"center\", fontsize=7, color=col)\n",
    "\n",
    "    c = 1/(2*n_clust) + (i_clust + 1)/(n_clust + 1)\n",
    "    l = lines.Line2D([w_pos_x + line_displ_x, c_cent[0]], [c, c_cent[1]], c=\"k\", zorder=-100)\n",
    "    ax_schema.add_line(l)\n",
    "    ax_schema.text(w_pos_x, c, \"$offset_i$\", ha=\"left\", va=\"center\", fontsize=7, color=\"k\")\n",
    "\n",
    "    ax_schema.add_patch(p)\n",
    "\n",
    "    l = lines.Line2D([c_cent[0], 1], [c_cent[1], c_cent[1]], c=\"k\", zorder=-100)\n",
    "    ax_schema.add_line(l)\n",
    "\n",
    "    # Text\n",
    "    ax_schema.text(*c_cent, \"$\\sum$\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "    ax_schema.text(0.55, 0.9, \"$PC_i = regr^{GC} \\cdot w_i^{GC} + regr^{IO} \\cdot w_i^{IO} + offset_i$\", \n",
    "                   ha=\"left\", va=\"center\", fontsize=7.5)\n",
    "    ax_trace.text(0, -3, \"$PC_i$\", ha=\"left\", va=\"center\", fontsize=9, color=sns.color_palette()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 9))\n",
    "schema_panel(clean_traces, regressors_mat, i=9, figure=fig, frame=[0.25, 0.77, 0.6, 0.2])\n",
    "\n",
    "offset_y = 0.13\n",
    "start_y = 0.36\n",
    "for i, idx in enumerate([97, 197, 89]):\n",
    "    y = start_y + i*offset_y\n",
    "    \n",
    "    make_single_cell_plot(clean_traces_sel, coefs_final_sel, fit_idxs_sel, idx, figure=fig, frame=[0., y, 0.53, 0.12], legend=(i==2), bar=(i==0))\n",
    "\n",
    "coefs_plot(clust_lab_sel, coefs_final_sel, figure=fig, frame=[0.58, 0.56, 0.4, 0.18])\n",
    "indexes_plot(gc_io_idx, rel_idx_sel, figure=fig, frame=[0.58, 0.35, 0.35, 0.2])\n",
    "time_contr_plot(time_contributions_mat, stim, figure= fig, frame=[0.1, 0.17, 0.65, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    fig.savefig(fig_fold / \"fig7_panel.pdf\", forma=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsupp = plt.figure(figsize=(6, 4))\n",
    "s = 0.45\n",
    "cost_figure(costs_final, costs_shuf, cost_threshold, figure=figsupp, frame=[0., 0.5, s, s])\n",
    "error_vs_reliabil(rel_idx_sel, costs_final_sel, figure=figsupp, frame=[0.5, 0.5, s, s])\n",
    "# gc_io_weights_hist(cleaned_coefs, figure=figsupp, frame=[0., 0., s, s])\n",
    "gc_io_nonzero_hist(non_zero_coefs, figure=figsupp, frame=[0.25, 0., s, s])\n",
    "# sorted_examples_plot(coefs_final, gc_io_idx, clean_traces, test_idxs, figure=figure6supp, frame=[0.5, 0.1, 0.5, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    figsupp.savefig(fig_fold.parent.parent / (fig_fold.parent.name + \"supp/src\") / \"supp_panel.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

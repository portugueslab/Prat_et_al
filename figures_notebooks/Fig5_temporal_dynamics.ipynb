{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import flammkuchen as fl\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "plt.style.use(\"figures.mplstyle\")\n",
    "cols = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fold = Path(r\"C:\\Users\\otprat\\Documents\\figures\\luminance\\manuscript_figures\\fig5\")\n",
    "\n",
    "if not os.path.isdir(fig_fold):\n",
    "    os.mkdir(fig_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from luminance_analysis import traces_stim_from_path, PooledData\n",
    "from luminance_analysis.utilities import deconv_resamp_norm_trace, reliability, \\\n",
    "    nanzscore, get_kernel, pearson_regressors, get_mn_and_error, train_test_split\n",
    "from luminance_analysis.plotting import shade_plot, make_bar, get_yg_custom_cmap, add_offset_axes\n",
    "from luminance_analysis.clustering import find_trunc_dendro_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path = Path(r\"\\\\FUNES2\\legacy\\experiments\\E0032_luminance\\neat_exps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_6f = 5\n",
    "ker_len = 30\n",
    "delay = 3\n",
    "n_clust_list = [4, 5, 4] * 2\n",
    "normalization = \"zscore\"\n",
    "\n",
    "protocol = \"flashes\"\n",
    "brain_regions_list = [\"GC\", \"IO\", \"PC\"]\n",
    "\n",
    "data_dict = {\"{}_{}\".format(r, protocol):{} for r in [\"GC\", \"IO\", \"PC\"]}\n",
    "\n",
    "for brain_region, n_clust in zip([\"GC\", \"IO\", \"PC\"], n_clust_list):\n",
    "    path = master_path / protocol / brain_region\n",
    "    stim, traces, _ = traces_stim_from_path(path)\n",
    "\n",
    "    # Mean traces, calculate reliability index :\n",
    "    rel_idxs = reliability(traces)\n",
    "    \n",
    "    # Find threshold from reliability histogram...\n",
    "    rel_thr = threshold_otsu(rel_idxs[~np.isnan(rel_idxs)])\n",
    "\n",
    "    # ...and load again filtering with the threshold:\n",
    "    _, traces, meanresps = traces_stim_from_path(path, resp_threshold=rel_thr, nanfraction_thr=1)\n",
    "    rel_idxs = reliability(traces)\n",
    "    \n",
    "    \n",
    "    # Fix problem with interpolated stimulus values between intermediate luminance levels:\n",
    "    invalid_idxs = np.array([stim[:, 1] != n for n in [0, 1, 0.2, 0.05]]).all(0)  # find invalid indexes\n",
    "    if sum(invalid_idxs) > 0:\n",
    "        stim[np.argwhere(invalid_idxs), 1] = stim[np.argwhere(invalid_idxs)-1, 1]  # replace with following value\n",
    "\n",
    "    # Cluster traces (needed for the sorted plots):\n",
    "    linked = linkage(meanresps, \"ward\")    \n",
    "\n",
    "    # make truncated tree to get clusters ids. \n",
    "    # Ugly but necessary to get the correct sequence of leaves:\n",
    "    plt.figure(figsize=(0.1, 0.1))  \n",
    "    dendro = dendrogram(linked, n_clust, truncate_mode =\"lastp\")\n",
    "    plt.close()\n",
    "    cluster_ids = dendro[\"leaves\"]\n",
    "    labels = find_trunc_dendro_clusters(linked, dendro)\n",
    "    \n",
    "    # Add everything to dictionary:\n",
    "    key = \"{}_{}\".format(brain_region, protocol)\n",
    "    data_dict[key][\"raw_traces\"] = traces\n",
    "    data_dict[key][\"rel_idxs\"] = rel_idxs\n",
    "    data_dict[key][\"mean_traces\"] = meanresps\n",
    "    data_dict[key][\"stim\"] = stim\n",
    "    data_dict[key][\"clust_labels\"] = labels\n",
    "    data_dict[key][\"pooled\"] = PooledData(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center of mass plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times in seconds at which the transitions occour:\n",
    "step_t_sec_list = [2, 12, 26]\n",
    "post_int_s_list = [3, 7, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indexes of the \"luminance ON\" clusters are manually specified according to results in fig. 3:\n",
    "for cell_type, excited_clusters in zip([\"GC\", \"IO\", \"PC\"], [[1,2,3], [1, 3, 4], [2, 3]]):\n",
    "    traces = data_dict[cell_type + \"_flashes\"][\"raw_traces\"]\n",
    "    stim = data_dict[cell_type + \"_flashes\"][\"stim\"]\n",
    "    pooled_data = data_dict[cell_type + \"_flashes\"][\"pooled\"]\n",
    "    labels = data_dict[cell_type + \"_flashes\"][\"clust_labels\"]\n",
    "\n",
    "    # Select only excitatory clusters (clustering is done as in fig. 3):\n",
    "    sel_idxs = np.argwhere(np.array([labels == n for n in excited_clusters]).any(0))[:, 0]\n",
    "    sel_traces = traces[sel_idxs, :, :]\n",
    "    sel_rel_idxs = data_dict[cell_type + \"_flashes\"][\"rel_idxs\"][sel_idxs]\n",
    "\n",
    "    # To cross validate, we will sort the averages of half responses and the display the other half:\n",
    "    order_traces, test_traces = train_test_split(sel_traces)  # Split repetitions in sort and test blocks\n",
    "    order_means, test_means = np.nanmean(order_traces, 2), np.nanmean(test_traces, 2)\n",
    "\n",
    "    #Find response center of mass and time of maximal response in the \"order\" block during the longest stimulus:\n",
    "    stim_i = 2\n",
    "    step_t, post_int = step_t_sec_list[stim_i], post_int_s_list[stim_i]\n",
    "\n",
    "    # Crop the traces matrix in the stimulus range:\n",
    "    responses = order_means[:, slice(*pooled_data.frame_from_t([step_t, step_t+post_int]))]\n",
    "\n",
    "    # Normalize to have integral of 1:\n",
    "    responses = (responses.T - responses.min(1)).T\n",
    "    responses = (responses.T/responses.sum(1)).T\n",
    "\n",
    "    # Center of mass for each trace: (for sorting reps)\n",
    "    centerofmass = responses.shape[1]*((np.arange(responses.shape[1])*responses).mean(1))\n",
    "    ordered_idx = np.argsort(centerofmass)\n",
    "    \n",
    "    # Center of mass for each trace: (for plotting reps)\n",
    "    test_responses = test_means[:, slice(*pooled_data.frame_from_t([step_t, step_t+post_int]))]\n",
    "    test_responses = (test_responses.T - test_responses.min(1)).T\n",
    "    test_responses = (test_responses.T/test_responses.sum(1)).T\n",
    "    test_centerofmass = test_responses.shape[1]*((np.arange(test_responses.shape[1])*test_responses).mean(1))\n",
    "\n",
    "    # We will plot the means of the not-sorted traces, and their peak times:\n",
    "    test_mean_sm = pd.DataFrame(test_means.T).rolling(4, center=True).mean().values.T  # smooth\n",
    "    test_mean_sm = ((test_mean_sm.T - np.nanmean(test_mean_sm, 1))/np.nanstd(test_mean_sm, 1)).T  # z score\n",
    "\n",
    "    # Find time of maximal response:\n",
    "    pad_pre = 1\n",
    "    pad_post = 2\n",
    "    responses = test_mean_sm[:, slice(*pooled_data.frame_from_t([step_t, step_t+post_int]))]\n",
    "    peak_times = np.argmax(responses, 1)\n",
    "    \n",
    "    data_dict[cell_type + \"_flashes\"][\"ordered_idx\"] = ordered_idx\n",
    "    data_dict[cell_type + \"_flashes\"][\"test_mean_sm\"] = test_mean_sm\n",
    "    data_dict[cell_type + \"_flashes\"][\"peak_times\"] = peak_times\n",
    "    data_dict[cell_type + \"_flashes\"][\"rel_idxs_sel\"] = sel_rel_idxs\n",
    "    data_dict[cell_type + \"_flashes\"][\"sel_idxs\"] = sel_idxs\n",
    "    data_dict[cell_type + \"_flashes\"][\"order_coms\"] = centerofmass\n",
    "    data_dict[cell_type + \"_flashes\"][\"test_coms\"] = test_centerofmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_traces_plot(data_dict, cell_type=\"GC\", bars=True, figure=None, frame=None, cplot_h=1):\n",
    "    l = 2  # colormap ranges\n",
    "    pad_pre = 1  # padding before stim starts\n",
    "    pad_post = 2  # padding after\n",
    "    num_groups = 11  # number of percentile groups for the mean traces\n",
    "\n",
    "    # Control x displacement of the plots:\n",
    "    offset_val = 0.04  \n",
    "    offset = 0.1\n",
    "    \n",
    "    ordered_idx = data_dict[cell_type + \"_flashes\"][\"ordered_idx\"]\n",
    "    test_mean_sm = data_dict[cell_type + \"_flashes\"][\"test_mean_sm\"]\n",
    "    peak_times = data_dict[cell_type + \"_flashes\"][\"peak_times\"]\n",
    "\n",
    "    custom_cm = get_yg_custom_cmap(n=100)\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(7,3))\n",
    "\n",
    "    for i, (step_t, post_int) in enumerate(zip(step_t_sec_list, post_int_s_list)):  # loop over flashes\n",
    "\n",
    "        w = 0.7 * (post_int_s_list[i] / sum(post_int_s_list))  # y width of the plot\n",
    "\n",
    "        # Crop stimulus array for the shade plot:\n",
    "        stim_cropped = stim[slice(*pooled_data.frame_from_t([step_t-pad_pre, step_t+post_int+pad_post])), :]\n",
    "\n",
    "        # Add axes and make the color plot:\n",
    "        ax_mat = add_offset_axes(figure, (offset, 0.2, w, 0.5*cplot_h), frame=frame)\n",
    "        #ax_mat = figure.add_axes()\n",
    "        to_plot = test_mean_sm[ordered_idx, slice(*pooled_data.frame_from_t([step_t-pad_pre, step_t+post_int+pad_post]))]\n",
    "        im = ax_mat.imshow(to_plot[::, :],  aspect=\"auto\", cmap=\"RdBu_r\", vmin=-l, vmax=+l, interpolation='none')\n",
    "\n",
    "        # Add axes and plot average trace of percentiles:\n",
    "        ax_traces = add_offset_axes(figure, (offset, 0.21 + 0.5*cplot_h, w, 0.25), frame=frame)\n",
    "        cells_per_group = to_plot.shape[0] // num_groups\n",
    "\n",
    "        for group in range(num_groups):\n",
    "            y = np.nanmean(to_plot[cells_per_group*group:cells_per_group*(group+1), :], 0)\n",
    "            plt.plot(stim_cropped[:, 0], y - y.min(), c=custom_cm.reversed()(group/num_groups),  linewidth=1.5)\n",
    "        ax_traces.set_xlim(stim_cropped[0, 0], stim_cropped[-1, 0])\n",
    "        \n",
    "        shade_plot(stim_cropped)\n",
    "\n",
    "        ax_mat.axis(\"off\")\n",
    "        ax_traces.axis(\"off\")\n",
    "\n",
    "        offset += w + offset_val  # offset of next plot\n",
    "\n",
    "    # Scatter the peak times:\n",
    "#     ax_mat.scatter(peak_times[ordered_idx], np.arange(len(peak_times)), color=(0.3,)*3, s=1)\n",
    "#     ax_mat.set_ylim(len(peak_times)-0.5, 0)\n",
    "\n",
    "    # Time bar, only on the last plot:\n",
    "    if bars:\n",
    "        dt = stim[1,0]\n",
    "        barlength = 4/dt\n",
    "        ax_mat.axis(\"on\")\n",
    "        ax_mat.axes.spines[\"left\"].set_visible(False)\n",
    "        ax_mat.set_yticks([])\n",
    "        make_bar(ax_mat, [len(y) - barlength, len(y)-1], label=\"{} s\".format(round(barlength*dt)), lw=2)\n",
    "        \n",
    "        axcolor = add_offset_axes(figure, (0.07, 0.2, 0.015, 0.15), frame=frame)\n",
    "        cbar1 = plt.colorbar(im, cax=axcolor, orientation=\"vertical\")\n",
    "        cbar1.set_ticks([-l, l])\n",
    "        cbar1.ax.tick_params(length=3)\n",
    "        axcolor.yaxis.set_ticks_position('left')\n",
    "        axcolor.yaxis.set_label_position('left')\n",
    "        axcolor.set_ylabel(\"dF/F\")\n",
    "\n",
    "    # Color bar for response position:\n",
    "    sm = plt.cm.ScalarMappable(cmap=custom_cm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    bar_cmap = add_offset_axes(figure, (offset - offset_val+0.003, 0.2, 0.015, 0.5*cplot_h), frame=frame)\n",
    "    cbar = plt.colorbar(sm, cax=bar_cmap, orientation=\"vertical\", ticks=[.18, .82])\n",
    "    cbar.ax.set_yticklabels([\"Late\", \"Early\"], rotation=90, va=\"center\")\n",
    "    cbar.ax.tick_params(length=0)\n",
    "    cbar.outline.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_traces_plot(data_dict, cell_type=\"GC\", cplot_h=0.5)\n",
    "# sorted_traces_plot(data_dict, cell_type=\"IO\", cplot_h=0.5)\n",
    "# sorted_traces_plot(data_dict, cell_type=\"PC\", cplot_h=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDE with peak times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def peaks_kde(data_dict, figure=None, frame=None):\n",
    "#     if figure is None:\n",
    "#         figure = plt.figure(figsize = (4,2))\n",
    "#     ax = add_offset_axes(figure, (0.15, 0.25, 0.8, 0.6), frame=frame)\n",
    "#     off = 0\n",
    "#     for i, cell_type in enumerate([\"GC\", \"IO\"]):\n",
    "#         ordered_idx = data_dict[cell_type + \"_flashes\"][\"ordered_idx\"]\n",
    "#         test_mean_sm = data_dict[cell_type + \"_flashes\"][\"test_mean_sm\"]\n",
    "#         peak_times = data_dict[cell_type + \"_flashes\"][\"peak_times\"]\n",
    "#         x_arr = np.arange(-40, test_mean_sm.shape[1])\n",
    "#         kde = gaussian_kde(peak_times)(x_arr)\n",
    "#         ax.fill_between(x_arr * stim[1, 0], kde/np.max(kde) -np.ones(len(x_arr))*off*i, -i*off, alpha=0.6)\n",
    "#         ax.text(20, 0.9-i*0.15, cell_type, color=sns.color_palette()[i], fontsize=7)\n",
    "#     ax.set_xlim(-1, 23)\n",
    "#     ax.set_xlabel(\"Time from stim. onset(s)\")\n",
    "#     ax.set_ylabel(\"Peak distr. (a.u.)\")\n",
    "#     ax.set_yticks([0, 0.4, 0.8])\n",
    "#     ax.set_ylim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_kde(data_dict, celltypes=[\"GC\", \"IO\", \"PC\"], figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize = (4,2))\n",
    "    ax = add_offset_axes(figure, (0.15, 0.25, 0.8, 0.6), frame=frame)\n",
    "    off = 0\n",
    "    for i, cell_type in enumerate(celltypes):\n",
    "        ordered_idx = data_dict[cell_type + \"_flashes\"][\"ordered_idx\"]\n",
    "        test_mean_sm = data_dict[cell_type + \"_flashes\"][\"test_mean_sm\"]\n",
    "        peak_times = data_dict[cell_type + \"_flashes\"][\"peak_times\"]\n",
    "        x_arr = np.arange(-40, test_mean_sm.shape[1])\n",
    "        kde = gaussian_kde(peak_times)(x_arr)\n",
    "        ax.plot(x_arr * stim[1, 0], kde/kde.max() -np.ones(len(x_arr))*off*i, linewidth=2, label=cell_type)\n",
    "        ax.fill_between(x_arr * stim[1, 0], kde/np.max(kde) -np.ones(len(x_arr))*off*i, -i*off, alpha=0.3)\n",
    "        ax.text(22, 0.9-i*0.15, cell_type, color=sns.color_palette()[i], fontsize=7)\n",
    "    ax.set_xlim(-1, 23)\n",
    "    ax.set_xlabel(\"Time from stim. onset(s)\")\n",
    "    ax.set_ylabel(\"Peak distr. (a.u.)\")\n",
    "    ax.set_yticks([0, 0.4, 0.8])\n",
    "    ax.set_ylim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_kde(data_dict, celltypes=[\"GC\", \"IO\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual cell plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_cell_plot(data_dict, idxs, off=2, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(5, 2))\n",
    "    ax = add_offset_axes(figure, [0.1, 0.2, 0.9, 0.8], frame=frame)\n",
    "    \n",
    "    for n, i in enumerate(idxs):\n",
    "        cell_trace = data_dict[\"GC_flashes\"][\"raw_traces\"][i, :, :].copy()\n",
    "        cell_trace = pd.DataFrame(cell_trace).rolling(4, center=True).mean().values  # smooth\n",
    "        cell_trace = (cell_trace - np.nanmean(cell_trace, 0))/np.nanstd(cell_trace, 0)  # normalise\n",
    "    \n",
    "        ax.plot(stim[:, 0], cell_trace-n*off, linewidth=0.3, \n",
    "                color=get_yg_custom_cmap(n=len(idxs)).reversed()(n/len(idxs)))\n",
    "        ax.plot(stim[:, 0], np.nanmean(cell_trace, 1)-n*off, linewidth=2, \n",
    "                color=get_yg_custom_cmap(n=len(idxs)).reversed()(n/len(idxs)))\n",
    "    \n",
    "    shade_plot(stim)\n",
    "    ax.set_xlim(0, stim[-1, 0])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines[\"left\"].set_visible(False) \n",
    "    make_bar(ax, [stim[-1, 0]-5, stim[-1,0]], label=\"5 s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find good example of ramping cell with high reliability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_idxs = data_dict[\"GC_flashes\"][\"rel_idxs\"]\n",
    "labels = data_dict[\"GC_flashes\"][\"clust_labels\"]\n",
    "\n",
    "idxs = np.argwhere((labels == 3) & (rel_idxs > 0.65))[:,0]\n",
    "print(idxs[27])  # high-quality, organic hand-picked cell ramping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_cell_plot(data_dict, [idxs[27]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cell_plot(data_dict, [313, 2164, 325], off=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_dir = Path().resolve().parent/'decoding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_decoding_dict = fl.load(decoding_dir / 'duration_decoding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_duration_decoding(decoding_dict, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize = (4,4))\n",
    "        \n",
    "    ax = add_offset_axes(figure, (0.05, 0.05, 0.95, 0.95), frame=frame)\n",
    "    \n",
    "    pred_mn = np.nanmean(decoding_dict['GC']['full_pred'], 0)\n",
    "    pred_sd = np.nanstd(decoding_dict['GC']['full_pred'], 0)\n",
    "\n",
    "    ax.fill_between(decoding_dict['GC']['time'], pred_mn-pred_sd, pred_mn+pred_sd, color=(0.1,0.1,0.1,0.07), linewidth=0)\n",
    "    ax.plot(decoding_dict['GC']['time'], pred_mn, label=\"GCs average\", c=sns.color_palette()[0])\n",
    "    ax.scatter(decoding_dict['IO']['time'], np.concatenate([decoding_dict['GC']['preds'][0], decoding_dict['GC']['preds'][1]]), color=sns.color_palette()[0], s=.4, label=\"GCs subset\")\n",
    "    ax.scatter(decoding_dict['IO']['time'], decoding_dict['IO']['preds'], color=sns.color_palette()[1], s=.4, label=\"IONs\")\n",
    "\n",
    "    ax.plot(decoding_dict['GC']['time'], decoding_dict['GC']['time'], color=(0.3, 0.3, 0.3,0.7))\n",
    "    ax.set_xlabel(\"Actual time since onset (s)\")\n",
    "    ax.set_ylabel(\"Predicted time since onset (s)\")\n",
    "    ax.set_aspect(1)\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_duration_decoding(duration_decoding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble final figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure5 = plt.figure(figsize=(6, 6))\n",
    "figure5 = plt.figure(figsize=(6, 9))\n",
    "\n",
    "single_cell_plot(data_dict, [313, 2164, 325], off=4, figure=figure5, frame=(0.12, 0.775, 0.7, 0.2))\n",
    "# plt.ylim(-9.8, 3.8)\n",
    "figure5.text(0.15, 0.98, 'A')\n",
    "\n",
    "sorted_traces_plot(data_dict, cell_type=\"GC\", figure=figure5, frame=(0.05, 0.5, .95, 0.3), bars=False)\n",
    "figure5.text(0.1, 0.79, 'B')\n",
    "\n",
    "# #sorted_traces_plot(data_dict, cell_type=\"IO\", figure=figure5, frame=(0.05, 0.17, .95, 0.36), cplot_h=0.4)\n",
    "sorted_traces_plot(data_dict, cell_type=\"IO\", figure=figure5, frame=(0.05, 0.3, .95, 0.35), cplot_h=0.4, bars=True)\n",
    "figure5.text(0.1, 0.53, 'C')\n",
    "\n",
    "# sorted_traces_plot(data_dict, cell_type=\"PC\", figure=figure5, frame=(0.05, 0.325, .95, 0.35), cplot_h=0.4)\n",
    "\n",
    "peaks_kde(data_dict, celltypes=[\"GC\", \"IO\"], figure=figure5, frame=(0.05, 0.075, .45, 0.25))\n",
    "figure5.text(0.025, 0.3, 'D')\n",
    "\n",
    "plot_duration_decoding(duration_decoding_dict, figure=figure5, frame=(0.45, 0.05, .6, 0.3))\n",
    "figure5.text(0.475, 0.34, 'E')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    figure5.savefig(str(fig_fold / \"sorted.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplementary figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fold = Path(r\"C:\\Users\\otprat\\Documents\\figures\\luminance\\manuscript_figures\\fig5supp\")\n",
    "\n",
    "if not os.path.isdir(fig_fold):\n",
    "    os.mkdir(fig_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COM crossvalidation reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_crossval_com_rel(data_dict, vmin, vmax, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(9, 3))\n",
    "\n",
    "    brain_regions = ['GC_flashes', 'IO_flashes']\n",
    "    colors = sns.color_palette()[:3]\n",
    "    \n",
    "    for i, (brain_region, color) in enumerate(zip(brain_regions, colors)):\n",
    "        \n",
    "        ax_scatter = add_offset_axes(figure, (0.075 + .3*i, 0.15, .25, .8), frame=frame)\n",
    "        \n",
    "        rel_cmap = LinearSegmentedColormap.from_list('rel_map', [[0.9, 0.9, 0.9], color], N=100)\n",
    "        \n",
    "        dt = data_dict['IO_flashes']['pooled'].dt_im\n",
    "        \n",
    "        points = ax_scatter.scatter(data_dict[brain_region]['order_coms']*dt - pad_pre, data_dict[brain_region]['test_coms']*dt - pad_pre, \n",
    "                        c=data_dict[brain_region][\"rel_idxs_sel\"], cmap=rel_cmap, vmin=vmin, vmax=vmax)\n",
    "        \n",
    "        ax_scatter.set_xlabel('COM in plotted reps. [s.]')\n",
    "        \n",
    "        lims = [2, 16]\n",
    "        ax_scatter.set_ylim([lims[0], lims[1]])\n",
    "        ax_scatter.set_xlim([lims[0], lims[1]])        \n",
    "        ax_scatter.plot(lims, lims, ls='--', c='black', alpha=.35)\n",
    "            \n",
    "        #Colorbar\n",
    "        axcolor = add_offset_axes(figure, (.63 + 0.015*i, 0.4, .01, .3), frame=frame)\n",
    "        cbar = plt.colorbar(points, cax=axcolor, shrink=.5)\n",
    "        cbar.set_ticks([])\n",
    "        \n",
    "        if i == 0:\n",
    "            ax_scatter.set_ylabel('COM in sorting reps. [s.]')\n",
    "            cbar.set_label('Reliability coef.', labelpad=-15)\n",
    "        elif i == 2:\n",
    "            cbar.set_ticks([vmin, vmax])\n",
    "            \n",
    "        # r & p values\n",
    "        r_val, p_val = stats.pearsonr(data_dict[brain_region]['order_coms']*dt - pad_pre, \n",
    "                                      data_dict[brain_region]['test_coms']*dt - pad_pre)\n",
    "        \n",
    "        ax_scatter.text(.1, .85, 'r = {:.4f} \\np = {:.4f}'.format(r_val, p_val), transform=ax_scatter.transAxes,\n",
    "                       fontsize=6)\n",
    "        print(r_val, p_val)\n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    return(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COM_reliability_plot = plot_crossval_com_rel(data_dict, 0, .7, figure=None, frame=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    COM_reliability_plot.savefig(str(fig_fold / \"COM_reliability.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TPI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "from luminance_analysis.plotting import TPI_plot\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define brain regions\n",
    "brain_regions = ['GC_flashes', 'IO_flashes']\n",
    "\n",
    "#Define padding for cropping\n",
    "pad_pre = 1\n",
    "pad_post = 2\n",
    "\n",
    "#Define Ca kernel\n",
    "filter_t = np.arange(0, 1, 0.005)\n",
    "tau = 0.01\n",
    "ca_kernel = np.exp(-filter_t / tau)\n",
    "\n",
    "#Crop stimulus and responses, normalize and store in dict\n",
    "flashes_dict = {brain_region: {} for brain_region in brain_regions}\n",
    "\n",
    "for brain_region in brain_regions:\n",
    "    flashes_dict_br = {flash_idx:{'stim':{}, 'conv_stim':{}, 'resps':{}} for flash_idx in range(3)}\n",
    "    sel_traces = data_dict[brain_region]['raw_traces'][data_dict[brain_region]['sel_idxs']]\n",
    "\n",
    "    for flash in range(3):\n",
    "        step_t, post_int = step_t_sec_list[flash], post_int_s_list[flash]\n",
    "        \n",
    "        #Crop and store stimulus\n",
    "        stim_cropped = data_dict[brain_region]['stim'][slice(*data_dict[brain_region]['pooled'].frame_from_t([step_t-pad_pre, step_t+post_int+pad_post])), :]\n",
    "        flashes_dict_br[flash]['stim'] = stim_cropped\n",
    "        \n",
    "        #Convolve stimulus\n",
    "        conv_stim = np.convolve(stim_cropped[:, 1], ca_kernel)[:stim_cropped[:, 1].shape[0]]\n",
    "        conv_stim_norm = conv_stim/np.trapz(conv_stim)\n",
    "        flashes_dict_br[flash]['conv_stim'] = np.array((stim_cropped[:, 0], conv_stim_norm)).transpose()\n",
    "        \n",
    "        #Crop and store responses\n",
    "        resps = sel_traces[data_dict[brain_region]['ordered_idx'], slice(*data_dict[brain_region]['pooled'].frame_from_t([step_t-pad_pre, step_t+post_int+pad_post]))]\n",
    "        flashes_dict_br[flash]['resps'] = np.empty_like(resps)\n",
    "        for roi in range(resps.shape[0]):\n",
    "            roi_data = resps[roi, :, :]\n",
    "            roi_data_norm = roi_data - np.nanmean(roi_data[:5, :], 0) #Normalize to response during first 2s (bring baseline to 0)\n",
    "            resps_integ = np.trapz(np.abs(roi_data_norm), axis=0)\n",
    "            roi_data_norm  = roi_data_norm/resps_integ #Normalize to integral\n",
    "            flashes_dict_br[flash]['resps'][roi, :, :] = roi_data_norm\n",
    "            \n",
    "    flashes_dict[brain_region] = flashes_dict_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPI_dict = {brain_region:{flash:{} for flash in range(3)} for brain_region in brain_regions}\n",
    "\n",
    "for brain_region in brain_regions:   \n",
    "    \n",
    "    for flash in range(3):\n",
    "        num_rois = flashes_dict[brain_region][flash]['resps'].shape[0]\n",
    "        flash_tpis = []\n",
    "        \n",
    "        for roi in range(num_rois):\n",
    "            roi_tpis = []\n",
    "            roi_resps = flashes_dict[brain_region][flash]['resps'][roi, :, :]\n",
    "            roi_resps = roi_resps[:, np.all(~np.isnan(roi_resps), 0)]\n",
    "            \n",
    "            #For each ROI, calculate its TPI during each one of its individual repetitions\n",
    "            for rep in range(roi_resps.shape[1]):\n",
    "                corr_coef = pearsonr(roi_resps[:, rep], flashes_dict[brain_region][flash]['conv_stim'][:, 1])\n",
    "                rep_tpi = 1-np.abs(corr_coef[0])\n",
    "                roi_tpis.append(rep_tpi)\n",
    "            \n",
    "            flash_tpis.append(roi_tpis)\n",
    "            \n",
    "        tpis_mat = np.empty((num_rois, max([len(flash_tpis[roi]) for roi in range(num_rois)])))\n",
    "        tpis_mat[:] = np.nan\n",
    "        \n",
    "        #Store TPIs from each ROI in a matrix\n",
    "        for roi in range(num_rois):\n",
    "            tpis_mat[roi, :len(flash_tpis[roi])] = flash_tpis[roi]\n",
    "            \n",
    "        TPI_dict[brain_region][flash] = tpis_mat       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate reliability of each ROI, during each flash\n",
    "reliability_dict = {brain_region:{flash:{} for flash in range(3)} for brain_region in brain_regions}\n",
    "\n",
    "for brain_region in brain_regions:\n",
    "    for flash in range(3):\n",
    "        roi_reliability = reliability(flashes_dict[brain_region][flash]['resps'])\n",
    "        reliability_dict[brain_region][flash]['reliability'] = roi_reliability                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPI_plot(TPI_dict, reliability_dict, v_min, v_max, figure=None, frame=None):\n",
    "    \n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    brain_regions = ['GC_flashes', 'IO_flashes']\n",
    "    colors = sns.color_palette()[:3]\n",
    "    \n",
    "    for i, brain_region in enumerate(brain_regions):\n",
    "        \n",
    "        rel_cmap = LinearSegmentedColormap.from_list('rel_map', [[0.9, 0.9, 0.9], colors[i]], N=100)\n",
    "        \n",
    "        for flash in range(3):\n",
    "            \n",
    "            ax_hist = add_offset_axes(figure, (0.075 + .275*flash, 0.7 - .3*i, .25, .25), frame=frame)\n",
    "\n",
    "            rois = range(TPI_dict[brain_region][flash].shape[0])\n",
    "            mean_tpi = np.nanmean(TPI_dict[brain_region][flash], 1)\n",
    "            points = ax_hist.scatter(rois, mean_tpi, c=reliability_dict[brain_region][flash]['reliability'], cmap=rel_cmap, vmin=v_min, vmax=v_max)\n",
    "\n",
    "            ax_hist.set_xlim(0, TPI_dict[brain_region][flash].shape[0])\n",
    "            ax_hist.set_ylim(0, 1)\n",
    "            \n",
    "            if i == 2:\n",
    "                ax_hist.set_xlabel('ROI (sorted by C.O.M. time)')\n",
    "            elif i == 0:\n",
    "                #ax_hist.set_title('Flash {}'.format(flash+1))\n",
    "                ax_hist.text(.5, 1.05, 'Flash {}'.format(flash+1), ha='center', va='top', transform=ax_hist.transAxes, fontsize=8.5)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if flash == 0:\n",
    "                ax_hist.set_ylabel('TPI')\n",
    "            else:\n",
    "                ax_hist.set_yticklabels([])\n",
    "\n",
    "        #Colorbar\n",
    "        axcolor = add_offset_axes(figure, (.925, 0.75 - .3*i, .015, .15), frame=frame)\n",
    "        cbar = plt.colorbar(points, cax=axcolor, shrink=.5)\n",
    "        cbar.set_ticks([v_min, v_max])\n",
    "        cbar.set_label('Reliability coef.', labelpad=-35)\n",
    "\n",
    "    return(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpi_plot = TPI_plot(TPI_dict, reliability_dict, 0, .7, figure=None, frame=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    tpi_plot.savefig(str(fig_fold / \"TPI_panel.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_decoding_dict['IO']['rsquared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rsquared(decoding_dict, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize = (4,4))\n",
    "        \n",
    "    ax = add_offset_axes(figure, (0.1, 0.1, 0.8, 0.8), frame=frame)\n",
    "\n",
    "    ax.hist(decoding_dict['GC']['rsquared'], bins=20, label=\"GCs subset\", color=sns.color_palette()[0])\n",
    "    ax.axvline(decoding_dict['IO']['rsquared'], color=sns.color_palette()[1], label=\"IONs\")\n",
    "    ax.set_xlabel(\"$R^2$\")\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rsquared(duration_decoding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figureS5 = plt.figure(figsize=(9,3))\n",
    "\n",
    "#COM reliability plot:\n",
    "COM_rel_panel = plot_crossval_com_rel(data_dict, 0, .7, figure=figureS5, frame=(0.05, 0.05, .9, .9))\n",
    "figureS5.text(0.05, 0.9, 'A')\n",
    "\n",
    "#COM reliability plot:\n",
    "COM_rel_panel = plot_rsquared(duration_decoding_dict, figure=figureS5, frame=(0.685, 0.05, 0.3, .9))\n",
    "figureS5.text(0.65, 0.9, 'B')\n",
    "\n",
    "# #TPI plot:\n",
    "# TPI_panel = TPI_plot(TPI_dict, reliability_dict, 0, .7, figure=figureS5, frame=(0.05, 0.05, 0.96, 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    figureS5.savefig(str(fig_fold / \"temporal_patterning_supplementary.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

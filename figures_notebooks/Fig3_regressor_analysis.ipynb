{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import flammkuchen as fl\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import cmocean as cmo\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "plt.style.use(\"figures.mplstyle\")\n",
    "cols = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fold = Path(r\"C:\\Users\\otprat\\Documents\\figures\\luminance\\manuscript_figures\\fig3\")\n",
    "\n",
    "if not os.path.isdir(fig_fold):\n",
    "    os.mkdir(fig_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from luminance_analysis import traces_stim_from_path, PooledData\n",
    "from luminance_analysis.utilities import deconv_resamp_norm_trace, reliability, \\\n",
    "    nanzscore, get_kernel, pearson_regressors, get_mn_and_error, train_test_split\n",
    "from luminance_analysis.plotting import shade_plot, make_bar, get_yg_custom_cmap, add_offset_axes\n",
    "from luminance_analysis.clustering import find_trunc_dendro_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressors_from_stim(stim):\n",
    "    \"\"\" Create the regressors for the regressor-based analysis.\n",
    "    \"\"\"\n",
    "    dt = stim[1, 0]\n",
    "    \n",
    "    # Absolute luminance level-based regressors:\n",
    "    reg_dict = dict()\n",
    "    reg_dict[\"lum_true\"] = stim[:, 1].copy()  # raw value\n",
    "    reg_dict[\"lum_gamma1\"] = stim[:, 1]**(1/3)  # gamma1\n",
    "    reg_dict[\"lum_gamma2\"] = stim[:, 1]**(0.1)  # gamma2\n",
    "    reg_dict[\"lum_interm\"] = stim[:, 1]**(0.05) - stim[:, 1]  # intermediate luminance\n",
    "\n",
    "    # Integration-based:\n",
    "    tau = 4  # tau for integrating regressor\n",
    "    kernel = np.exp(-np.arange(0, 10, dt) / tau)\n",
    "#     reg_dict[\"lum_integr\"] = np.convolve(stim[:, 1], kernel / 100)[:stim.shape[0]]\n",
    "\n",
    "    # Derivative-based:\n",
    "    diff = np.insert(np.diff(stim[:, 1]**(1/3)), 0, 0)\n",
    "\n",
    "    lum_on = diff.copy()\n",
    "    lum_on[lum_on < 0] = 0\n",
    "    reg_dict[\"trans_on\"] = lum_on  # on transitions, proportional\n",
    "    reg_dict[\"trans_on_abs\"] = (lum_on > 0).astype(float)  # on transitions, absolute val\n",
    "\n",
    "    lum_off = -diff.copy()\n",
    "    lum_off[lum_off < 0] = 0\n",
    "    reg_dict[\"trans_off\"] = lum_off  # off transitions, proportional\n",
    "    reg_dict[\"trans_off_abs\"] = (lum_off > 0).astype(float)  # off transitions, absolute val\n",
    "\n",
    "    reg_dict[\"trans_onoff\"] = reg_dict[\"trans_on\"] + reg_dict[\"trans_off\"]  # on and off\n",
    "    reg_dict[\"trans_onoff_abs\"] = reg_dict[\"trans_on_abs\"] + reg_dict[\"trans_off_abs\"]  # on and off absolute\n",
    "    \n",
    "    return reg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and create correlation matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path = Path(r\"\\\\FUNES2\\legacy\\experiments\\E0032_luminance\\neat_exps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_6f = 5\n",
    "ker_len = 30\n",
    "delay = 3\n",
    "n_clust = 5\n",
    "normalization = \"zscore\"\n",
    "protocol = \"steps\"\n",
    "\n",
    "protocols = [\"steps\", \"flashes\"]\n",
    "brain_regions_list = [\"GC\", \"IO\", \"PC\"]\n",
    "\n",
    "data_dict = {\"{}_{}\".format(r, p):{} for p, r in product([\"steps\", \"flashes\"], [\"GC\", \"IO\"])}\n",
    "\n",
    "for protocol, brain_region in product([\"steps\", \"flashes\"], [\"GC\", \"IO\"]):\n",
    "    \n",
    "    path = master_path / protocol / brain_region\n",
    "    stim, traces, _ = traces_stim_from_path(path)\n",
    "\n",
    "    # Mean traces, calculate reliability index :\n",
    "    rel_idxs = reliability(traces)\n",
    "    \n",
    "    # Find threshold from reliability histogram...\n",
    "    rel_thr = threshold_otsu(rel_idxs[~np.isnan(rel_idxs)])\n",
    "\n",
    "    # ...and load again filtering with the threshold:\n",
    "    _, traces, meanresps = traces_stim_from_path(path, resp_threshold=rel_thr, nanfraction_thr=1)\n",
    "    \n",
    "    \n",
    "    # Fix problem with interpolated stimulus values between intermediate luminance levels:\n",
    "    invalid_idxs = np.array([stim[:, 1] != n for n in [0, 1, 0.2, 0.05]]).all(0)  # find invalid indexes\n",
    "    if sum(invalid_idxs) > 0:\n",
    "        stim[np.argwhere(invalid_idxs), 1] = stim[np.argwhere(invalid_idxs)-1, 1]  # replace with following value\n",
    "        \n",
    "    # Create regressors:\n",
    "    reg_dict = regressors_from_stim(stim)\n",
    "    \n",
    "    # Convolve them\n",
    "    kernel = get_kernel(tau=tau_6f, ker_len=ker_len, delay=delay)\n",
    "    reg_df = pd.DataFrame({k: nanzscore(np.convolve(reg_dict[k], kernel)[:stim.shape[0]]) for k in reg_dict.keys()})\n",
    "    \n",
    "    # Calculate regressions:\n",
    "    coefs = pd.DataFrame(pearson_regressors(meanresps.T, reg_df.values).T, columns=reg_df.columns)\n",
    "    \n",
    "    # Cluster traces (needed for the sorted plots):\n",
    "    linked = linkage(meanresps, \"ward\")    \n",
    "\n",
    "    # make truncated tree to get clusters ids. \n",
    "    # Ugly but necessary to get the correct sequence of leaves:\n",
    "    plt.figure(figsize=(0.1, 0.1))  \n",
    "    dendro = dendrogram(linked, n_clust, truncate_mode =\"lastp\")\n",
    "    plt.close()\n",
    "    cluster_ids = dendro[\"leaves\"]\n",
    "    labels = find_trunc_dendro_clusters(linked, dendro)\n",
    "    \n",
    "    # Add everything to dictionary:\n",
    "    key = \"{}_{}\".format(brain_region, protocol)\n",
    "    data_dict[key][\"raw_traces\"] = traces\n",
    "    data_dict[key][\"mean_traces\"] = meanresps\n",
    "    data_dict[key][\"stim\"] = stim\n",
    "    data_dict[key][\"reg_df\"] = reg_df\n",
    "    data_dict[key][\"coefs\"] = coefs\n",
    "    data_dict[key][\"clust_labels\"] = labels\n",
    "    data_dict[key][\"pooled\"] = PooledData(path)\n",
    "    \n",
    "reg_keys = list(data_dict[\"GC_steps\"][\"reg_df\"].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the regressor plot, find best predicted trace from each regressor (considering only the steps protocol):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traces_regressors(data_dict, figure=None, frame=None,\n",
    "                           regressors_list=[\"lum_true\", \"lum_interm\", \"trans_off\", \"trans_onoff\"]):\n",
    "    \n",
    "    # Combine IO and GC steps regressors in a single matrix:\n",
    "    io_and_gc_coefs = np.concatenate([data_dict[c + \"_steps\"][\"coefs\"].values for c in [\"GC\", \"IO\"]], axis=0)\n",
    "    n_gc_steps = len(data_dict[\"GC_steps\"][\"coefs\"])  # number of gc in the combined gc and io coefficients matrix\n",
    "\n",
    "    # For each regressor, find best predicted cell:\n",
    "    best_reg_idx = np.array([np.argmax(io_and_gc_coefs[:, c]) for c in range(io_and_gc_coefs.shape[1])])\n",
    "\n",
    "    # For each regressor find the type of the best predicted cell:\n",
    "    cell_type = np.array([\"GC\"]*io_and_gc_coefs.shape[1])\n",
    "    cell_type[best_reg_idx > n_gc_steps] = \"IO\"\n",
    "\n",
    "    # Now from best predicted cell index find index in the relative traces array:\n",
    "    best_reg_idx_pertype = best_reg_idx.copy()\n",
    "    best_reg_idx_pertype[best_reg_idx > n_gc_steps] -= n_gc_steps\n",
    "\n",
    "    offset = 7\n",
    "    barlength = 10  # scalebar in seconds\n",
    "\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(7, 3))\n",
    "    ax = add_offset_axes(figure, (0., 0.1, 1, 0.9), frame=frame)\n",
    "\n",
    "    reg_keys = list(data_dict[\"GC_steps\"][\"reg_df\"].columns)\n",
    "    for n, reg in enumerate(regressors_list):\n",
    "        i = reg_keys.index(reg)\n",
    "        stim = data_dict[\"{}_steps\".format(cell_type[i])][\"stim\"]\n",
    "        reg_df = data_dict[\"{}_steps\".format(cell_type[i])][\"reg_df\"]\n",
    "        tracecol = sns.color_palette()[0] if cell_type[i] == \"GC\" else sns.color_palette()[1]\n",
    "        trace = data_dict[\"{}_steps\".format(cell_type[i])][\"mean_traces\"][best_reg_idx_pertype[i], :]\n",
    "        coef_value = io_and_gc_coefs[best_reg_idx[i], i]\n",
    "        \n",
    "        reg_trace = reg_df[reg] - offset * n\n",
    "        ax.fill_between(stim[:, 0], np.zeros(len(reg_trace)) + np.min(reg_trace), reg_trace\n",
    "                        , facecolor=sns.color_palette()[7], edgecolor=None, alpha=0.5, zorder=100)\n",
    "        ax.plot(stim[:, 0], nanzscore(trace) - offset * n, c=tracecol, zorder=100)\n",
    "        ax.text(1, 2.7 - offset*n, \"{} - {} (R: {:1.2})\".format(reg, cell_type[i], coef_value), fontsize=7, color=tracecol)\n",
    "\n",
    "\n",
    "    shade_plot(stim, shade_range=(0.8, 0.97))\n",
    "    ax.set_xlim(stim[0, 0], stim[-1, 0])\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylim(None, 4)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    make_bar(ax, [stim[-1, 0] - barlength, stim[-1, 0]], \n",
    "             label=\"{} s\".format(barlength))\n",
    "    \n",
    "    #return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_traces_regressors(data_dict, plt.figure(figsize=(7, 3)), frame=(0, 0, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary figure for all regressors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_hist_figure(data_dict, figure=None, frame=None):\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(2.5,2.5))    \n",
    "\n",
    "    for i, c in enumerate([\"GC\", \"IO\"]):\n",
    "        ax = add_offset_axes(figure, (0.1, 0.05 + 1-0.34*(i+1), 0.7, 0.23), frame=frame)\n",
    "        coefs = data_dict[c + \"_steps\"][\"coefs\"].values\n",
    "\n",
    "        best_regressors = np.nanargmax(np.abs(coefs), 1)\n",
    "        percent = np.sum(best_regressors < 4) / len(best_regressors) * 100\n",
    "\n",
    "        ax.hist(best_regressors, np.arange(0,11,1), density=True, stacked=True, color=cols[i])\n",
    "        ax.axvline(4, c=\"k\", linestyle=\"dashed\")\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticks([])\n",
    "\n",
    "        ax.text(9.8, plt.gca().get_ylim()[1]/2, c, fontsize=7, color=cols[i], fontweight=\"bold\")\n",
    "        ax.text(2, plt.gca().get_ylim()[1], \"{:2.1f}%\".format(percent), fontsize=7, color=cols[i])\n",
    "        ax.text(7, plt.gca().get_ylim()[1], \"{:2.1f}%\".format(100 - percent), fontsize=7, color=cols[i])\n",
    "\n",
    "    ax.set_xticks(np.arange(len(reg_keys))+0.5)\n",
    "    ax.set_xticklabels(reg_keys, rotation=80)\n",
    "    sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(4,2.5)) \n",
    "reg_hist_figure(data_dict, figure=figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_scatter_plot(data_dict, figure=None, frame=None, size=5):\n",
    "\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(3,3))\n",
    "        \n",
    "    lims=(-0.05,1.05)\n",
    "    alpha=1\n",
    "    alpha_kde=0.4\n",
    "    n_lum_clust = 4  # number of luminance regressors in the regressor panel\n",
    "    \n",
    "    all_gc = pd.concat([data_dict[\"GC_\" + s][\"coefs\"] for s in [\"steps\", \"flashes\"]], axis=0)\n",
    "    all_io = pd.concat([data_dict[\"IO_\" + s][\"coefs\"] for s in [\"steps\", \"flashes\"]], axis=0)\n",
    "\n",
    "    ax_scatter = add_offset_axes(figure, (0.2, 0.2, 0.5, 0.5), frame=frame)\n",
    "    dwn = all_gc.shape[0] // (all_io.shape[0]*2)  # Downsampling factor to show equal number of points\n",
    "    x_gc = np.nanmax(np.abs(all_gc.values[::dwn, :n_lum_clust]), 1)\n",
    "    y_gc = np.nanmax(np.abs(all_gc.values[::dwn, n_lum_clust:]), 1)\n",
    "    ax_scatter.scatter(x_gc, y_gc, s=size, alpha=alpha, color=cols[0], label=\"GC\")\n",
    "\n",
    "    x_io = np.nanmax(np.abs(all_io.values[:, :n_lum_clust]), 1)\n",
    "    y_io = np.nanmax(np.abs(all_io.values[:, n_lum_clust:]), 1)\n",
    "    ax_scatter.scatter(x_io, y_io, s=size, alpha=alpha, color=cols[1], label=\"IO\")\n",
    "    ax_scatter.text(0.9, 0.9, \"GC\", color=cols[0], fontweight=\"bold\", fontsize=7)\n",
    "    ax_scatter.text(0.9, 0.8, \"IO\", color=cols[1], fontweight=\"bold\", fontsize=7)\n",
    "\n",
    "    ax_scatter.set_aspect('equal')\n",
    "    ax_scatter.set_xlim(*lims)\n",
    "    ax_scatter.set_ylim(*lims)\n",
    "    ax_scatter.set_xticks(np.arange(0,1.1,0.2))\n",
    "    ax_scatter.set_yticks(np.arange(0,1.1,0.2))\n",
    "    ax_scatter.set_xlabel(\"Luminance corr. coef.\")\n",
    "    ax_scatter.set_ylabel(\"Transition corr. coef.\")\n",
    "\n",
    "    x_arr = np.arange(lims[0],lims[1], 0.01)\n",
    "    \n",
    "    ax_kde2 = add_offset_axes(figure, (0.2, 0.7, 0.5, 0.2), frame=frame)\n",
    "    ax_kde2.axis(\"off\")\n",
    "    ax_kde2.fill_between(x_arr, np.zeros(x_arr.shape), gaussian_kde(x_gc)(x_arr), alpha=alpha_kde)\n",
    "    ax_kde2.fill_between(x_arr, np.zeros(x_arr.shape), gaussian_kde(x_io)(x_arr), alpha=alpha_kde)\n",
    "    \n",
    "    ax_kde1 = add_offset_axes(figure, (0.7, 0.2, 0.2, 0.5), frame=frame)\n",
    "    ax_kde1.axis(\"off\")\n",
    "    ax_kde1.fill_betweenx(x_arr, np.zeros(x_arr.shape), gaussian_kde(y_gc)(x_arr), alpha=alpha_kde)\n",
    "    ax_kde1.fill_betweenx(x_arr, np.zeros(x_arr.shape), gaussian_kde(y_io)(x_arr), alpha=alpha_kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_scatter_plot(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding of absolute luminance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_path = Path().resolve().parent/'decoding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_pred_data = fl.load(decoding_path / \"abs_lum_decoding_results_IO_final.h5\")\n",
    "gc_pred_data = fl.load(decoding_path / \"abs_lum_decoding_results_GCsubsampled_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lum_levels = np.array([0.  , 0.05, 0.2 , 1.  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_luminance_decoding(io_data, gc_data, figure=None, frame=None):\n",
    "\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(10, 5))\n",
    "             \n",
    "    for i, (decoding, population) in enumerate(zip([gc_data, io_data],['GCs', 'IONs'])):    \n",
    "        ax_scatter = add_offset_axes(figure, (0.1+0.4*i, 0.15, .3, .8), frame=frame)\n",
    "        \n",
    "        if i==0:\n",
    "            all_iters = pd.concat(gc_data)\n",
    "            sns.violinplot(x=all_iters['lum_true'], y=all_iters['lum_svm'], color=sns.color_palette()[i], ax=ax_scatter)\n",
    "            plt.setp(ax_scatter.collections, alpha=.75, edgecolor=sns.color_palette()[i], facecolor='white')\n",
    "\n",
    "#             for pc in violin_parts['bodies']:\n",
    "#                 pc.set_facecolor('red')\n",
    "#                 pc.set_edgecolor('black')\n",
    "\n",
    "            \n",
    "            plot_iter = 5\n",
    "            sns.swarmplot(x=decoding[plot_iter].lum_true, y=decoding[plot_iter][\"lum_svm\"], s=1.7, ax=ax_scatter, color=sns.color_palette()[i])\n",
    "            ax_scatter.set_ylabel('Predicted luminance')\n",
    "        if i==1:\n",
    "            sns.swarmplot(x=decoding.lum_true, y=decoding[\"lum_svm\"], s=1.7, ax=ax_scatter, color=sns.color_palette()[i])\n",
    "            ax_scatter.set_ylabel('')\n",
    "\n",
    "        ax_scatter.hlines(lum_levels, np.arange(-0.4, 3.6, 1), np.arange(0.4, 3.5, 1), lw=1, color=(0.3, 0.3, 0.3), zorder=3)\n",
    "        ax_scatter.set_xlabel('Actual luminance')\n",
    "        ax_scatter.set_ylim([-.25,1.4])\n",
    "        ax_scatter.set_title(population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_luminance_decoding(io_pred_data, gc_pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding of transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_trans_data = fl.load(decoding_path / \"transition_results_IO_final.h5\")\n",
    "gc_trans_data = fl.load(decoding_path / \"transition_results_GC_final.h5\")\n",
    "all_options = fl.load(decoding_path / \"all_options.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from itertools import product, starmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_product(**items):\n",
    "    Product = namedtuple(\"Product\", items.keys())\n",
    "    return starmap(Product, product(*items.values()))\n",
    "\n",
    "def confmat(pred_bins, pred_gt):\n",
    "    \"\"\" Calculate the confusion matrix by averaging the probaility\n",
    "    distribution of the decoded category for each appearence of that\n",
    "    category (indexed by pred_gt)\n",
    "    \"\"\"\n",
    "    pred_gt = pred_gt.astype(np.int32)\n",
    "    n_bins = pred_bins.shape[1]\n",
    "    confmat = np.zeros((n_bins, n_bins))\n",
    "    n_avg = np.zeros(n_bins, dtype=np.uint16)\n",
    "    for i in range(len(pred_gt)):\n",
    "        confmat[pred_gt[i], :] += pred_bins[i, :]\n",
    "        n_avg[pred_gt[i]] += 1\n",
    "    return confmat/n_avg[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2\n",
    "\n",
    "option_it = list(named_product(**all_options))\n",
    "copt = option_it[0]\n",
    "io_confusion_mat = confmat(io_trans_data[0], np.tile(all_options[\"features\"][copt.features], n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mats_list = []\n",
    "\n",
    "for i in range(len(gc_trans_data)):\n",
    "    option_it = list(named_product(**all_options))\n",
    "\n",
    "    copt = option_it[0]\n",
    "    confusion_mats_list.append(confmat(gc_trans_data[i][0], np.tile(all_options[\"features\"][copt.features], n_test)))\n",
    "    \n",
    "gc_confusion_mats = np.stack(confusion_mats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confmat(confusion_mat):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(confusion_mat, cmap=cmo.cm.tempo, origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"transition {} decoded from {} with a {} decoder\".format(copt.features, copt.population, copt.decoder))\n",
    "    plt.xlabel('Predicted transition')\n",
    "    plt.ylabel('Actual transition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = [np.nan, -1,-.2,-.05, 0, .05, .2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transition_confmats(io_mat, gc_mats, figure=None, frame=None):\n",
    "\n",
    "    if figure is None:\n",
    "        figure = plt.figure(figsize=(10, 5))\n",
    "             \n",
    "    for i, (confmat, population) in enumerate(zip([gc_mats, io_mat],['GCs', 'IONs'])):    \n",
    "        ax_confmat = add_offset_axes(figure, (0.1+0.4*i, 0.15, .3, .8), frame=frame)\n",
    "        if i==0:\n",
    "            ax_confmat.imshow(np.nanmean(confmat, 0), cmap=cmo.cm.tempo, origin='lower')\n",
    "            ax_confmat.set_ylabel('Actual transition')\n",
    "        else:\n",
    "            im = ax_confmat.imshow(confmat, cmap=cmo.cm.tempo, origin='lower')\n",
    "       \n",
    "        ax_confmat.set_title(population)\n",
    "        ax_confmat.set_xlabel('Predicted transition')\n",
    "        ax_confmat.set_xticklabels(transitions)\n",
    "        ax_confmat.set_yticklabels(transitions)\n",
    "        \n",
    "    axcolor = add_offset_axes(figure, (.825, 0.35, 0.015, 0.4), frame=frame)\n",
    "    cbar=plt.colorbar(im, cax=axcolor, orientation='vertical', ticks=[0,.2,.4,.6,.8,1])\n",
    "    cbar.set_label('Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transition_confmats(io_confusion_mat, gc_confusion_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,5)\n",
    "axes = axes.ravel()\n",
    "    \n",
    "for i in range(20):\n",
    "    axes[i].imshow(gc_confusion_mats[i, :, :], cmap=cmo.cm.tempo, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble final figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure3 = plt.figure(figsize=(9,12))\n",
    "\n",
    "# Regressors traces:\n",
    "plot_traces_regressors(data_dict, figure=figure3, frame=(0.05, 0.8, .9, 0.2))\n",
    "figure3.text(.025,.99, 'A')\n",
    "\n",
    "# Regressors histogram:\n",
    "reg_hist_figure(data_dict, figure=figure3, frame=(0.06, 0.525, 0.5, 0.25))\n",
    "figure3.text(.1,.775, 'B')\n",
    "\n",
    "# Regressors scatterplot:\n",
    "regr_scatter_plot(data_dict, figure=figure3, frame=(0.45, 0.525, 0.5, 0.3))\n",
    "figure3.text(.5,.775, 'C')\n",
    "\n",
    "# Luminance value decoding\n",
    "plot_luminance_decoding(io_pred_data, gc_pred_data, figure=figure3, frame=(0.05, 0.29, 1, 0.22))\n",
    "figure3.text(.1,.515, 'D')\n",
    "\n",
    "# Luminance transition decoding\n",
    "plot_transition_confmats(io_confusion_mat, gc_confusion_mats, figure=figure3, frame=(0.05, 0.05, 1, .22))\n",
    "figure3.text(.1,.275, 'E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    figure3.savefig(str(fig_fold / \"comparison.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure3 = plt.figure(figsize=(9,10))\n",
    "\n",
    "# Regressors traces:\n",
    "plot_traces_regressors(data_dict, figure=figure3, frame=(0.05, 0.65, .9, 0.35))\n",
    "figure3.text(.025,.99, 'A')\n",
    "\n",
    "# Regressors histogram:\n",
    "reg_hist_figure(data_dict, figure=figure3, frame=(0.06, 0.375, 0.5, 0.25))\n",
    "figure3.text(.1,.65, 'B')\n",
    "\n",
    "# Regressors scatterplot:\n",
    "regr_scatter_plot(data_dict, figure=figure3, frame=(0.45, 0.375, 0.5, 0.3))\n",
    "figure3.text(.5,.65, 'C')\n",
    "\n",
    "# Luminance value decoding\n",
    "plot_luminance_decoding(io_pred_data, gc_pred_data, figure=figure3, frame=(0.05, 0.05, 1, 0.3))\n",
    "figure3.text(.1,.35, 'D')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    figure3.savefig(str(fig_fold / \"fig3.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure3supp = plt.figure(figsize=(6, 5))\n",
    "plot_traces_regressors(data_dict, figure3supp, frame=(0, 0, 1, 1), regressors_list=reg_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_fold = Path(r\"C:\\Users\\otprat\\Documents\\figures\\luminance\\manuscript_figures\\fig3supp\")\n",
    "\n",
    "if not os.path.isdir(fig_fold):\n",
    "    os.mkdir(fig_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_fold is not None:\n",
    "    figure3supp.savefig(fig_fold/ \"fig3_supplementary.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
